{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Nifti_MONAI6Balanced).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. This is the improved of Model 5\n",
        "1. the architecture is 3DUNet\n",
        "2. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the\n",
        "3. strong augmentation is used in the code...\n",
        "4. Dice Loss is 1 and Binary classification Entropy is 1\n",
        "5. Number of positive pixels is for all patients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c9b63d-ee38-415c-d355-304f737ebe59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (1.26.4)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import AsDiscrete\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    ResizeWithPadOrCropd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandFlipd,\n",
        "    RandAffined,\n",
        "    RandGaussianNoised,\n",
        "    RandScaleIntensityd,\n",
        "    ToTensord,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstD,\n",
        "    SpatialPadd,\n",
        "    Rand3DElasticd,\n",
        "    NormalizeIntensityd,\n",
        "    RandGaussianSmoothd,\n",
        "    RandAdjustContrastd\n",
        "\n",
        ")\n",
        "import json\n",
        "from monai.data import CacheDataset\n",
        "from monai.transforms import Transform\n",
        "from monai.data import CacheDataset\n",
        "import torch.nn.functional as F\n",
        "from monai.data import Dataset, DataLoader, CacheDataset, pad_list_data_collate\n",
        "from monai.networks.layers import Norm\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from monai.transforms import EnsureTyped\n",
        "from monai.transforms import SaveImaged\n",
        "from monai.utils import set_determinism\n",
        "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Num foregrounds 0, Num backgrounds.*unable to generate class balanced samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "17d0fe4f-d7fb-4763-aab3-ca46e3951643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGu3zWdW3jje"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class ImprovedDiceFocalLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, dice_weight=0.7, focal_weight=0.3, gamma=2.0, alpha=0.25, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.dice_weight = dice_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.pos_weight = pos_weight  # Store pos_weight\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "\n",
        "        # Dice Loss\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth\n",
        "        )\n",
        "\n",
        "        # Focal Loss with pos_weight\n",
        "        if self.pos_weight is not None:\n",
        "            # Apply pos_weight to the focal loss\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(\n",
        "                preds, targets,\n",
        "                reduction='none',\n",
        "                pos_weight=self.pos_weight  # This is the key change!\n",
        "            )\n",
        "        else:\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(preds, targets, reduction='none')\n",
        "\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
        "\n",
        "        return self.dice_weight * dice_loss + self.focal_weight * focal_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        # Remove super().__init__() since there's no parent class\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "        self.hd95_metric = HausdorffDistanceMetric(include_background=False, percentile=95, reduction=\"mean\")\n",
        "        self.asd_metric = SurfaceDistanceMetric(include_background=False, reduction=\"mean\")\n",
        "\n",
        "        # Create test output directory\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Update CSV headers to include new metrics\n",
        "        self._init_enhanced_metrics_csv()\n",
        "\n",
        "    def _init_enhanced_metrics_csv(self):\n",
        "        \"\"\"Initialize CSV with additional metric columns\"\"\"\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\n",
        "                    \"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\",\n",
        "                    \"Dice\", \"HD95\", \"ASD\", \"Time\"\n",
        "                ])\n",
        "\n",
        "    def calculate_basic_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate basic segmentation metrics (replacement for missing parent class)\"\"\"\n",
        "        # If you had a parent class with calculate_metrics, implement it here\n",
        "        eps = 1e-8\n",
        "\n",
        "        tp = np.sum(y_true * y_pred)\n",
        "        fp = np.sum((1 - y_true) * y_pred)\n",
        "        fn = np.sum(y_true * (1 - y_pred))\n",
        "        tn = np.sum((1 - y_true) * (1 - y_pred))\n",
        "\n",
        "        jaccard = tp / (tp + fp + fn + eps)\n",
        "        f1 = 2 * tp / (2 * tp + fp + fn + eps)\n",
        "        recall = tp / (tp + fn + eps)\n",
        "        precision = tp / (tp + fp + eps)\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn + eps)\n",
        "\n",
        "        return [jaccard, f1, recall, precision, accuracy]\n",
        "\n",
        "    def calculate_comprehensive_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate both basic and medical image metrics\"\"\"\n",
        "        # Use the new basic metrics method\n",
        "        basic_metrics = self.calculate_basic_metrics(y_true, y_pred)\n",
        "\n",
        "        # Convert to torch tensors for MONAI metrics\n",
        "        y_true_t = torch.from_numpy(y_true.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "        y_pred_t = torch.from_numpy(y_pred.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Calculate MONAI metrics\n",
        "        dice_value = self.dice_metric(y_pred_t, y_true_t)\n",
        "        hd95_value = self.hd95_metric(y_pred_t, y_true_t)\n",
        "        asd_value = self.asd_metric(y_pred_t, y_true_t)\n",
        "\n",
        "        # Reset metrics for next calculation\n",
        "        self.dice_metric.reset()\n",
        "        self.hd95_metric.reset()\n",
        "        self.asd_metric.reset()\n",
        "\n",
        "        return basic_metrics + [\n",
        "            dice_value.item() if not dice_value.isnan() else 0.0,\n",
        "            hd95_value.item() if not hd95_value.isnan() else 0.0,\n",
        "            asd_value.item() if not asd_value.isnan() else 0.0\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image_np: np.ndarray, pred_np: np.ndarray, label_np: np.ndarray, sample_id: str):\n",
        "        \"\"\"Save sample slices for visualization\"\"\"\n",
        "        try:\n",
        "            # Find slices with predictions for better visualization\n",
        "            pred_slices = np.where(np.any(pred_np, axis=(0, 1)))[0]\n",
        "            label_slices = np.where(np.any(label_np, axis=(0, 1)))[0]\n",
        "\n",
        "            # Combine and get unique slices of interest\n",
        "            slices_of_interest = np.unique(np.concatenate([pred_slices, label_slices]))\n",
        "\n",
        "            # If no positive slices, use center slices\n",
        "            if len(slices_of_interest) == 0:\n",
        "                slices_of_interest = [pred_np.shape[2] // 2 - 1, pred_np.shape[2] // 2, pred_np.shape[2] // 2 + 1]\n",
        "\n",
        "            # Save a few representative slices\n",
        "            for i, slice_idx in enumerate(slices_of_interest[:3]):  # Save max 3 slices\n",
        "                if 0 <= slice_idx < pred_np.shape[2]:\n",
        "                    # Create a simple visualization\n",
        "                    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "                    axes[0].imshow(image_np[:, :, slice_idx], cmap='gray')\n",
        "                    axes[0].set_title(f'Image - Slice {slice_idx}')\n",
        "                    axes[0].axis('off')\n",
        "\n",
        "                    axes[1].imshow(label_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[1].set_title('Ground Truth')\n",
        "                    axes[1].axis('off')\n",
        "\n",
        "                    axes[2].imshow(pred_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[2].set_title('Prediction')\n",
        "                    axes[2].axis('off')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    save_path = os.path.join(self.test_result_path, f\"{sample_id}_slice_{slice_idx}.png\")\n",
        "                    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not save slices for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        \"\"\"Override to handle extended metrics\"\"\"\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            # Now metrics should have: [jaccard, f1, recall, precision, accuracy, dice, hd95, asd]\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(8)  # Now 8 metrics total\n",
        "        total_times = []\n",
        "\n",
        "        # Count samples with actual predictions\n",
        "        samples_with_predictions = 0\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                # Skip if no predictions AND no ground truth (empty case)\n",
        "                if pred_np.sum() == 0 and label_np.sum() == 0:\n",
        "                    print(f\"📝 Sample {batch_idx}: No predictions and no ground truth - skipping\")\n",
        "                    continue\n",
        "\n",
        "                # Enhanced metrics calculation\n",
        "                metrics = self.calculate_comprehensive_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "                samples_with_predictions += 1\n",
        "\n",
        "                sample_id = f\"sample_{batch_idx:03d}\"\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "                # Print sample-level results\n",
        "                print(f\"📊 Sample {batch_idx}: Dice={metrics[5]:.4f}, HD95={metrics[6]:.2f}mm, Time={elapsed:.2f}s\")\n",
        "\n",
        "        # Print enhanced summary (only for samples with meaningful data)\n",
        "        if samples_with_predictions > 0:\n",
        "            num_samples = samples_with_predictions\n",
        "            metric_names = [\"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Dice\", \"HD95\", \"ASD\"]\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"📊 ENHANCED TEST METRICS SUMMARY:\")\n",
        "            print(\"=\"*60)\n",
        "            for i, name in enumerate(metric_names):\n",
        "                print(f\"{name:<12}: {total_metrics[i]/num_samples:.4f}\")\n",
        "            print(f\"📈 Samples evaluated: {num_samples}/{len(test_loader)}\")\n",
        "            print(f\"⚡ Average FPS: {1 / np.mean(total_times):.2f}\")\n",
        "            print(f\"⏱️  Average time per sample: {np.mean(total_times):.2f}s\")\n",
        "        else:\n",
        "            print(\"❌ No samples with meaningful predictions to evaluate!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) Early Stopping"
      ],
      "metadata": {
        "id": "3JLRqnw5L7xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0, pos_weight=None):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "        self.pos_weight = pos_weight  # Store pos_weight\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None, pos_weight=None):\n",
        "        # Update pos_weight if provided\n",
        "        if pos_weight is not None:\n",
        "            self.pos_weight = pos_weight\n",
        "\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"✅ Validation loss improved ({self.val_loss_min:.6f}). Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"⏳ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # Always save a full checkpoint with pos_weight\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter,\n",
        "            'pos_weight': self.pos_weight  # Save pos_weight here\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        if self.verbose and self.pos_weight is not None:\n",
        "            print(f\"💾 Checkpoint saved with pos_weight: {self.pos_weight:.4f}\")"
      ],
      "metadata": {
        "id": "LA4lGL-xL6st"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (7). Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------- Trainer ----------\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        # Initialize pos_weight_file\n",
        "        self.pos_weight_file = model_file.replace('.pth', '_pos_weight.json')\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, scheduler, accumulation_steps, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = torch.amp.GradScaler()\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        # Initialize patch monitoring variables\n",
        "        positive_patches = 0\n",
        "        total_patches = 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            inputs, labels = batch[\"vol\"].to(self.device, non_blocking=True), batch[\"seg\"].to(self.device, non_blocking=True)\n",
        "\n",
        "            # Monitor patch quality\n",
        "            batch_positives = labels.sum().item()\n",
        "            if batch_positives > 0:\n",
        "                positive_patches += 1\n",
        "\n",
        "            total_patches += 1\n",
        "\n",
        "            with torch.amp.autocast(device_type=device_type, enabled=True):\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels) / accumulation_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"  Batch {i+1}/{len(loader)}, Loss: {loss.item() * accumulation_steps:.4f}\")\n",
        "\n",
        "        print(f\"  Patch Quality: {positive_patches}/{total_patches} ({positive_patches/total_patches*100:.1f}%) with positives\")\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def save_pos_weight(self, pos_weight):\n",
        "        \"\"\"Save pos_weight to JSON file\"\"\"\n",
        "        with open(self.pos_weight_file, 'w') as f:\n",
        "            json.dump({'pos_weight': pos_weight, 'timestamp': time.time()}, f)\n",
        "        print(f\"💾 Saved pos_weight: {pos_weight:.4f}\")\n",
        "\n",
        "    def load_pos_weight(self):\n",
        "        \"\"\"Load pos_weight from JSON file\"\"\"\n",
        "        if os.path.exists(self.pos_weight_file):\n",
        "            try:\n",
        "                with open(self.pos_weight_file, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    pos_weight = data['pos_weight']\n",
        "                    print(f\"📂 Loaded pos_weight: {pos_weight:.4f}\")\n",
        "                    return pos_weight\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error loading pos_weight: {e}\")\n",
        "        return None\n",
        "\n",
        "    def get_pos_weight(self, train_loader, force_recompute=False):\n",
        "        \"\"\"Get pos_weight - load if exists, otherwise compute and save\"\"\"\n",
        "        if not force_recompute:\n",
        "            pos_weight = self.load_pos_weight()\n",
        "            if pos_weight is not None:\n",
        "                return pos_weight\n",
        "\n",
        "        # Compute new pos_weight\n",
        "        pos_weight = self.compute_pos_weight(train_loader, max_batches=None)\n",
        "        self.save_pos_weight(pos_weight)\n",
        "        return pos_weight\n",
        "\n",
        "    def compute_pos_weight(self, train_loader, max_batches=None):\n",
        "        \"\"\"Compute pos_weight with better diagnostics\"\"\"\n",
        "        pos, neg = 0, 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            seg = batch[\"seg\"].to(self.device)\n",
        "            batch_pos = seg.sum().item()\n",
        "            batch_neg = seg.numel() - batch_pos\n",
        "\n",
        "            pos += batch_pos\n",
        "            neg += batch_neg\n",
        "            total_samples += 1\n",
        "\n",
        "            print(f\"Batch {i}: pos={batch_pos}, neg={batch_neg}, pos_ratio={batch_pos/seg.numel():.6f}\")\n",
        "\n",
        "            if max_batches and (i + 1) >= max_batches:\n",
        "                break\n",
        "\n",
        "        pos_ratio = pos / (pos + neg) if (pos + neg) > 0 else 0\n",
        "        pos_weight = neg / (pos + 1e-8)\n",
        "\n",
        "        print(f\"📊 Final Stats:\")\n",
        "        print(f\"  Total pos voxels: {pos}\")\n",
        "        print(f\"  Total neg voxels: {neg}\")\n",
        "        print(f\"  Positive ratio: {pos_ratio:.6f} ({pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Computed pos_weight: {pos_weight:.4f}\")\n",
        "        return pos_weight\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        # Use the smaller, faster model as I suggested\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),  # Reduced channels\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,  # Reduced residual units\n",
        "            norm=Norm.INSTANCE,\n",
        "            dropout=0.1,\n",
        "            act='PRELU'  # PReLU for better gradient flow\n",
        "        ).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
        "\n",
        "        scheduler = lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=self.lr,\n",
        "            epochs=self.num_epochs,\n",
        "            steps_per_epoch=len(train_loader),\n",
        "            pct_start=0.1,\n",
        "            div_factor=10,\n",
        "            final_div_factor=100\n",
        "        )\n",
        "\n",
        "        # 🔹 Auto-compute pos_weight before training\n",
        "        pos_weight = self.get_pos_weight(train_loader)\n",
        "        # Cap pos_weight to reasonable value\n",
        "        reasonable_pos_weight = min(pos_weight, 100.0)  # Maximum 100:1 imbalance\n",
        "        print(f\"📊 Using reasonable pos_weight: {reasonable_pos_weight:.2f} (capped from {pos_weight:.2f})\")\n",
        "\n",
        "        # ✅ USE OPTION 1: Modified ImprovedDiceFocalLoss with pos_weight support\n",
        "        loss_fn = ImprovedDiceFocalLoss(\n",
        "            dice_weight=0.8,\n",
        "            focal_weight=0.2,\n",
        "            gamma=3.0,\n",
        "            alpha=0.8,\n",
        "            pos_weight=torch.tensor([reasonable_pos_weight], device=self.device)  # Add pos_weight here\n",
        "        )\n",
        "\n",
        "        accumulation_steps = 4\n",
        "\n",
        "        # ---- Resume training state ----\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "            # Load pos_weight from checkpoint if available\n",
        "            loaded_pos_weight = checkpoint.get('pos_weight')\n",
        "            if loaded_pos_weight is not None:\n",
        "                pos_weight = loaded_pos_weight\n",
        "                reasonable_pos_weight = min(pos_weight, 100.0)\n",
        "                # Recreate loss function with loaded pos_weight\n",
        "                loss_fn = ImprovedDiceFocalLoss(\n",
        "                    dice_weight=0.8,\n",
        "                    focal_weight=0.2,\n",
        "                    gamma=3.0,\n",
        "                    alpha=0.8,\n",
        "                    pos_weight=torch.tensor([reasonable_pos_weight], device=self.device)\n",
        "                )\n",
        "                print(f\"📂 Loaded pos_weight from checkpoint: {pos_weight:.4f}\")\n",
        "\n",
        "        # History loading code (you'll need to implement this part)\n",
        "        # if os.path.exists(self.loss_result_path):\n",
        "        #     ... your history loading code ...\n",
        "\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter,\n",
        "            pos_weight=reasonable_pos_weight  # Use the capped value\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # ---- Training loop ----\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(\n",
        "                model, train_loader, optimizer, scheduler, accumulation_steps, loss_fn\n",
        "            )\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "\n",
        "            mins, secs = self.epoch_time(start_time, time.time())\n",
        "            print(f\"Epoch {epoch:03d} | Time: {mins}m {secs}s | \"\n",
        "                  f\"Train: {train_loss:.6f} | Val: {valid_loss:.6f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer, reasonable_pos_weight):\n",
        "                print(\"🛑 Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this class definition with your other custom classes\n",
        "class CenterCropByPositiveRegiond(Transform):\n",
        "    \"\"\"Crop around regions that contain positive labels\"\"\"\n",
        "    def __init__(self, keys, label_key, spatial_size, num_samples=2):\n",
        "        self.keys = keys\n",
        "        self.label_key = label_key\n",
        "        self.spatial_size = spatial_size\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __call__(self, data):\n",
        "        seg = data[self.label_key]\n",
        "\n",
        "        # Find coordinates of positive voxels\n",
        "        positive_coords = torch.nonzero(seg[0] > 0.5)  # [N, 3]\n",
        "\n",
        "        patches = []\n",
        "\n",
        "        if len(positive_coords) > 0:\n",
        "            # Sample different positive regions\n",
        "            for i in range(self.num_samples):\n",
        "                if i < len(positive_coords):\n",
        "                    center_coord = positive_coords[i % len(positive_coords)]\n",
        "                else:\n",
        "                    center_coord = positive_coords[torch.randint(0, len(positive_coords), (1,))[0]]\n",
        "\n",
        "                # Calculate crop bounds\n",
        "                spatial_size = self.spatial_size\n",
        "                roi_start = [\n",
        "                    max(0, center_coord[0].item() - spatial_size[0] // 2),\n",
        "                    max(0, center_coord[1].item() - spatial_size[1] // 2),\n",
        "                    max(0, center_coord[2].item() - spatial_size[2] // 2)\n",
        "                ]\n",
        "                roi_end = [\n",
        "                    min(seg.shape[1], roi_start[0] + spatial_size[0]),\n",
        "                    min(seg.shape[2], roi_start[1] + spatial_size[1]),\n",
        "                    min(seg.shape[3], roi_start[2] + spatial_size[2])\n",
        "                ]\n",
        "\n",
        "                # Apply crop\n",
        "                crop_transform = SpatialCropd(keys=self.keys, roi_start=roi_start, roi_end=roi_end)\n",
        "\n",
        "                try:\n",
        "                    patch = crop_transform(data)\n",
        "                    patches.append(patch)\n",
        "                except Exception as e:\n",
        "                    # Fallback to random crop if center crop fails\n",
        "                    print(f\"⚠️ Center crop failed: {e}, using random fallback\")\n",
        "                    rand_crop = RandCropByPosNegLabeld(\n",
        "                        keys=self.keys, label_key=self.label_key,\n",
        "                        spatial_size=self.spatial_size, num_samples=1\n",
        "                    )\n",
        "                    fallback_patches = rand_crop(data)\n",
        "                    if isinstance(fallback_patches, list):\n",
        "                        patches.extend(fallback_patches)\n",
        "                    else:\n",
        "                        patches.append(fallback_patches)\n",
        "        else:\n",
        "            # Fallback if no positives found\n",
        "            print(\"⚠️ No positive voxels found, using random sampling\")\n",
        "            rand_crop = RandCropByPosNegLabeld(\n",
        "                keys=self.keys, label_key=self.label_key,\n",
        "                spatial_size=self.spatial_size, num_samples=self.num_samples\n",
        "            )\n",
        "            patches = rand_crop(data)\n",
        "\n",
        "        return patches[:self.num_samples]"
      ],
      "metadata": {
        "id": "El6TbMoXGWE9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (8). Pipeline"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CwcTHPshqu0O",
        "outputId": "6bdfba60-612c-432c-af7b-dd1f126e1079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "📦 Preparing datasets and transforms...\n",
            "🔄 Loading training dataset...\n",
            "📊 Filtered 340 -> 340 non-empty samples\n",
            "📁 train: Loaded 340 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 34/34 [03:27<00:00,  6.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading validation dataset...\n",
            "📁 valid: Loaded 43 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 8/8 [00:56<00:00,  7.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading test dataset...\n",
            "📁 test: Loaded 38 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 7/7 [00:48<00:00,  6.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Filtered 340 -> 340 non-empty samples\n",
            "📁 train: Loaded 340 samples\n",
            "✅ Dataset sizes — Train: 340, Valid: 43, Test: 38\n",
            "\n",
            "============================================================\n",
            "🔍 RUNNING DATASET QUALITY ANALYSIS...\n",
            "============================================================\n",
            "📊 Analyzing dataset quality...\n",
            "\n",
            "📊 TRAIN (Full Volumes) Dataset Analysis:\n",
            "----------------------------------------\n",
            "  Total volumes: 340\n",
            "  Volumes with positives: 70 (20.6%)\n",
            "  Overall positive ratio: 0.001857 (0.1857%)\n",
            "  Total positive voxels: 558,554.0\n",
            "  Total voxels: 300,810,240\n",
            "\n",
            "📊 VALID (Full Volumes) Dataset Analysis:\n",
            "----------------------------------------\n",
            "  Total volumes: 43\n",
            "  Volumes with positives: 14 (32.6%)\n",
            "  Overall positive ratio: 0.002372 (0.2372%)\n",
            "  Total positive voxels: 90,254.0\n",
            "  Total voxels: 38,043,648\n",
            "\n",
            "📊 TEST (Full Volumes) Dataset Analysis:\n",
            "----------------------------------------\n",
            "  Total volumes: 38\n",
            "  Volumes with positives: 8 (21.1%)\n",
            "  Overall positive ratio: 0.002062 (0.2062%)\n",
            "  Total positive voxels: 69,339.0\n",
            "  Total voxels: 33,619,968\n",
            "\n",
            "🔍 Analyzing Training Patches (After Sampling):\n",
            "\n",
            "📊 TRAIN PATCHES Patch Analysis (first 20 batches):\n",
            "--------------------------------------------------\n",
            "  Batch 0, Patch 0: 1710.0/884736 (0.193% positive)\n",
            "  Batch 0, Patch 1: 1710.0/884736 (0.193% positive)\n",
            "  Batch 0, Patch 2: 1710.0/884736 (0.193% positive)\n",
            "  Batch 0, Patch 3: 1710.0/884736 (0.193% positive)\n",
            "  Batch 1, Patch 0: 3615.0/884736 (0.409% positive)\n",
            "  Batch 1, Patch 1: 3615.0/884736 (0.409% positive)\n",
            "  Batch 1, Patch 2: 3615.0/884736 (0.409% positive)\n",
            "  Batch 1, Patch 3: 3615.0/884736 (0.409% positive)\n",
            "  Batch 2, Patch 0: 990.0/884736 (0.112% positive)\n",
            "  Batch 2, Patch 1: 990.0/884736 (0.112% positive)\n",
            "  Batch 2, Patch 2: 990.0/884736 (0.112% positive)\n",
            "  Batch 2, Patch 3: 990.0/884736 (0.112% positive)\n",
            "  Batch 3, Patch 0: 55883.0/884736 (6.316% positive)\n",
            "  Batch 3, Patch 1: 28695.0/884736 (3.243% positive)\n",
            "  Batch 3, Patch 2: 45480.0/884736 (5.141% positive)\n",
            "  Batch 3, Patch 3: 54297.0/884736 (6.137% positive)\n",
            "  Batch 4, Patch 0: 8715.0/884736 (0.985% positive)\n",
            "  Batch 4, Patch 1: 8370.0/884736 (0.946% positive)\n",
            "  Batch 4, Patch 2: 8715.0/884736 (0.985% positive)\n",
            "  Batch 4, Patch 3: 8304.0/884736 (0.939% positive)\n",
            "  Batch 5, Patch 0: 28921.0/884736 (3.269% positive)\n",
            "  Batch 5, Patch 1: 42803.0/884736 (4.838% positive)\n",
            "  Batch 5, Patch 2: 28593.0/884736 (3.232% positive)\n",
            "  Batch 5, Patch 3: 42490.0/884736 (4.803% positive)\n",
            "  Batch 6, Patch 0: 33051.0/884736 (3.736% positive)\n",
            "  Batch 6, Patch 1: 35981.0/884736 (4.067% positive)\n",
            "  Batch 6, Patch 2: 37816.0/884736 (4.274% positive)\n",
            "  Batch 6, Patch 3: 30960.0/884736 (3.499% positive)\n",
            "  Batch 7, Patch 0: 6555.0/884736 (0.741% positive)\n",
            "  Batch 7, Patch 1: 6567.0/884736 (0.742% positive)\n",
            "  Batch 7, Patch 2: 6396.0/884736 (0.723% positive)\n",
            "  Batch 7, Patch 3: 6438.0/884736 (0.728% positive)\n",
            "  Batch 8, Patch 0: 96756.0/884736 (10.936% positive)\n",
            "  Batch 8, Patch 1: 106959.0/884736 (12.089% positive)\n",
            "  Batch 8, Patch 2: 87715.0/884736 (9.914% positive)\n",
            "  Batch 8, Patch 3: 106269.0/884736 (12.011% positive)\n",
            "  Batch 9, Patch 0: 38355.0/884736 (4.335% positive)\n",
            "  Batch 9, Patch 1: 27029.0/884736 (3.055% positive)\n",
            "  Batch 9, Patch 2: 29622.0/884736 (3.348% positive)\n",
            "  Batch 9, Patch 3: 22671.0/884736 (2.562% positive)\n",
            "  Batch 10, Patch 0: 17891.0/884736 (2.022% positive)\n",
            "  Batch 10, Patch 1: 17253.0/884736 (1.950% positive)\n",
            "  Batch 10, Patch 2: 17806.0/884736 (2.013% positive)\n",
            "  Batch 10, Patch 3: 17448.0/884736 (1.972% positive)\n",
            "  Batch 11, Patch 0: 90219.0/884736 (10.197% positive)\n",
            "  Batch 11, Patch 1: 93637.0/884736 (10.584% positive)\n",
            "  Batch 11, Patch 2: 42990.0/884736 (4.859% positive)\n",
            "  Batch 11, Patch 3: 79899.0/884736 (9.031% positive)\n",
            "  Batch 12, Patch 0: 29089.0/884736 (3.288% positive)\n",
            "  Batch 12, Patch 1: 36100.0/884736 (4.080% positive)\n",
            "  Batch 12, Patch 2: 15679.0/884736 (1.772% positive)\n",
            "  Batch 12, Patch 3: 19443.0/884736 (2.198% positive)\n",
            "  Batch 13, Patch 0: 17436.0/884736 (1.971% positive)\n",
            "  Batch 13, Patch 1: 17436.0/884736 (1.971% positive)\n",
            "  Batch 13, Patch 2: 73173.0/884736 (8.271% positive)\n",
            "  Batch 13, Patch 3: 68119.0/884736 (7.699% positive)\n",
            "  Batch 14, Patch 0: 9966.0/884736 (1.126% positive)\n",
            "  Batch 14, Patch 1: 9099.0/884736 (1.028% positive)\n",
            "  Batch 14, Patch 2: 9966.0/884736 (1.126% positive)\n",
            "  Batch 14, Patch 3: 9947.0/884736 (1.124% positive)\n",
            "  Batch 15, Patch 0: 55890.0/884736 (6.317% positive)\n",
            "  Batch 15, Patch 1: 70122.0/884736 (7.926% positive)\n",
            "  Batch 15, Patch 2: 80787.0/884736 (9.131% positive)\n",
            "  Batch 15, Patch 3: 100613.0/884736 (11.372% positive)\n",
            "  Batch 16, Patch 0: 13439.0/884736 (1.519% positive)\n",
            "  Batch 16, Patch 1: 12147.0/884736 (1.373% positive)\n",
            "  Batch 16, Patch 2: 13248.0/884736 (1.497% positive)\n",
            "  Batch 16, Patch 3: 13659.0/884736 (1.544% positive)\n",
            "  Batch 17, Patch 0: 67198.0/884736 (7.595% positive)\n",
            "  Batch 17, Patch 1: 80551.0/884736 (9.105% positive)\n",
            "  Batch 17, Patch 2: 57167.0/884736 (6.461% positive)\n",
            "  Batch 17, Patch 3: 69639.0/884736 (7.871% positive)\n",
            "  Batch 18, Patch 0: 22254.0/884736 (2.515% positive)\n",
            "  Batch 18, Patch 1: 21511.0/884736 (2.431% positive)\n",
            "  Batch 18, Patch 2: 24452.0/884736 (2.764% positive)\n",
            "  Batch 18, Patch 3: 15667.0/884736 (1.771% positive)\n",
            "  Batch 19, Patch 0: 10527.0/884736 (1.190% positive)\n",
            "  Batch 19, Patch 1: 10997.0/884736 (1.243% positive)\n",
            "  Batch 19, Patch 2: 10179.0/884736 (1.151% positive)\n",
            "  Batch 19, Patch 3: 10083.0/884736 (1.140% positive)\n",
            "\n",
            "📈 TRAIN PATCHES Patch Summary:\n",
            "  Total patches analyzed: 80\n",
            "  Patches with positives: 80 (100.0%)\n",
            "  Overall positive ratio: 0.035581 (3.5581%)\n",
            "\n",
            "============================================================\n",
            "✅ RUNNING COMPREHENSIVE DATA SANITY CHECKS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "🔍 RUNNING COMPREHENSIVE DATA SANITY CHECKS\n",
            "============================================================\n",
            "\n",
            "📊 TRAINING DATA SANITY CHECK:\n",
            "🔍 Checking train loader...\n",
            "\n",
            "  Batch 0:\n",
            "    Volume shape: torch.Size([4, 1, 96, 96, 96])\n",
            "    Volume range: [-1.1003, 1.1026]\n",
            "    Volume mean: -0.2272 ± 0.4788\n",
            "    Segmentation shape: torch.Size([4, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0., 1.])\n",
            "    Positives: 6,822.0/3,538,944 (0.1928%)\n",
            "\n",
            "  Batch 1:\n",
            "    Volume shape: torch.Size([4, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0045, 1.0034]\n",
            "    Volume mean: -0.1701 ± 0.4484\n",
            "    Segmentation shape: torch.Size([4, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0., 1.])\n",
            "    Positives: 59,073.0/3,538,944 (1.6692%)\n",
            "\n",
            "  📈 train Summary (2 batches):\n",
            "    Total positives: 65,895.0\n",
            "    Total voxels: 7,077,888\n",
            "    Overall positive ratio: 0.009310 (0.9310%)\n",
            "\n",
            "📊 VALIDATION DATA SANITY CHECK:\n",
            "🔍 Checking valid loader...\n",
            "\n",
            "  Batch 0:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: -0.0290 ± 0.4649\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0., 1.])\n",
            "    Positives: 14,575.0/884,736 (1.6474%)\n",
            "\n",
            "  Batch 1:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: 0.1739 ± 0.3835\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0., 1.])\n",
            "    Positives: 2,131.0/884,736 (0.2409%)\n",
            "\n",
            "  📈 valid Summary (2 batches):\n",
            "    Total positives: 16,706.0\n",
            "    Total voxels: 1,769,472\n",
            "    Overall positive ratio: 0.009441 (0.9441%)\n",
            "\n",
            "📊 TEST DATA SANITY CHECK:\n",
            "🔍 Checking test loader...\n",
            "\n",
            "  Batch 0:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: 0.0950 ± 0.3471\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0.])\n",
            "    Positives: 0.0/884,736 (0.0000%)\n",
            "\n",
            "  Batch 1:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: 0.3079 ± 0.3204\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0., 1.])\n",
            "    Positives: 4,878.0/884,736 (0.5514%)\n",
            "\n",
            "  📈 test Summary (2 batches):\n",
            "    Total positives: 4,878.0\n",
            "    Total voxels: 1,769,472\n",
            "    Overall positive ratio: 0.002757 (0.2757%)\n",
            "\n",
            "📊 FULL VOLUME SANITY CHECK (Before Patch Sampling):\n",
            "🔍 Checking full_train loader...\n",
            "\n",
            "  Batch 0:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: 0.2214 ± 0.3247\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0.])\n",
            "    Positives: 0.0/884,736 (0.0000%)\n",
            "\n",
            "  Batch 1:\n",
            "    Volume shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Volume range: [-1.0000, 1.0000]\n",
            "    Volume mean: 0.2422 ± 0.3573\n",
            "    Segmentation shape: torch.Size([1, 1, 96, 96, 96])\n",
            "    Segmentation unique values: tensor([0.])\n",
            "    Positives: 0.0/884,736 (0.0000%)\n",
            "\n",
            "  📈 full_train Summary (2 batches):\n",
            "    Total positives: 0.0\n",
            "    Total voxels: 1,769,472\n",
            "    Overall positive ratio: 0.000000 (0.0000%)\n",
            "\n",
            "============================================================\n",
            "📊 CHECKING DATA DISTRIBUTIONS\n",
            "============================================================\n",
            "\n",
            "📈 Training Intensity Distribution:\n",
            "  Range: [-1.1482, 1.1185]\n",
            "  Mean: -0.1980 ± 0.4781\n",
            "  Median: 0.0190\n",
            "  Non-zero values: 16,625,664/17,694,720 (93.96%)\n",
            "\n",
            "📈 Validation Intensity Distribution:\n",
            "  Range: [-1.0000, 1.0000]\n",
            "  Mean: 0.1440 ± 0.3960\n",
            "  Median: 0.2154\n",
            "  Non-zero values: 4,331,520/4,423,680 (97.92%)\n",
            "\n",
            "📈 Test Intensity Distribution:\n",
            "  Range: [-1.0000, 1.0000]\n",
            "  Mean: 0.2222 ± 0.3332\n",
            "  Median: 0.2294\n",
            "  Non-zero values: 4,368,384/4,423,680 (98.75%)\n",
            "\n",
            "============================================================\n",
            "📏 CHECKING SPATIAL CONSISTENCY\n",
            "============================================================\n",
            "\n",
            "📐 Training Spatial Properties:\n",
            "  Batch 0 shape: torch.Size([4, 1, 96, 96, 96])\n",
            "  Batch 1 shape: torch.Size([4, 1, 96, 96, 96])\n",
            "  Batch 2 shape: torch.Size([4, 1, 96, 96, 96])\n",
            "  ✅ All batches have consistent shape: torch.Size([96, 96, 96])\n",
            "\n",
            "📐 Validation Spatial Properties:\n",
            "  Batch 0 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  Batch 1 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  Batch 2 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  ✅ All batches have consistent shape: torch.Size([96, 96, 96])\n",
            "\n",
            "📐 Test Spatial Properties:\n",
            "  Batch 0 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  Batch 1 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  Batch 2 shape: torch.Size([1, 1, 96, 96, 96])\n",
            "  ✅ All batches have consistent shape: torch.Size([96, 96, 96])\n",
            "🚀 Starting pipeline with:\n",
            "   - Train samples: 340\n",
            "   - Valid samples: 43\n",
            "   - Test samples: 38\n",
            "   - Device: cuda\n",
            "   - Output directory: ./results/Results_Nifti_MONAI6_Original\n",
            "🎯 GPU Memory allocated: 0.00 GB\n",
            "🎯 GPU Memory cached: 0.00 GB\n",
            "Batch 0: pos=131591.0, neg=3407353.0, pos_ratio=0.037184\n",
            "Batch 1: pos=174415.0, neg=3364529.0, pos_ratio=0.049284\n",
            "Batch 2: pos=545627.0, neg=2993317.0, pos_ratio=0.154178\n",
            "Batch 3: pos=174128.0, neg=3364816.0, pos_ratio=0.049203\n",
            "Batch 4: pos=17732.0, neg=3521212.0, pos_ratio=0.005011\n",
            "Batch 5: pos=118703.0, neg=3420241.0, pos_ratio=0.033542\n",
            "Batch 6: pos=184197.0, neg=3354747.0, pos_ratio=0.052049\n",
            "Batch 7: pos=352390.0, neg=3186554.0, pos_ratio=0.099575\n",
            "Batch 8: pos=349831.0, neg=3189113.0, pos_ratio=0.098852\n",
            "Batch 9: pos=130384.0, neg=3408560.0, pos_ratio=0.036843\n",
            "Batch 10: pos=322156.0, neg=3216788.0, pos_ratio=0.091032\n",
            "Batch 11: pos=3900.0, neg=3535044.0, pos_ratio=0.001102\n",
            "Batch 12: pos=167144.0, neg=3371800.0, pos_ratio=0.047230\n",
            "Batch 13: pos=257595.0, neg=3281349.0, pos_ratio=0.072789\n",
            "Batch 14: pos=114040.0, neg=3424904.0, pos_ratio=0.032224\n",
            "Batch 15: pos=40358.0, neg=3498586.0, pos_ratio=0.011404\n",
            "Batch 16: pos=245108.0, neg=3293836.0, pos_ratio=0.069260\n",
            "Batch 17: pos=133360.0, neg=3405584.0, pos_ratio=0.037684\n",
            "Batch 18: pos=225820.0, neg=3313124.0, pos_ratio=0.063810\n",
            "Batch 19: pos=17076.0, neg=3521868.0, pos_ratio=0.004825\n",
            "Batch 20: pos=209087.0, neg=3329857.0, pos_ratio=0.059082\n",
            "Batch 21: pos=286694.0, neg=3252250.0, pos_ratio=0.081011\n",
            "Batch 22: pos=101807.0, neg=3437137.0, pos_ratio=0.028768\n",
            "Batch 23: pos=206880.0, neg=3332064.0, pos_ratio=0.058458\n",
            "Batch 24: pos=19368.0, neg=3519576.0, pos_ratio=0.005473\n",
            "Batch 25: pos=233881.0, neg=3305063.0, pos_ratio=0.066088\n",
            "Batch 26: pos=14347.0, neg=3524597.0, pos_ratio=0.004054\n",
            "Batch 27: pos=79598.0, neg=3459346.0, pos_ratio=0.022492\n",
            "Batch 28: pos=114720.0, neg=3424224.0, pos_ratio=0.032416\n",
            "Batch 29: pos=537351.0, neg=3001593.0, pos_ratio=0.151839\n",
            "Batch 30: pos=31947.0, neg=3506997.0, pos_ratio=0.009027\n",
            "Batch 31: pos=310791.0, neg=3228153.0, pos_ratio=0.087820\n",
            "Batch 32: pos=64372.0, neg=3474572.0, pos_ratio=0.018190\n",
            "Batch 33: pos=461763.0, neg=3077181.0, pos_ratio=0.130480\n",
            "Batch 34: pos=259448.0, neg=3279496.0, pos_ratio=0.073312\n",
            "Batch 35: pos=107009.0, neg=3431935.0, pos_ratio=0.030238\n",
            "Batch 36: pos=91680.0, neg=3447264.0, pos_ratio=0.025906\n",
            "Batch 37: pos=16286.0, neg=3522658.0, pos_ratio=0.004602\n",
            "Batch 38: pos=227982.0, neg=3310962.0, pos_ratio=0.064421\n",
            "Batch 39: pos=4944.0, neg=3534000.0, pos_ratio=0.001397\n",
            "Batch 40: pos=15133.0, neg=3523811.0, pos_ratio=0.004276\n",
            "Batch 41: pos=10944.0, neg=3528000.0, pos_ratio=0.003092\n",
            "Batch 42: pos=5472.0, neg=3533472.0, pos_ratio=0.001546\n",
            "Batch 43: pos=26922.0, neg=3512022.0, pos_ratio=0.007607\n",
            "Batch 44: pos=87987.0, neg=3450957.0, pos_ratio=0.024863\n",
            "Batch 45: pos=73593.0, neg=3465351.0, pos_ratio=0.020795\n",
            "Batch 46: pos=510101.0, neg=3028843.0, pos_ratio=0.144139\n",
            "Batch 47: pos=129249.0, neg=3409695.0, pos_ratio=0.036522\n",
            "Batch 48: pos=754439.0, neg=2784505.0, pos_ratio=0.213182\n",
            "Batch 49: pos=593839.0, neg=2945105.0, pos_ratio=0.167801\n",
            "Batch 50: pos=190039.0, neg=3348905.0, pos_ratio=0.053699\n",
            "Batch 51: pos=82241.0, neg=3456703.0, pos_ratio=0.023239\n",
            "Batch 52: pos=32866.0, neg=3506078.0, pos_ratio=0.009287\n",
            "Batch 53: pos=215139.0, neg=3323805.0, pos_ratio=0.060792\n",
            "Batch 54: pos=15771.0, neg=3523173.0, pos_ratio=0.004456\n",
            "Batch 55: pos=132865.0, neg=3406079.0, pos_ratio=0.037544\n",
            "Batch 56: pos=36672.0, neg=3502272.0, pos_ratio=0.010362\n",
            "Batch 57: pos=621934.0, neg=2917010.0, pos_ratio=0.175740\n",
            "Batch 58: pos=186779.0, neg=3352165.0, pos_ratio=0.052778\n",
            "Batch 59: pos=55726.0, neg=3483218.0, pos_ratio=0.015747\n",
            "Batch 60: pos=178463.0, neg=3360481.0, pos_ratio=0.050428\n",
            "Batch 61: pos=291259.0, neg=3247685.0, pos_ratio=0.082301\n",
            "Batch 62: pos=318218.0, neg=3220726.0, pos_ratio=0.089919\n",
            "Batch 63: pos=3324.0, neg=3535620.0, pos_ratio=0.000939\n",
            "Batch 64: pos=431788.0, neg=3107156.0, pos_ratio=0.122010\n",
            "Batch 65: pos=3192.0, neg=3535752.0, pos_ratio=0.000902\n",
            "Batch 66: pos=350293.0, neg=3188651.0, pos_ratio=0.098982\n",
            "Batch 67: pos=40726.0, neg=3498218.0, pos_ratio=0.011508\n",
            "Batch 68: pos=66544.0, neg=3472400.0, pos_ratio=0.018803\n",
            "Batch 69: pos=76302.0, neg=3462642.0, pos_ratio=0.021561\n",
            "Batch 70: pos=131489.0, neg=3407455.0, pos_ratio=0.037155\n",
            "Batch 71: pos=47683.0, neg=3491261.0, pos_ratio=0.013474\n",
            "Batch 72: pos=22365.0, neg=3516579.0, pos_ratio=0.006320\n",
            "Batch 73: pos=2760.0, neg=3536184.0, pos_ratio=0.000780\n",
            "Batch 74: pos=340942.0, neg=3198002.0, pos_ratio=0.096340\n",
            "Batch 75: pos=52975.0, neg=3485969.0, pos_ratio=0.014969\n",
            "Batch 76: pos=251520.0, neg=3287424.0, pos_ratio=0.071072\n",
            "Batch 77: pos=804848.0, neg=2734096.0, pos_ratio=0.227426\n",
            "Batch 78: pos=135234.0, neg=3403710.0, pos_ratio=0.038213\n",
            "Batch 79: pos=211068.0, neg=3327876.0, pos_ratio=0.059642\n",
            "Batch 80: pos=11110.0, neg=3527834.0, pos_ratio=0.003139\n",
            "Batch 81: pos=109568.0, neg=3429376.0, pos_ratio=0.030961\n",
            "Batch 82: pos=6492.0, neg=3532452.0, pos_ratio=0.001834\n",
            "Batch 83: pos=59992.0, neg=3478952.0, pos_ratio=0.016952\n",
            "Batch 84: pos=19404.0, neg=3519540.0, pos_ratio=0.005483\n",
            "Batch 85: pos=12672.0, neg=3526272.0, pos_ratio=0.003581\n",
            "Batch 86: pos=140158.0, neg=3398786.0, pos_ratio=0.039604\n",
            "Batch 87: pos=6859.0, neg=3532085.0, pos_ratio=0.001938\n",
            "Batch 88: pos=139041.0, neg=3399903.0, pos_ratio=0.039289\n",
            "Batch 89: pos=5967.0, neg=3532977.0, pos_ratio=0.001686\n",
            "Batch 90: pos=370033.0, neg=3168911.0, pos_ratio=0.104560\n",
            "Batch 91: pos=28973.0, neg=3509971.0, pos_ratio=0.008187\n",
            "Batch 92: pos=26435.0, neg=3512509.0, pos_ratio=0.007470\n",
            "Batch 93: pos=106246.0, neg=3432698.0, pos_ratio=0.030022\n",
            "Batch 94: pos=92647.0, neg=3446297.0, pos_ratio=0.026179\n",
            "Batch 95: pos=160129.0, neg=3378815.0, pos_ratio=0.045248\n",
            "Batch 96: pos=402149.0, neg=3136795.0, pos_ratio=0.113635\n",
            "Batch 97: pos=156280.0, neg=3382664.0, pos_ratio=0.044160\n",
            "Batch 98: pos=6012.0, neg=3532932.0, pos_ratio=0.001699\n",
            "Batch 99: pos=5880.0, neg=3533064.0, pos_ratio=0.001662\n",
            "Batch 100: pos=121766.0, neg=3417178.0, pos_ratio=0.034407\n",
            "Batch 101: pos=120351.0, neg=3418593.0, pos_ratio=0.034008\n",
            "Batch 102: pos=107680.0, neg=3431264.0, pos_ratio=0.030427\n",
            "Batch 103: pos=19793.0, neg=3519151.0, pos_ratio=0.005593\n",
            "Batch 104: pos=165203.0, neg=3373741.0, pos_ratio=0.046681\n",
            "Batch 105: pos=220224.0, neg=3318720.0, pos_ratio=0.062229\n",
            "Batch 106: pos=4452.0, neg=3534492.0, pos_ratio=0.001258\n",
            "Batch 107: pos=262919.0, neg=3276025.0, pos_ratio=0.074293\n",
            "Batch 108: pos=75236.0, neg=3463708.0, pos_ratio=0.021259\n",
            "Batch 109: pos=52602.0, neg=3486342.0, pos_ratio=0.014864\n",
            "Batch 110: pos=14940.0, neg=3524004.0, pos_ratio=0.004222\n",
            "Batch 111: pos=32046.0, neg=3506898.0, pos_ratio=0.009055\n",
            "Batch 112: pos=74212.0, neg=3464732.0, pos_ratio=0.020970\n",
            "Batch 113: pos=365856.0, neg=3173088.0, pos_ratio=0.103380\n",
            "Batch 114: pos=374017.0, neg=3164927.0, pos_ratio=0.105686\n",
            "Batch 115: pos=267385.0, neg=3271559.0, pos_ratio=0.075555\n",
            "Batch 116: pos=131735.0, neg=3407209.0, pos_ratio=0.037224\n",
            "Batch 117: pos=313594.0, neg=3225350.0, pos_ratio=0.088612\n",
            "Batch 118: pos=65510.0, neg=3473434.0, pos_ratio=0.018511\n",
            "Batch 119: pos=92022.0, neg=3446922.0, pos_ratio=0.026003\n",
            "Batch 120: pos=8028.0, neg=3530916.0, pos_ratio=0.002268\n",
            "Batch 121: pos=42909.0, neg=3496035.0, pos_ratio=0.012125\n",
            "Batch 122: pos=47801.0, neg=3491143.0, pos_ratio=0.013507\n",
            "Batch 123: pos=150955.0, neg=3387989.0, pos_ratio=0.042655\n",
            "Batch 124: pos=449812.0, neg=3089132.0, pos_ratio=0.127103\n",
            "Batch 125: pos=30369.0, neg=3508575.0, pos_ratio=0.008581\n",
            "Batch 126: pos=511243.0, neg=3027701.0, pos_ratio=0.144462\n",
            "Batch 127: pos=372939.0, neg=3166005.0, pos_ratio=0.105381\n",
            "Batch 128: pos=268555.0, neg=3270389.0, pos_ratio=0.075886\n",
            "Batch 129: pos=13881.0, neg=3525063.0, pos_ratio=0.003922\n",
            "Batch 130: pos=130007.0, neg=3408937.0, pos_ratio=0.036736\n",
            "Batch 131: pos=53227.0, neg=3485717.0, pos_ratio=0.015040\n",
            "Batch 132: pos=105554.0, neg=3433390.0, pos_ratio=0.029826\n",
            "Batch 133: pos=33795.0, neg=3505149.0, pos_ratio=0.009549\n",
            "Batch 134: pos=321933.0, neg=3217011.0, pos_ratio=0.090969\n",
            "Batch 135: pos=47745.0, neg=3491199.0, pos_ratio=0.013491\n",
            "Batch 136: pos=499426.0, neg=3039518.0, pos_ratio=0.141123\n",
            "Batch 137: pos=5556.0, neg=3533388.0, pos_ratio=0.001570\n",
            "Batch 138: pos=113488.0, neg=3425456.0, pos_ratio=0.032068\n",
            "Batch 139: pos=35313.0, neg=3503631.0, pos_ratio=0.009978\n",
            "Batch 140: pos=11112.0, neg=3527832.0, pos_ratio=0.003140\n",
            "Batch 141: pos=163226.0, neg=3375718.0, pos_ratio=0.046123\n",
            "Batch 142: pos=84891.0, neg=3454053.0, pos_ratio=0.023988\n",
            "Batch 143: pos=139514.0, neg=3399430.0, pos_ratio=0.039422\n",
            "Batch 144: pos=367179.0, neg=3171765.0, pos_ratio=0.103754\n",
            "Batch 145: pos=37127.0, neg=3501817.0, pos_ratio=0.010491\n",
            "Batch 146: pos=14460.0, neg=3524484.0, pos_ratio=0.004086\n",
            "Batch 147: pos=57639.0, neg=3481305.0, pos_ratio=0.016287\n",
            "Batch 148: pos=357019.0, neg=3181925.0, pos_ratio=0.100883\n",
            "Batch 149: pos=142332.0, neg=3396612.0, pos_ratio=0.040219\n",
            "Batch 150: pos=115405.0, neg=3423539.0, pos_ratio=0.032610\n",
            "Batch 151: pos=104578.0, neg=3434366.0, pos_ratio=0.029551\n",
            "Batch 152: pos=468993.0, neg=3069951.0, pos_ratio=0.132523\n",
            "Batch 153: pos=337107.0, neg=3201837.0, pos_ratio=0.095256\n",
            "Batch 154: pos=259980.0, neg=3278964.0, pos_ratio=0.073463\n",
            "Batch 155: pos=275865.0, neg=3263079.0, pos_ratio=0.077951\n",
            "Batch 156: pos=152818.0, neg=3386126.0, pos_ratio=0.043182\n",
            "Batch 157: pos=115017.0, neg=3423927.0, pos_ratio=0.032500\n",
            "Batch 158: pos=12308.0, neg=3526636.0, pos_ratio=0.003478\n",
            "Batch 159: pos=20176.0, neg=3518768.0, pos_ratio=0.005701\n",
            "Batch 160: pos=15175.0, neg=3523769.0, pos_ratio=0.004288\n",
            "Batch 161: pos=43237.0, neg=3495707.0, pos_ratio=0.012217\n",
            "Batch 162: pos=23624.0, neg=3515320.0, pos_ratio=0.006675\n",
            "Batch 163: pos=56501.0, neg=3482443.0, pos_ratio=0.015965\n",
            "Batch 164: pos=98703.0, neg=3440241.0, pos_ratio=0.027891\n",
            "Batch 165: pos=37271.0, neg=3501673.0, pos_ratio=0.010532\n",
            "Batch 166: pos=65435.0, neg=3473509.0, pos_ratio=0.018490\n",
            "Batch 167: pos=261993.0, neg=3276951.0, pos_ratio=0.074031\n",
            "Batch 168: pos=8858.0, neg=3530086.0, pos_ratio=0.002503\n",
            "Batch 169: pos=237773.0, neg=3301171.0, pos_ratio=0.067188\n",
            "Batch 170: pos=19029.0, neg=3519915.0, pos_ratio=0.005377\n",
            "Batch 171: pos=205973.0, neg=3332971.0, pos_ratio=0.058202\n",
            "Batch 172: pos=8911.0, neg=3530033.0, pos_ratio=0.002518\n",
            "Batch 173: pos=33316.0, neg=3505628.0, pos_ratio=0.009414\n",
            "Batch 174: pos=68119.0, neg=3470825.0, pos_ratio=0.019248\n",
            "Batch 175: pos=43885.0, neg=3495059.0, pos_ratio=0.012401\n",
            "Batch 176: pos=18062.0, neg=3520882.0, pos_ratio=0.005104\n",
            "Batch 177: pos=282617.0, neg=3256327.0, pos_ratio=0.079859\n",
            "Batch 178: pos=10308.0, neg=3528636.0, pos_ratio=0.002913\n",
            "Batch 179: pos=311760.0, neg=3227184.0, pos_ratio=0.088094\n",
            "Batch 180: pos=137383.0, neg=3401561.0, pos_ratio=0.038820\n",
            "Batch 181: pos=39139.0, neg=3499805.0, pos_ratio=0.011060\n",
            "Batch 182: pos=181556.0, neg=3357388.0, pos_ratio=0.051302\n",
            "Batch 183: pos=301884.0, neg=3237060.0, pos_ratio=0.085303\n",
            "Batch 184: pos=66028.0, neg=3472916.0, pos_ratio=0.018658\n",
            "Batch 185: pos=227744.0, neg=3311200.0, pos_ratio=0.064354\n",
            "Batch 186: pos=42488.0, neg=3496456.0, pos_ratio=0.012006\n",
            "Batch 187: pos=142343.0, neg=3396601.0, pos_ratio=0.040222\n",
            "Batch 188: pos=33631.0, neg=3505313.0, pos_ratio=0.009503\n",
            "Batch 189: pos=19263.0, neg=3519681.0, pos_ratio=0.005443\n",
            "Batch 190: pos=23634.0, neg=3515310.0, pos_ratio=0.006678\n",
            "Batch 191: pos=242498.0, neg=3296446.0, pos_ratio=0.068523\n",
            "Batch 192: pos=175856.0, neg=3363088.0, pos_ratio=0.049692\n",
            "Batch 193: pos=202514.0, neg=3336430.0, pos_ratio=0.057224\n",
            "Batch 194: pos=96444.0, neg=3442500.0, pos_ratio=0.027252\n",
            "Batch 195: pos=51023.0, neg=3487921.0, pos_ratio=0.014418\n",
            "Batch 196: pos=165701.0, neg=3373243.0, pos_ratio=0.046822\n",
            "Batch 197: pos=234353.0, neg=3304591.0, pos_ratio=0.066221\n",
            "Batch 198: pos=41982.0, neg=3496962.0, pos_ratio=0.011863\n",
            "Batch 199: pos=123436.0, neg=3415508.0, pos_ratio=0.034879\n",
            "Batch 200: pos=96365.0, neg=3442579.0, pos_ratio=0.027230\n",
            "Batch 201: pos=66645.0, neg=3472299.0, pos_ratio=0.018832\n",
            "Batch 202: pos=106575.0, neg=3432369.0, pos_ratio=0.030115\n",
            "Batch 203: pos=94574.0, neg=3444370.0, pos_ratio=0.026724\n",
            "Batch 204: pos=19125.0, neg=3519819.0, pos_ratio=0.005404\n",
            "Batch 205: pos=598042.0, neg=2940902.0, pos_ratio=0.168989\n",
            "Batch 206: pos=64811.0, neg=3474133.0, pos_ratio=0.018314\n",
            "Batch 207: pos=173087.0, neg=3365857.0, pos_ratio=0.048909\n",
            "Batch 208: pos=88585.0, neg=3450359.0, pos_ratio=0.025031\n",
            "Batch 209: pos=85750.0, neg=3453194.0, pos_ratio=0.024230\n",
            "Batch 210: pos=97648.0, neg=3441296.0, pos_ratio=0.027592\n",
            "Batch 211: pos=60840.0, neg=3478104.0, pos_ratio=0.017192\n",
            "Batch 212: pos=115384.0, neg=3423560.0, pos_ratio=0.032604\n",
            "Batch 213: pos=196602.0, neg=3342342.0, pos_ratio=0.055554\n",
            "Batch 214: pos=171164.0, neg=3367780.0, pos_ratio=0.048366\n",
            "Batch 215: pos=22837.0, neg=3516107.0, pos_ratio=0.006453\n",
            "Batch 216: pos=47481.0, neg=3491463.0, pos_ratio=0.013417\n",
            "Batch 217: pos=631415.0, neg=2907529.0, pos_ratio=0.178419\n",
            "Batch 218: pos=43089.0, neg=3495855.0, pos_ratio=0.012176\n",
            "Batch 219: pos=350196.0, neg=3188748.0, pos_ratio=0.098955\n",
            "Batch 220: pos=457635.0, neg=3081309.0, pos_ratio=0.129314\n",
            "Batch 221: pos=6827.0, neg=3532117.0, pos_ratio=0.001929\n",
            "Batch 222: pos=24301.0, neg=3514643.0, pos_ratio=0.006867\n",
            "Batch 223: pos=46917.0, neg=3492027.0, pos_ratio=0.013257\n",
            "Batch 224: pos=374045.0, neg=3164899.0, pos_ratio=0.105694\n",
            "Batch 225: pos=55937.0, neg=3483007.0, pos_ratio=0.015806\n",
            "Batch 226: pos=58334.0, neg=3480610.0, pos_ratio=0.016483\n",
            "Batch 227: pos=34538.0, neg=3504406.0, pos_ratio=0.009759\n",
            "Batch 228: pos=32998.0, neg=3505946.0, pos_ratio=0.009324\n",
            "Batch 229: pos=3120.0, neg=3535824.0, pos_ratio=0.000882\n",
            "Batch 230: pos=302324.0, neg=3236620.0, pos_ratio=0.085428\n",
            "Batch 231: pos=32506.0, neg=3506438.0, pos_ratio=0.009185\n",
            "Batch 232: pos=251308.0, neg=3287636.0, pos_ratio=0.071012\n",
            "Batch 233: pos=170946.0, neg=3367998.0, pos_ratio=0.048304\n",
            "Batch 234: pos=13252.0, neg=3525692.0, pos_ratio=0.003745\n",
            "Batch 235: pos=23726.0, neg=3515218.0, pos_ratio=0.006704\n",
            "Batch 236: pos=21324.0, neg=3517620.0, pos_ratio=0.006026\n",
            "Batch 237: pos=40909.0, neg=3498035.0, pos_ratio=0.011560\n",
            "Batch 238: pos=2100.0, neg=3536844.0, pos_ratio=0.000593\n",
            "Batch 239: pos=358837.0, neg=3180107.0, pos_ratio=0.101397\n",
            "Batch 240: pos=78698.0, neg=3460246.0, pos_ratio=0.022238\n",
            "Batch 241: pos=253242.0, neg=3285702.0, pos_ratio=0.071559\n",
            "Batch 242: pos=224030.0, neg=3314914.0, pos_ratio=0.063304\n",
            "Batch 243: pos=146648.0, neg=3392296.0, pos_ratio=0.041438\n",
            "Batch 244: pos=16244.0, neg=3522700.0, pos_ratio=0.004590\n",
            "Batch 245: pos=68309.0, neg=3470635.0, pos_ratio=0.019302\n",
            "Batch 246: pos=77958.0, neg=3460986.0, pos_ratio=0.022029\n",
            "Batch 247: pos=119911.0, neg=3419033.0, pos_ratio=0.033883\n",
            "Batch 248: pos=152031.0, neg=3386913.0, pos_ratio=0.042959\n",
            "Batch 249: pos=62082.0, neg=3476862.0, pos_ratio=0.017543\n",
            "Batch 250: pos=260575.0, neg=3278369.0, pos_ratio=0.073631\n",
            "Batch 251: pos=198449.0, neg=3340495.0, pos_ratio=0.056076\n",
            "Batch 252: pos=512996.0, neg=3025948.0, pos_ratio=0.144957\n",
            "Batch 253: pos=103915.0, neg=3435029.0, pos_ratio=0.029363\n",
            "Batch 254: pos=69548.0, neg=3469396.0, pos_ratio=0.019652\n",
            "Batch 255: pos=133644.0, neg=3405300.0, pos_ratio=0.037764\n",
            "Batch 256: pos=292684.0, neg=3246260.0, pos_ratio=0.082704\n",
            "Batch 257: pos=276830.0, neg=3262114.0, pos_ratio=0.078224\n",
            "Batch 258: pos=12642.0, neg=3526302.0, pos_ratio=0.003572\n",
            "Batch 259: pos=131071.0, neg=3407873.0, pos_ratio=0.037037\n",
            "Batch 260: pos=31433.0, neg=3507511.0, pos_ratio=0.008882\n",
            "Batch 261: pos=35946.0, neg=3502998.0, pos_ratio=0.010157\n",
            "Batch 262: pos=51761.0, neg=3487183.0, pos_ratio=0.014626\n",
            "Batch 263: pos=173870.0, neg=3365074.0, pos_ratio=0.049130\n",
            "Batch 264: pos=160928.0, neg=3378016.0, pos_ratio=0.045473\n",
            "Batch 265: pos=196273.0, neg=3342671.0, pos_ratio=0.055461\n",
            "Batch 266: pos=12152.0, neg=3526792.0, pos_ratio=0.003434\n",
            "Batch 267: pos=30498.0, neg=3508446.0, pos_ratio=0.008618\n",
            "Batch 268: pos=14250.0, neg=3524694.0, pos_ratio=0.004027\n",
            "Batch 269: pos=233260.0, neg=3305684.0, pos_ratio=0.065912\n",
            "Batch 270: pos=94064.0, neg=3444880.0, pos_ratio=0.026580\n",
            "Batch 271: pos=39691.0, neg=3499253.0, pos_ratio=0.011215\n",
            "Batch 272: pos=25205.0, neg=3513739.0, pos_ratio=0.007122\n",
            "Batch 273: pos=57810.0, neg=3481134.0, pos_ratio=0.016335\n",
            "Batch 274: pos=152775.0, neg=3386169.0, pos_ratio=0.043170\n",
            "Batch 275: pos=4008.0, neg=3534936.0, pos_ratio=0.001133\n",
            "Batch 276: pos=132101.0, neg=3406843.0, pos_ratio=0.037328\n",
            "Batch 277: pos=18662.0, neg=3520282.0, pos_ratio=0.005273\n",
            "Batch 278: pos=75020.0, neg=3463924.0, pos_ratio=0.021198\n",
            "Batch 279: pos=93761.0, neg=3445183.0, pos_ratio=0.026494\n",
            "Batch 280: pos=75192.0, neg=3463752.0, pos_ratio=0.021247\n",
            "Batch 281: pos=12516.0, neg=3526428.0, pos_ratio=0.003537\n",
            "Batch 282: pos=290970.0, neg=3247974.0, pos_ratio=0.082219\n",
            "Batch 283: pos=253708.0, neg=3285236.0, pos_ratio=0.071690\n",
            "Batch 284: pos=22504.0, neg=3516440.0, pos_ratio=0.006359\n",
            "Batch 285: pos=13944.0, neg=3525000.0, pos_ratio=0.003940\n",
            "Batch 286: pos=53720.0, neg=3485224.0, pos_ratio=0.015180\n",
            "Batch 287: pos=95909.0, neg=3443035.0, pos_ratio=0.027101\n",
            "Batch 288: pos=519482.0, neg=3019462.0, pos_ratio=0.146790\n",
            "Batch 289: pos=56543.0, neg=3482401.0, pos_ratio=0.015977\n",
            "Batch 290: pos=201541.0, neg=3337403.0, pos_ratio=0.056949\n",
            "Batch 291: pos=10627.0, neg=3417725.0, pos_ratio=0.003100\n",
            "Batch 292: pos=201214.0, neg=3337730.0, pos_ratio=0.056857\n",
            "Batch 293: pos=174820.0, neg=3364124.0, pos_ratio=0.049399\n",
            "Batch 294: pos=36734.0, neg=3502210.0, pos_ratio=0.010380\n",
            "Batch 295: pos=10704.0, neg=3528240.0, pos_ratio=0.003025\n",
            "Batch 296: pos=254834.0, neg=3284110.0, pos_ratio=0.072008\n",
            "Batch 297: pos=38837.0, neg=3500107.0, pos_ratio=0.010974\n",
            "Batch 298: pos=375849.0, neg=3163095.0, pos_ratio=0.106204\n",
            "Batch 299: pos=140894.0, neg=3398050.0, pos_ratio=0.039812\n",
            "Batch 300: pos=127009.0, neg=3411935.0, pos_ratio=0.035889\n",
            "Batch 301: pos=19725.0, neg=3519219.0, pos_ratio=0.005574\n",
            "Batch 302: pos=28883.0, neg=3510061.0, pos_ratio=0.008161\n",
            "Batch 303: pos=151658.0, neg=3387286.0, pos_ratio=0.042854\n",
            "Batch 304: pos=2844.0, neg=3536100.0, pos_ratio=0.000804\n",
            "Batch 305: pos=639976.0, neg=2898968.0, pos_ratio=0.180838\n",
            "Batch 306: pos=26380.0, neg=3512564.0, pos_ratio=0.007454\n",
            "Batch 307: pos=18437.0, neg=3520507.0, pos_ratio=0.005210\n",
            "Batch 308: pos=133574.0, neg=3405370.0, pos_ratio=0.037744\n",
            "Batch 309: pos=306009.0, neg=3232935.0, pos_ratio=0.086469\n",
            "Batch 310: pos=291566.0, neg=3247378.0, pos_ratio=0.082388\n",
            "Batch 311: pos=101228.0, neg=3437716.0, pos_ratio=0.028604\n",
            "Batch 312: pos=233396.0, neg=3305548.0, pos_ratio=0.065951\n",
            "Batch 313: pos=317001.0, neg=3221943.0, pos_ratio=0.089575\n",
            "Batch 314: pos=13526.0, neg=3525418.0, pos_ratio=0.003822\n",
            "Batch 315: pos=15560.0, neg=3523384.0, pos_ratio=0.004397\n",
            "Batch 316: pos=136438.0, neg=3402506.0, pos_ratio=0.038553\n",
            "Batch 317: pos=221193.0, neg=3317751.0, pos_ratio=0.062503\n",
            "Batch 318: pos=136032.0, neg=3402912.0, pos_ratio=0.038439\n",
            "Batch 319: pos=45044.0, neg=3493900.0, pos_ratio=0.012728\n",
            "Batch 320: pos=44296.0, neg=3494648.0, pos_ratio=0.012517\n",
            "Batch 321: pos=110421.0, neg=3428523.0, pos_ratio=0.031202\n",
            "Batch 322: pos=62553.0, neg=3476391.0, pos_ratio=0.017676\n",
            "Batch 323: pos=98544.0, neg=3440400.0, pos_ratio=0.027846\n",
            "Batch 324: pos=68830.0, neg=3470114.0, pos_ratio=0.019449\n",
            "Batch 325: pos=73689.0, neg=3465255.0, pos_ratio=0.020822\n",
            "Batch 326: pos=266872.0, neg=3272072.0, pos_ratio=0.075410\n",
            "Batch 327: pos=377934.0, neg=3161010.0, pos_ratio=0.106793\n",
            "Batch 328: pos=358244.0, neg=3180700.0, pos_ratio=0.101229\n",
            "Batch 329: pos=55557.0, neg=3483387.0, pos_ratio=0.015699\n",
            "Batch 330: pos=11460.0, neg=3527484.0, pos_ratio=0.003238\n",
            "Batch 331: pos=103660.0, neg=3435284.0, pos_ratio=0.029291\n",
            "Batch 332: pos=13080.0, neg=3525864.0, pos_ratio=0.003696\n",
            "Batch 333: pos=467163.0, neg=3071781.0, pos_ratio=0.132006\n",
            "Batch 334: pos=520418.0, neg=3018526.0, pos_ratio=0.147055\n",
            "Batch 335: pos=174141.0, neg=3364803.0, pos_ratio=0.049207\n",
            "Batch 336: pos=352695.0, neg=3186249.0, pos_ratio=0.099661\n",
            "Batch 337: pos=268903.0, neg=3270041.0, pos_ratio=0.075984\n",
            "Batch 338: pos=3960.0, neg=3534984.0, pos_ratio=0.001119\n",
            "Batch 339: pos=51623.0, neg=3487321.0, pos_ratio=0.014587\n",
            "📊 Final Stats:\n",
            "  Total pos voxels: 49807674.0\n",
            "  Total neg voxels: 1153322694.0\n",
            "  Positive ratio: 0.041398 (4.1398%)\n",
            "  Computed pos_weight: 23.1555\n",
            "💾 Saved pos_weight: 23.1555\n",
            "📊 Using reasonable pos_weight: 23.16 (capped from 23.16)\n",
            "  Batch 50/340, Loss: 0.8625\n",
            "  Batch 100/340, Loss: 0.8484\n",
            "  Batch 150/340, Loss: 0.8505\n",
            "  Batch 200/340, Loss: 0.9024\n",
            "  Batch 250/340, Loss: 0.8396\n",
            "❌ Pipeline failed: Sizes of tensors must match except in dimension 1. Expected size 47 but got size 48 for tensor number 1 in the list.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 47 but got size 48 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1790582725.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1790582725.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnetPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1790582725.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1790582725.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         )\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2429812682.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             train_loss = self.train_one_epoch(\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-2429812682.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, model, loader, optimizer, scheduler, accumulation_steps, loss_fn)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/networks/nets/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/networks/layers/simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/data/meta_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;31m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# if \"out\" in kwargs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 47 but got size 48 for tensor number 1 in the list."
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        set_determinism(seed=42)\n",
        "\n",
        "        # Setup paths\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "        # Prepare loaders\n",
        "        print(\"📦 Preparing datasets and transforms...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader, self.full_train_loader = self.prepare_loaders()\n",
        "        self.debug_model_shapes()\n",
        "        # Dataset quality analysis\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 RUNNING DATASET QUALITY ANALYSIS...\")\n",
        "        print(\"=\"*60)\n",
        "        self.analyze_dataset_quality()\n",
        "\n",
        "        # 🔥 ADD COMPREHENSIVE SANITY CHECKS\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        print(\"=\"*60)\n",
        "        self.check_data_sanity(max_batches=2)\n",
        "        self.check_data_distributions()\n",
        "        self.check_spatial_consistency()\n",
        "\n",
        "    def analyze_dataset_quality(self):\n",
        "        \"\"\"Comprehensive dataset quality analysis\"\"\"\n",
        "        print(\"📊 Analyzing dataset quality...\")\n",
        "\n",
        "        # Analyze full volumes (before patch sampling)\n",
        "        self._analyze_loader_quality(self.full_train_loader, \"TRAIN (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.valid_loader, \"VALID (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.test_loader, \"TEST (Full Volumes)\")\n",
        "\n",
        "        # Analyze training patches (after patch sampling)\n",
        "        print(\"\\n\" + \"🔍 Analyzing Training Patches (After Sampling):\")\n",
        "        self._analyze_patch_quality(self.train_loader, \"TRAIN PATCHES\")\n",
        "\n",
        "    def debug_model_shapes(self):\n",
        "        \"\"\"Debug method to identify shape mismatches between model and data\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 DEBUGGING MODEL SHAPES\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Get a sample batch\n",
        "        sample_batch = next(iter(self.train_loader))\n",
        "        images, segs = sample_batch[\"vol\"], sample_batch[\"seg\"]\n",
        "        print(f\"📐 Input data shape: {images.shape}\")\n",
        "        print(f\"🎯 Target segmentation shape: {segs.shape}\")\n",
        "\n",
        "        # Test current model configuration\n",
        "        from monai.networks.nets import UNet\n",
        "\n",
        "        current_model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "        ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = current_model(images)\n",
        "            print(f\"🤖 Current model output shape: {output.shape}\")\n",
        "\n",
        "            # Check for mismatch\n",
        "            if output.shape[2:] != segs.shape[2:]:\n",
        "                print(f\"❌ SHAPE MISMATCH DETECTED!\")\n",
        "                print(f\"   Model output: {output.shape[2:]}\")\n",
        "                print(f\"   Target: {segs.shape[2:]}\")\n",
        "                print(f\"   Difference: {tuple(o-t for o,t in zip(output.shape[2:], segs.shape[2:]))}\")\n",
        "            else:\n",
        "                print(\"✅ Shapes match perfectly!\")\n",
        "\n",
        "        return output.shape, segs.shape\n",
        "\n",
        "\n",
        "    def _analyze_loader_quality(self, loader, name: str):\n",
        "        \"\"\"Analyze a specific data loader\"\"\"\n",
        "        print(f\"\\n📊 {name} Dataset Analysis:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        total_volumes = 0\n",
        "        volumes_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each volume in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                volume_seg = seg[i]\n",
        "                total_volumes += 1\n",
        "                volume_positives = volume_seg.sum().item()\n",
        "                volume_voxels = volume_seg.numel()\n",
        "\n",
        "                if volume_positives > 0:\n",
        "                    volumes_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += volume_positives\n",
        "                total_voxels += volume_voxels\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"  Total volumes: {total_volumes}\")\n",
        "        print(f\"  Volumes with positives: {volumes_with_positives} ({volumes_with_positives/total_volumes*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Total positive voxels: {total_pos_voxels:,}\")\n",
        "        print(f\"  Total voxels: {total_voxels:,}\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def _analyze_patch_quality(self, loader, name: str, max_batches: int = 20):\n",
        "        \"\"\"Analyze patch distribution in training loader\"\"\"\n",
        "        print(f\"\\n📊 {name} Patch Analysis (first {max_batches} batches):\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        total_patches = 0\n",
        "        patches_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            if batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each patch in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                patch_seg = seg[i]\n",
        "                total_patches += 1\n",
        "                patch_positives = patch_seg.sum().item()\n",
        "                patch_voxels = patch_seg.numel()\n",
        "\n",
        "                if patch_positives > 0:\n",
        "                    patches_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += patch_positives\n",
        "                total_voxels += patch_voxels\n",
        "\n",
        "                pos_ratio = patch_positives / patch_voxels if patch_voxels > 0 else 0\n",
        "                if patch_positives > 0:  # Only print patches with positives for clarity\n",
        "                    print(f\"  Batch {batch_idx}, Patch {i}: {patch_positives}/{patch_voxels} \"\n",
        "                          f\"({pos_ratio*100:.3f}% positive)\")\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"\\n📈 {name} Patch Summary:\")\n",
        "        print(f\"  Total patches analyzed: {total_patches}\")\n",
        "        print(f\"  Patches with positives: {patches_with_positives} ({patches_with_positives/total_patches*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def check_data_sanity(self, max_batches: int = 3):\n",
        "        \"\"\"Comprehensive data sanity checks for all loaders\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check training data\n",
        "        print(\"\\n📊 TRAINING DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.train_loader, \"train\", max_batches)\n",
        "\n",
        "        # Check validation data\n",
        "        print(\"\\n📊 VALIDATION DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.valid_loader, \"valid\", max_batches)\n",
        "\n",
        "        # Check test data\n",
        "        print(\"\\n📊 TEST DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.test_loader, \"test\", max_batches)\n",
        "\n",
        "        # Check full volumes (before patch sampling)\n",
        "        print(\"\\n📊 FULL VOLUME SANITY CHECK (Before Patch Sampling):\")\n",
        "        self._check_loader_sanity(self.full_train_loader, \"full_train\", max_batches)\n",
        "\n",
        "    def _check_loader_sanity(self, loader, name: str, max_batches: int):\n",
        "        \"\"\"Check a specific loader for data sanity\"\"\"\n",
        "        print(f\"🔍 Checking {name} loader...\")\n",
        "\n",
        "        batch_count = 0\n",
        "        total_positives = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "\n",
        "            vol = batch[\"vol\"]\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            print(f\"\\n  Batch {i}:\")\n",
        "            print(f\"    Volume shape: {vol.shape}\")\n",
        "            print(f\"    Volume range: [{vol.min():.4f}, {vol.max():.4f}]\")\n",
        "            print(f\"    Volume mean: {vol.mean():.4f} ± {vol.std():.4f}\")\n",
        "            print(f\"    Segmentation shape: {seg.shape}\")\n",
        "            print(f\"    Segmentation unique values: {torch.unique(seg)}\")\n",
        "\n",
        "            # Check for NaNs or Infs\n",
        "            if torch.isnan(vol).any():\n",
        "                print(\"    ⚠️ WARNING: Volume contains NaN values!\")\n",
        "            if torch.isinf(vol).any():\n",
        "                print(\"    ⚠️ WARNING: Volume contains Inf values!\")\n",
        "\n",
        "            # Check segmentation values are binary\n",
        "            unique_vals = torch.unique(seg)\n",
        "            if not all(val in [0, 1] for val in unique_vals):\n",
        "                print(f\"    ⚠️ WARNING: Segmentation has non-binary values: {unique_vals}\")\n",
        "\n",
        "            # Calculate positives\n",
        "            batch_positives = seg.sum().item()\n",
        "            batch_voxels = seg.numel()\n",
        "            pos_ratio = batch_positives / batch_voxels if batch_voxels > 0 else 0\n",
        "\n",
        "            print(f\"    Positives: {batch_positives:,}/{batch_voxels:,} ({pos_ratio*100:.4f}%)\")\n",
        "\n",
        "            total_positives += batch_positives\n",
        "            total_voxels += batch_voxels\n",
        "            batch_count += 1\n",
        "\n",
        "        # Summary for this loader\n",
        "        if batch_count > 0:\n",
        "            overall_ratio = total_positives / total_voxels if total_voxels > 0 else 0\n",
        "            print(f\"\\n  📈 {name} Summary ({batch_count} batches):\")\n",
        "            print(f\"    Total positives: {total_positives:,}\")\n",
        "            print(f\"    Total voxels: {total_voxels:,}\")\n",
        "            print(f\"    Overall positive ratio: {overall_ratio:.6f} ({overall_ratio*100:.4f}%)\")\n",
        "\n",
        "    def check_data_distributions(self):\n",
        "        \"\"\"Check intensity distributions and data consistency\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📊 CHECKING DATA DISTRIBUTIONS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check intensity distributions\n",
        "        self._check_intensity_distribution(self.train_loader, \"Training\")\n",
        "        self._check_intensity_distribution(self.valid_loader, \"Validation\")\n",
        "        self._check_intensity_distribution(self.test_loader, \"Test\")\n",
        "\n",
        "    def _check_intensity_distribution(self, loader, name: str):\n",
        "        \"\"\"Check intensity distribution for a loader\"\"\"\n",
        "        print(f\"\\n📈 {name} Intensity Distribution:\")\n",
        "\n",
        "        all_values = []\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= 5:  # Check first 5 batches for speed\n",
        "                break\n",
        "            vol = batch[\"vol\"]\n",
        "            all_values.extend(vol.flatten().cpu().numpy())\n",
        "\n",
        "        if all_values:\n",
        "            all_values = np.array(all_values)\n",
        "            print(f\"  Range: [{np.min(all_values):.4f}, {np.max(all_values):.4f}]\")\n",
        "            print(f\"  Mean: {np.mean(all_values):.4f} ± {np.std(all_values):.4f}\")\n",
        "            print(f\"  Median: {np.median(all_values):.4f}\")\n",
        "            print(f\"  Non-zero values: {np.sum(all_values != 0):,}/{len(all_values):,} \"\n",
        "                  f\"({np.sum(all_values != 0)/len(all_values)*100:.2f}%)\")\n",
        "\n",
        "    def check_spatial_consistency(self):\n",
        "        \"\"\"Check that all volumes have consistent spatial properties\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📏 CHECKING SPATIAL CONSISTENCY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        loaders = {\n",
        "            \"Training\": self.train_loader,\n",
        "            \"Validation\": self.valid_loader,\n",
        "            \"Test\": self.test_loader\n",
        "        }\n",
        "\n",
        "        for name, loader in loaders.items():\n",
        "            print(f\"\\n📐 {name} Spatial Properties:\")\n",
        "            shapes = []\n",
        "            for i, batch in enumerate(loader):\n",
        "                if i >= 3:  # Check first 3 batches\n",
        "                    break\n",
        "                vol = batch[\"vol\"]\n",
        "                shapes.append(vol.shape[2:])  # Get spatial dimensions (D, H, W)\n",
        "                print(f\"  Batch {i} shape: {vol.shape}\")\n",
        "\n",
        "            # Check consistency\n",
        "            if len(shapes) > 1:\n",
        "                if all(shape == shapes[0] for shape in shapes):\n",
        "                    print(f\"  ✅ All batches have consistent shape: {shapes[0]}\")\n",
        "                else:\n",
        "                    print(f\"  ⚠️ Shape inconsistency: {shapes}\")\n",
        "\n",
        "    def filter_empty_samples(self, file_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Remove samples that have no positive segmentation labels\"\"\"\n",
        "        filtered_files = []\n",
        "\n",
        "        for file_pair in file_list:\n",
        "            # Load just the segmentation to check if it's empty\n",
        "            seg_loader = Compose([\n",
        "                LoadImaged(keys=[\"seg\"]),\n",
        "                EnsureChannelFirstd(keys=[\"seg\"]),\n",
        "            ])\n",
        "\n",
        "            try:\n",
        "                seg_data = seg_loader(file_pair)[\"seg\"]\n",
        "                if seg_data.sum() > 0:  # Only keep if has positive voxels\n",
        "                    filtered_files.append(file_pair)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error loading {file_pair['seg']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"📊 Filtered {len(file_list)} -> {len(filtered_files)} non-empty samples\")\n",
        "        return filtered_files\n",
        "\n",
        "    def prepare_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader]:\n",
        "        \"\"\"Prepare data loaders for training, validation, and testing\"\"\"\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        patch_size = (96, 96, 96)\n",
        "\n",
        "        def get_files(split: str) -> List[Dict]:\n",
        "            \"\"\"Get file paths for a specific split with validation\"\"\"\n",
        "            ct_dir = os.path.join(self.dataset_dir, split, \"ct\")\n",
        "            seg_dir = os.path.join(self.dataset_dir, split, \"segment\")\n",
        "\n",
        "            # Validate directories exist\n",
        "            if not os.path.exists(ct_dir):\n",
        "                raise FileNotFoundError(f\"CT directory not found: {ct_dir}\")\n",
        "            if not os.path.exists(seg_dir):\n",
        "                raise FileNotFoundError(f\"Segmentation directory not found: {seg_dir}\")\n",
        "\n",
        "            ct_files = sorted(glob(os.path.join(ct_dir, \"*.nii.gz\")))\n",
        "            seg_files = sorted(glob(os.path.join(seg_dir, \"*.nii.gz\")))\n",
        "\n",
        "            if len(ct_files) == 0:\n",
        "                raise RuntimeError(f\"No CT files found in {ct_dir}\")\n",
        "            if len(seg_files) == 0:\n",
        "                raise RuntimeError(f\"No segmentation files found in {seg_dir}\")\n",
        "            if len(ct_files) != len(seg_files):\n",
        "                raise RuntimeError(f\"Mismatch CT/SEG for {split}: {len(ct_files)} vs {len(seg_files)}\")\n",
        "\n",
        "            # Create file pairs\n",
        "            files = []\n",
        "            for ct_file, seg_file in zip(ct_files, seg_files):\n",
        "                # Verify file correspondence\n",
        "                ct_id = os.path.basename(ct_file).replace('.nii.gz', '')\n",
        "                seg_id = os.path.basename(seg_file).replace('.nii.gz', '')\n",
        "                if ct_id != seg_id:\n",
        "                    print(f\"⚠️ Warning: File name mismatch - CT: {ct_id}, SEG: {seg_id}\")\n",
        "                files.append({\"vol\": ct_file, \"seg\": seg_file})\n",
        "\n",
        "            # Filter out empty samples for training\n",
        "            if split == \"train\":\n",
        "                files = self.filter_empty_samples(files)\n",
        "\n",
        "            print(f\"📁 {split}: Loaded {len(files)} samples\")\n",
        "            return files\n",
        "\n",
        "        # Common base transforms for ALL datasets\n",
        "        base_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),  # allow_smaller=True by default\n",
        "            ResizeWithPadOrCropd(keys=[\"vol\", \"seg\"], spatial_size=patch_size, mode=\"constant\"),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\",\"seg\"], track_meta=True),\n",
        "        ])\n",
        "\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\", margin=10),  # allow_smaller=True by default\n",
        "\n",
        "            RandCropByPosNegLabeld(\n",
        "                keys=[\"vol\", \"seg\"],\n",
        "                label_key=\"seg\",\n",
        "                spatial_size=patch_size,  # Now (96,96,96)\n",
        "                pos=1.0,\n",
        "                neg=0.0,\n",
        "                num_samples=4,\n",
        "                image_key=\"vol\",\n",
        "                image_threshold=0,\n",
        "                allow_smaller=True,  # ← Keep this as True\n",
        "            ),\n",
        "\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=[0, 1, 2]),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.05),\n",
        "\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\", \"seg\"]),\n",
        "        ])\n",
        "\n",
        "        # Create datasets with optimized cache rates for 3D data\n",
        "        print(\"🔄 Loading training dataset...\")\n",
        "        train_ds = CacheDataset(\n",
        "            data=get_files(\"train\"),\n",
        "            transform=train_transforms,\n",
        "            cache_rate=0.1,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        print(\"🔄 Loading validation dataset...\")\n",
        "        valid_ds = CacheDataset(\n",
        "            data=get_files(\"valid\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        print(\"🔄 Loading test dataset...\")\n",
        "        test_ds = CacheDataset(\n",
        "            data=get_files(\"test\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        # Create data loaders with optimized settings\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=True,\n",
        "            num_workers=min(4, os.cpu_count() // 2),  # Adaptive worker count\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            persistent_workers=True,\n",
        "            prefetch_factor=2,\n",
        "            collate_fn=pad_list_data_collate,\n",
        "            drop_last=True  # Avoid partial batches\n",
        "        )\n",
        "\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=min(4, os.cpu_count() // 2),\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            # No persistent_workers for validation\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=min(4, os.cpu_count() // 2),\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            # No persistent_workers for test\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        # Full volume train loader for sanity checks (no patching)\n",
        "        full_train_ds = Dataset(get_files(\"train\"), base_transforms)\n",
        "        full_train_loader = DataLoader(\n",
        "            full_train_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Dataset sizes — Train: {len(train_ds)}, Valid: {len(valid_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "        return train_loader, valid_loader, test_loader, full_train_loader\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Execute training with resource monitoring\"\"\"\n",
        "        # Monitor resources\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"🎯 GPU Memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "            print(f\"🎯 GPU Memory cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n",
        "        print(\"\\n🔍 Final shape check before training...\")\n",
        "        self.debug_model_shapes()\n",
        "        # Validate we have data\n",
        "\n",
        "        if len(self.train_loader.dataset) == 0:\n",
        "            raise ValueError(\"No training data available!\")\n",
        "        if len(self.valid_loader.dataset) == 0:\n",
        "            raise ValueError(\"No validation data available!\")\n",
        "\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Execute testing with checkpoint validation\"\"\"\n",
        "        # Use consistent architecture with training\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),  # Must match training\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.INSTANCE,\n",
        "            dropout=0.1,\n",
        "            act='PRELU'\n",
        "        ).to(self.device)\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            print(\"📂 Loading checkpoint...\")\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "\n",
        "            # Validate checkpoint\n",
        "            if 'model_state_dict' not in checkpoint:\n",
        "                raise ValueError(\"Invalid checkpoint: missing 'model_state_dict'\")\n",
        "\n",
        "            try:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                print(\"✅ Checkpoint loaded successfully\")\n",
        "\n",
        "                # Print training info if available\n",
        "                if 'epoch' in checkpoint:\n",
        "                    print(f\"📅 Checkpoint from epoch: {checkpoint['epoch']}\")\n",
        "                if 'val_loss' in checkpoint:\n",
        "                    print(f\"📉 Checkpoint validation loss: {checkpoint['val_loss']:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Checkpoint loading failed: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Model file not found: {self.model_file}\")\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Execute full pipeline with validation\"\"\"\n",
        "        print(\"🚀 Starting pipeline with:\")\n",
        "        print(f\"   - Train samples: {len(self.train_loader.dataset)}\")\n",
        "        print(f\"   - Valid samples: {len(self.valid_loader.dataset)}\")\n",
        "        print(f\"   - Test samples: {len(self.test_loader.dataset)}\")\n",
        "        print(f\"   - Device: {self.device}\")\n",
        "        print(f\"   - Output directory: {self.output_dir}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            self.train()\n",
        "            self.test()\n",
        "\n",
        "            total_time = time.time() - start_time\n",
        "            print(f\"✅ Pipeline completed in {total_time/60:.2f} minutes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Pipeline failed: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "# ---------- Run ----------\n",
        "def main():\n",
        "    import multiprocessing as mp\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_Nifti_MONAI6_Original\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 1,   # Effective patches per step = num_samples * batch_size\n",
        "        'num_epochs': 200,\n",
        "        'learning_rate': 1e-4,\n",
        "    }\n",
        "\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    Resized,\n",
        "    CopyItemsd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    SaveImaged,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "# from monai.transforms.utils import SaveTransform\n",
        "\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_ct_dir, input_seg_dir, output_dir, device=\"cuda:0\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_ct_dir = input_ct_dir\n",
        "        self.input_seg_dir = input_seg_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.ct_out_dir = os.path.join(output_dir, \"ct\")\n",
        "        self.seg_out_dir = os.path.join(output_dir, \"segment\")\n",
        "        os.makedirs(self.ct_out_dir, exist_ok=True)\n",
        "        os.makedirs(self.seg_out_dir, exist_ok=True)\n",
        "        self.model_path = model_path\n",
        "        self.model = self._load_model()\n",
        "        set_determinism(seed=42)\n",
        "        self.forward_transforms = self._get_forward_transforms()\n",
        "        self.inverse_transforms = None\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        model.load_state_dict(state_dict.get('model_state_dict', state_dict))\n",
        "\n",
        "        print(f\"✅ Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_forward_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            CopyItemsd(keys=[\"vol\"], names=[\"vol_meta_dict\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\"], spatial_size=(96, 96, 96)),\n",
        "            EnsureTyped(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _get_inverse_transforms(self):\n",
        "        return Compose([\n",
        "            Invertd(\n",
        "                keys=[\"seg\"],\n",
        "                transform=self.forward_transforms,\n",
        "                orig_keys=[\"vol\"],\n",
        "                meta_keys=[\"vol_meta_dict\"],\n",
        "                nearest_interp=True,\n",
        "                to_tensor=False,\n",
        "            ),\n",
        "            EnsureTyped(keys=[\"seg\"])\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        data = []\n",
        "        for f in os.listdir(self.input_ct_dir):\n",
        "            if f.endswith(('.nii', '.nii.gz')):\n",
        "                ct_path = os.path.join(self.input_ct_dir, f)\n",
        "                data.append({\"vol\": ct_path})\n",
        "        print(f\"🔍 Found {len(data)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data, transform=self.forward_transforms), batch_size=1, num_workers=0)\n",
        "\n",
        "    def infer(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                batch = decollate_batch(batch)[0]\n",
        "                vol_meta = batch[\"vol_meta_dict\"]\n",
        "                ct = batch[\"vol\"]\n",
        "\n",
        "                if ct.dim() == 4:\n",
        "                    ct = ct.unsqueeze(0)\n",
        "                ct = ct.to(self.device)\n",
        "\n",
        "                filename = os.path.basename(vol_meta.meta[\"filename_or_obj\"])\n",
        "                orig_vol = nib.load(vol_meta.meta[\"filename_or_obj\"]).get_fdata()\n",
        "                print(f\"🔍 Inference on [{i+1}] {filename} | shape = {ct.shape}\")\n",
        "                print(f\"🔍 Original volume shape = {orig_vol.shape}\")\n",
        "                pred = self.model(ct)\n",
        "                pred = (torch.sigmoid(pred) > 0.5).float()\n",
        "\n",
        "                print(f\"✅ Predicted mask shape: {pred.shape}\")\n",
        "\n",
        "                batch[\"seg\"] = pred.cpu().squeeze(0)\n",
        "                print(f\"✅ Batch shape: {batch['seg'].shape}\")\n",
        "\n",
        "                if self.inverse_transforms is None:\n",
        "                    self.inverse_transforms = self._get_inverse_transforms()\n",
        "\n",
        "                inverted = self.inverse_transforms(batch)\n",
        "                inv_seg = inverted[\"seg\"].squeeze(0).numpy()\n",
        "                inv_seg = (inv_seg > 0.5).astype(np.uint8)\n",
        "                print(f\"✅ Inverted mask shape: {inv_seg.shape}\")\n",
        "\n",
        "                self._save_nifti(inv_seg, vol_meta, self.seg_out_dir, filename, is_segmentation=True)\n",
        "\n",
        "\n",
        "    def _save_nifti(self, array, meta_tensor, out_dir, filename, is_segmentation=False):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        affine = meta_tensor.meta.get(\"original_affine\", meta_tensor.meta.get(\"affine\", np.eye(4)))\n",
        "        dtype = np.uint8 if is_segmentation else np.float32\n",
        "        nib_img = nib.Nifti1Image(array.astype(dtype), affine)\n",
        "        nib.save(nib_img, os.path.join(out_dir, filename))\n",
        "        print(f\"✅ Saved: {os.path.join(out_dir, filename)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "z6a0G1DXTIV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a85b9f-c61a-4fd8-b379-3bd00e32c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 89 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG3-01.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (59, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (59, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-01.nii.gz\n",
            "🔍 Inference on [2] LUNG3-02.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (57, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (57, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-02.nii.gz\n",
            "🔍 Inference on [3] LUNG3-03.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-03.nii.gz\n",
            "🔍 Inference on [4] LUNG3-04.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-04.nii.gz\n",
            "🔍 Inference on [5] LUNG3-05.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (229, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (229, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-05.nii.gz\n",
            "🔍 Inference on [6] LUNG3-06.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-06.nii.gz\n",
            "🔍 Inference on [7] LUNG3-07.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (86, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (86, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-07.nii.gz\n",
            "🔍 Inference on [8] LUNG3-08.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-08.nii.gz\n",
            "🔍 Inference on [9] LUNG3-09.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (140, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (140, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-09.nii.gz\n",
            "🔍 Inference on [10] LUNG3-10.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-10.nii.gz\n",
            "🔍 Inference on [11] LUNG3-11.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (252, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (252, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-11.nii.gz\n",
            "🔍 Inference on [12] LUNG3-12.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (206, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (206, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-12.nii.gz\n",
            "🔍 Inference on [13] LUNG3-13.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (71, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (71, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-13.nii.gz\n",
            "🔍 Inference on [14] LUNG3-14.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (325, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (325, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-14.nii.gz\n",
            "🔍 Inference on [15] LUNG3-15.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (234, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (234, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-15.nii.gz\n",
            "🔍 Inference on [16] LUNG3-16.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (192, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (192, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-16.nii.gz\n",
            "🔍 Inference on [17] LUNG3-17.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (226, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (226, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-17.nii.gz\n",
            "🔍 Inference on [18] LUNG3-18.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-18.nii.gz\n",
            "🔍 Inference on [19] LUNG3-19.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-19.nii.gz\n",
            "🔍 Inference on [20] LUNG3-20.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (176, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (176, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-20.nii.gz\n",
            "🔍 Inference on [21] LUNG3-21.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-21.nii.gz\n",
            "🔍 Inference on [22] LUNG3-22.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (236, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (236, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-22.nii.gz\n",
            "🔍 Inference on [23] LUNG3-23.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (52, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (52, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-23.nii.gz\n",
            "🔍 Inference on [24] LUNG3-24.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-24.nii.gz\n",
            "🔍 Inference on [25] LUNG3-25.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (202, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (202, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-25.nii.gz\n",
            "🔍 Inference on [26] LUNG3-26.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (83, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (83, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-26.nii.gz\n",
            "🔍 Inference on [27] LUNG3-27.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (149, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (149, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-27.nii.gz\n",
            "🔍 Inference on [28] LUNG3-28.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (86, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (86, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-28.nii.gz\n",
            "🔍 Inference on [29] LUNG3-29.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (173, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (173, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-29.nii.gz\n",
            "🔍 Inference on [30] LUNG3-30.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (72, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (72, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-30.nii.gz\n",
            "🔍 Inference on [31] LUNG3-31.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (242, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (242, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-31.nii.gz\n",
            "🔍 Inference on [32] LUNG3-32.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (58, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (58, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-32.nii.gz\n",
            "🔍 Inference on [33] LUNG3-33.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (276, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (276, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-33.nii.gz\n",
            "🔍 Inference on [34] LUNG3-34.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-34.nii.gz\n",
            "🔍 Inference on [35] LUNG3-35.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (253, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (253, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-35.nii.gz\n",
            "🔍 Inference on [36] LUNG3-36.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (356, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (356, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-36.nii.gz\n",
            "🔍 Inference on [37] LUNG3-37.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (97, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (97, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-37.nii.gz\n",
            "🔍 Inference on [38] LUNG3-38.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (223, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (223, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-38.nii.gz\n",
            "🔍 Inference on [39] LUNG3-39.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (82, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (82, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-39.nii.gz\n",
            "🔍 Inference on [40] LUNG3-40.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (239, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (239, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-40.nii.gz\n",
            "🔍 Inference on [41] LUNG3-41.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (110, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (110, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-41.nii.gz\n",
            "🔍 Inference on [42] LUNG3-42.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-42.nii.gz\n",
            "🔍 Inference on [43] LUNG3-43.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (68, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (68, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-43.nii.gz\n",
            "🔍 Inference on [44] LUNG3-44.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (227, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (227, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-44.nii.gz\n",
            "🔍 Inference on [45] LUNG3-45.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-45.nii.gz\n",
            "🔍 Inference on [46] LUNG3-46.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (184, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (184, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-46.nii.gz\n",
            "🔍 Inference on [47] LUNG3-47.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (275, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (275, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-47.nii.gz\n",
            "🔍 Inference on [48] LUNG3-48.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (157, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (157, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-48.nii.gz\n",
            "🔍 Inference on [49] LUNG3-49.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (89, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (89, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-49.nii.gz\n",
            "🔍 Inference on [50] LUNG3-50.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-50.nii.gz\n",
            "🔍 Inference on [51] LUNG3-51.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (76, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (76, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-51.nii.gz\n",
            "🔍 Inference on [52] LUNG3-52.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (50, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (50, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-52.nii.gz\n",
            "🔍 Inference on [53] LUNG3-53.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-53.nii.gz\n",
            "🔍 Inference on [54] LUNG3-54.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (175, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (175, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-54.nii.gz\n",
            "🔍 Inference on [55] LUNG3-55.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (72, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (72, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-55.nii.gz\n",
            "🔍 Inference on [56] LUNG3-56.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-56.nii.gz\n",
            "🔍 Inference on [57] LUNG3-57.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-57.nii.gz\n",
            "🔍 Inference on [58] LUNG3-58.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (64, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (64, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-58.nii.gz\n",
            "🔍 Inference on [59] LUNG3-59.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (62, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (62, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-59.nii.gz\n",
            "🔍 Inference on [60] LUNG3-60.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-60.nii.gz\n",
            "🔍 Inference on [61] LUNG3-61.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (203, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (203, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-61.nii.gz\n",
            "🔍 Inference on [62] LUNG3-62.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (66, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (66, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-62.nii.gz\n",
            "🔍 Inference on [63] LUNG3-63.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (57, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (57, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-63.nii.gz\n",
            "🔍 Inference on [64] LUNG3-64.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (172, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (172, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-64.nii.gz\n",
            "🔍 Inference on [65] LUNG3-65.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (175, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (175, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-65.nii.gz\n",
            "🔍 Inference on [66] LUNG3-66.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (69, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (69, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-66.nii.gz\n",
            "🔍 Inference on [67] LUNG3-67.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-67.nii.gz\n",
            "🔍 Inference on [68] LUNG3-68.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (60, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (60, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-68.nii.gz\n",
            "🔍 Inference on [69] LUNG3-69.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-69.nii.gz\n",
            "🔍 Inference on [70] LUNG3-70.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (258, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (258, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-70.nii.gz\n",
            "🔍 Inference on [71] LUNG3-71.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (287, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (287, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-71.nii.gz\n",
            "🔍 Inference on [72] LUNG3-72.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (84, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (84, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-72.nii.gz\n",
            "🔍 Inference on [73] LUNG3-73.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (218, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (218, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-73.nii.gz\n",
            "🔍 Inference on [74] LUNG3-74.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (67, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (67, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-74.nii.gz\n",
            "🔍 Inference on [75] LUNG3-75.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (88, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (88, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-75.nii.gz\n",
            "🔍 Inference on [76] LUNG3-76.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-76.nii.gz\n",
            "🔍 Inference on [77] LUNG3-77.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-77.nii.gz\n",
            "🔍 Inference on [78] LUNG3-78.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-78.nii.gz\n",
            "🔍 Inference on [79] LUNG3-79.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (240, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (240, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-79.nii.gz\n",
            "🔍 Inference on [80] LUNG3-80.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (59, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (59, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-80.nii.gz\n",
            "🔍 Inference on [81] LUNG3-81.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (307, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (307, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-81.nii.gz\n",
            "🔍 Inference on [82] LUNG3-82.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (78, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (78, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-82.nii.gz\n",
            "🔍 Inference on [83] LUNG3-83.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-83.nii.gz\n",
            "🔍 Inference on [84] LUNG3-84.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (66, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (66, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-84.nii.gz\n",
            "🔍 Inference on [85] LUNG3-85.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (234, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (234, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-85.nii.gz\n",
            "🔍 Inference on [86] LUNG3-86.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (78, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (78, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-86.nii.gz\n",
            "🔍 Inference on [87] LUNG3-87.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (79, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (79, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-87.nii.gz\n",
            "🔍 Inference on [88] LUNG3-88.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (154, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (154, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-88.nii.gz\n",
            "🔍 Inference on [89] LUNG3-89.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-89.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "b54762e0-6093-45f5-86b6-48c278f39d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 38 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG1-001.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-001.nii.gz\n",
            "🔍 Inference on [2] LUNG1-025.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-025.nii.gz\n",
            "🔍 Inference on [3] LUNG1-027.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (108, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (108, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-027.nii.gz\n",
            "🔍 Inference on [4] LUNG1-034.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-034.nii.gz\n",
            "🔍 Inference on [5] LUNG1-039.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-039.nii.gz\n",
            "🔍 Inference on [6] LUNG1-066.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-066.nii.gz\n",
            "🔍 Inference on [7] LUNG1-078.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-078.nii.gz\n",
            "🔍 Inference on [8] LUNG1-088.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (123, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (123, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-088.nii.gz\n",
            "🔍 Inference on [9] LUNG1-107.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (116, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (116, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-107.nii.gz\n",
            "🔍 Inference on [10] LUNG1-132.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (114, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (114, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-132.nii.gz\n",
            "🔍 Inference on [11] LUNG1-133.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (184, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (184, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-133.nii.gz\n",
            "🔍 Inference on [12] LUNG1-143.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-143.nii.gz\n",
            "🔍 Inference on [13] LUNG1-149.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (118, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (118, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-149.nii.gz\n",
            "🔍 Inference on [14] LUNG1-151.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (118, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (118, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-151.nii.gz\n",
            "🔍 Inference on [15] LUNG1-158.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-158.nii.gz\n",
            "🔍 Inference on [16] LUNG1-168.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-168.nii.gz\n",
            "🔍 Inference on [17] LUNG1-175.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (112, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (112, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-175.nii.gz\n",
            "🔍 Inference on [18] LUNG1-176.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-176.nii.gz\n",
            "🔍 Inference on [19] LUNG1-201.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-201.nii.gz\n",
            "🔍 Inference on [20] LUNG1-224.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-224.nii.gz\n",
            "🔍 Inference on [21] LUNG1-225.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-225.nii.gz\n",
            "🔍 Inference on [22] LUNG1-235.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (129, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (129, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-235.nii.gz\n",
            "🔍 Inference on [23] LUNG1-239.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-239.nii.gz\n",
            "🔍 Inference on [24] LUNG1-246.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-246.nii.gz\n",
            "🔍 Inference on [25] LUNG1-263.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-263.nii.gz\n",
            "🔍 Inference on [26] LUNG1-266.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-266.nii.gz\n",
            "🔍 Inference on [27] LUNG1-281.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (101, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (101, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-281.nii.gz\n",
            "🔍 Inference on [28] LUNG1-286.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-286.nii.gz\n",
            "🔍 Inference on [29] LUNG1-312.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-312.nii.gz\n",
            "🔍 Inference on [30] LUNG1-338.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-338.nii.gz\n",
            "🔍 Inference on [31] LUNG1-352.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-352.nii.gz\n",
            "🔍 Inference on [32] LUNG1-353.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-353.nii.gz\n",
            "🔍 Inference on [33] LUNG1-365.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-365.nii.gz\n",
            "🔍 Inference on [34] LUNG1-374.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (130, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (130, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-374.nii.gz\n",
            "🔍 Inference on [35] LUNG1-383.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-383.nii.gz\n",
            "🔍 Inference on [36] LUNG1-405.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-405.nii.gz\n",
            "🔍 Inference on [37] LUNG1-408.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (107, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (107, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-408.nii.gz\n",
            "🔍 Inference on [38] LUNG1-410.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-410.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIi6GZ347x8",
        "outputId": "5b5fc90e-eeaf-4b07-d6a5-bf3197b8e4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 43 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG1-010.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (91, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (91, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-010.nii.gz\n",
            "🔍 Inference on [2] LUNG1-031.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (153, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (153, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-031.nii.gz\n",
            "🔍 Inference on [3] LUNG1-040.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-040.nii.gz\n",
            "🔍 Inference on [4] LUNG1-056.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-056.nii.gz\n",
            "🔍 Inference on [5] LUNG1-057.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (101, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (101, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-057.nii.gz\n",
            "🔍 Inference on [6] LUNG1-071.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (135, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (135, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-071.nii.gz\n",
            "🔍 Inference on [7] LUNG1-073.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (176, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (176, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-073.nii.gz\n",
            "🔍 Inference on [8] LUNG1-074.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-074.nii.gz\n",
            "🔍 Inference on [9] LUNG1-076.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-076.nii.gz\n",
            "🔍 Inference on [10] LUNG1-077.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (117, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (117, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-077.nii.gz\n",
            "🔍 Inference on [11] LUNG1-080.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-080.nii.gz\n",
            "🔍 Inference on [12] LUNG1-091.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (135, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (135, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-091.nii.gz\n",
            "🔍 Inference on [13] LUNG1-095.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-095.nii.gz\n",
            "🔍 Inference on [14] LUNG1-117.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (90, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (90, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-117.nii.gz\n",
            "🔍 Inference on [15] LUNG1-134.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (108, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (108, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-134.nii.gz\n",
            "🔍 Inference on [16] LUNG1-139.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (107, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (107, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-139.nii.gz\n",
            "🔍 Inference on [17] LUNG1-147.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-147.nii.gz\n",
            "🔍 Inference on [18] LUNG1-170.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (110, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (110, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-170.nii.gz\n",
            "🔍 Inference on [19] LUNG1-177.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-177.nii.gz\n",
            "🔍 Inference on [20] LUNG1-186.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-186.nii.gz\n",
            "🔍 Inference on [21] LUNG1-194.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (127, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (127, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-194.nii.gz\n",
            "🔍 Inference on [22] LUNG1-196.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-196.nii.gz\n",
            "🔍 Inference on [23] LUNG1-198.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (131, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (131, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-198.nii.gz\n",
            "🔍 Inference on [24] LUNG1-210.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (131, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (131, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-210.nii.gz\n",
            "🔍 Inference on [25] LUNG1-220.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-220.nii.gz\n",
            "🔍 Inference on [26] LUNG1-230.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-230.nii.gz\n",
            "🔍 Inference on [27] LUNG1-233.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-233.nii.gz\n",
            "🔍 Inference on [28] LUNG1-241.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-241.nii.gz\n",
            "🔍 Inference on [29] LUNG1-249.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-249.nii.gz\n",
            "🔍 Inference on [30] LUNG1-264.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (130, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (130, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-264.nii.gz\n",
            "🔍 Inference on [31] LUNG1-273.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-273.nii.gz\n",
            "🔍 Inference on [32] LUNG1-299.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-299.nii.gz\n",
            "🔍 Inference on [33] LUNG1-329.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-329.nii.gz\n",
            "🔍 Inference on [34] LUNG1-337.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-337.nii.gz\n",
            "🔍 Inference on [35] LUNG1-340.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-340.nii.gz\n",
            "🔍 Inference on [36] LUNG1-356.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-356.nii.gz\n",
            "🔍 Inference on [37] LUNG1-371.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (173, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (173, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-371.nii.gz\n",
            "🔍 Inference on [38] LUNG1-372.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-372.nii.gz\n",
            "🔍 Inference on [39] LUNG1-412.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-412.nii.gz\n",
            "🔍 Inference on [40] LUNG1-415.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (122, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (122, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-415.nii.gz\n",
            "🔍 Inference on [41] LUNG1-418.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (133, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (133, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-418.nii.gz\n",
            "🔍 Inference on [42] LUNG1-419.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-419.nii.gz\n",
            "🔍 Inference on [43] LUNG1-421.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-421.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOckv4nzdtpW+uj7wrMb6zI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}