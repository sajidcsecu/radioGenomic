{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Preprocessed_Uniform_Volume_DiceLoss_And_Strong_Augmentation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1350-150]) and the strong augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddeaee4-35cb-4387-f129-271ff413d726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import cv2\n",
        "from typing import List\n",
        "import torch.multiprocessing as mp\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torch.amp as amp\n",
        "import pickle\n",
        "from torch.utils.data import Sampler\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "42eef6e3-b107-4d4f-8ce0-c3c8cf7ee874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4PdRsL8DChf"
      },
      "source": [
        "# (4) Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTo3RxLmjW5r"
      },
      "outputs": [],
      "source": [
        "class StrongJointTransform3D:\n",
        "    def __init__(self, p_flip=0.5, p_rotate=0.5, p_gamma=0.5, p_noise=0.5):\n",
        "        self.p_flip = p_flip\n",
        "        self.p_rotate = p_rotate\n",
        "        self.p_gamma = p_gamma\n",
        "        self.p_noise = p_noise\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        if random.random() < self.p_flip:\n",
        "            if random.random() > 0.5:\n",
        "                image = torch.flip(image, dims=[2])  # Horizontal flip (W)\n",
        "                mask = torch.flip(mask, dims=[2])\n",
        "            else:\n",
        "                image = torch.flip(image, dims=[3])  # Vertical flip (H)\n",
        "                mask = torch.flip(mask, dims=[3])\n",
        "\n",
        "        if random.random() < self.p_rotate:\n",
        "            k = random.randint(0, 3)\n",
        "            image = torch.rot90(image, k, dims=[2, 3])  # Rotate in plane\n",
        "            mask = torch.rot90(mask, k, dims=[2, 3])\n",
        "\n",
        "        if random.random() < self.p_gamma:\n",
        "            gamma = random.uniform(0.7, 1.5)\n",
        "            image = torch.pow(image, gamma)\n",
        "\n",
        "        if random.random() < self.p_noise:\n",
        "            noise = torch.randn_like(image) * 0.05\n",
        "            image = torch.clamp(image + noise, 0, 1)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvhtapeukPgt"
      },
      "outputs": [],
      "source": [
        "class BalancedTumorSampler(Sampler):\n",
        "    def __init__(self, dataset, tumor_ratio=0.5, shuffle=True, index_cache_path=None):\n",
        "        self.dataset = dataset\n",
        "        self.tumor_ratio = tumor_ratio\n",
        "        self.shuffle = shuffle\n",
        "        self.index_cache_path = index_cache_path\n",
        "\n",
        "        self.tumor_indices = []\n",
        "        self.non_tumor_indices = []\n",
        "\n",
        "        if index_cache_path and os.path.exists(index_cache_path):\n",
        "            print(f\"📂 Loading cached indices from {index_cache_path}\")\n",
        "            with open(index_cache_path, 'rb') as f:\n",
        "                cached = pickle.load(f)\n",
        "                self.tumor_indices = cached['tumor']\n",
        "                self.non_tumor_indices = cached['non_tumor']\n",
        "            print(f\"✅ Loaded: {len(self.tumor_indices)} tumor, {len(self.non_tumor_indices)} non-tumor\")\n",
        "        else:\n",
        "            print(\"🛠️ Computing tumor/non-tumor indices...\")\n",
        "            self._prepare_indices()\n",
        "            if index_cache_path:\n",
        "                print(f\"💾 Saving indices to {index_cache_path}\")\n",
        "                with open(index_cache_path, 'wb') as f:\n",
        "                    pickle.dump({'tumor': self.tumor_indices, 'non_tumor': self.non_tumor_indices}, f)\n",
        "\n",
        "    def _prepare_indices(self):\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, mask = self.dataset[idx]\n",
        "            if mask.sum() > 0:\n",
        "                self.tumor_indices.append(idx)\n",
        "            else:\n",
        "                self.non_tumor_indices.append(idx)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.tumor_indices)\n",
        "            random.shuffle(self.non_tumor_indices)\n",
        "\n",
        "        total_samples = min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n",
        "        num_tumor = int(self.tumor_ratio * total_samples)\n",
        "        num_non_tumor = total_samples - num_tumor\n",
        "\n",
        "        selected_tumor = self.tumor_indices[:num_tumor]\n",
        "        selected_non_tumor = self.non_tumor_indices[:num_non_tumor]\n",
        "\n",
        "        combined = selected_tumor + selected_non_tumor\n",
        "        if self.shuffle:\n",
        "            random.shuffle(combined)\n",
        "\n",
        "        return iter(combined)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoGkyWq93X-H"
      },
      "outputs": [],
      "source": [
        "class HDF5SegmentationDataset3D(Dataset):\n",
        "    def __init__(self, hdf5_path, transform=None, target_shape=(64, 512, 512)):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.target_shape = target_shape  # (depth, height, width)\n",
        "        self.file = None\n",
        "        self.clip_min = -1350\n",
        "        self.clip_max = 150\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            self.patient_ids = list(f.keys())\n",
        "\n",
        "        if not self.patient_ids:\n",
        "            raise RuntimeError(f\"No patient groups found in HDF5 file: {hdf5_path}\")\n",
        "        print(f\"📂 Found {len(self.patient_ids)} patients in {hdf5_path}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.file is None:\n",
        "            self.file = h5py.File(self.hdf5_path, 'r')\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        ct_volume = self.file[pid]['ct'][()]  # shape: D x H x W\n",
        "        mask_volume = self.file[pid]['mask'][()]  # shape: D x H x W\n",
        "\n",
        "        # Normalize CT\n",
        "        ct_volume = (ct_volume - self.clip_min) / (self.clip_max - self.clip_min + 1e-5)\n",
        "\n",
        "        # Convert to tensors: shape => [1, D, H, W]\n",
        "        ct_tensor = torch.tensor(ct_volume, dtype=torch.float32).unsqueeze(0)\n",
        "        mask_tensor = torch.tensor(mask_volume, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Apply resizing/cropping\n",
        "        ct_tensor, mask_tensor = self._adjust_depth_pair(ct_tensor, mask_tensor)\n",
        "\n",
        "        # Apply transforms (e.g. augmentation)\n",
        "        if self.transform:\n",
        "            ct_tensor, mask_tensor = self.transform(ct_tensor, mask_tensor)\n",
        "\n",
        "        return ct_tensor, mask_tensor\n",
        "\n",
        "    def _adjust_depth_pair(self, ct_tensor, mask_tensor):\n",
        "        target_d, target_h, target_w = self.target_shape\n",
        "\n",
        "        # Add batch dimension\n",
        "        ct_tensor = ct_tensor.unsqueeze(0)   # Shape: (1, 1, D, H, W)\n",
        "        mask_tensor = mask_tensor.unsqueeze(0)\n",
        "\n",
        "        # Resize H and W to 512x512 (keeping D the same for now)\n",
        "        ct_tensor = F.interpolate(ct_tensor, size=(ct_tensor.shape[2], target_h, target_w), mode='trilinear', align_corners=False)\n",
        "        mask_tensor = F.interpolate(mask_tensor, size=(mask_tensor.shape[2], target_h, target_w), mode='nearest')\n",
        "\n",
        "        # Remove batch dimension\n",
        "        ct_tensor = ct_tensor.squeeze(0)     # Back to shape: (1, D, H, W)\n",
        "        mask_tensor = mask_tensor.squeeze(0)\n",
        "\n",
        "        # Crop or pad along depth\n",
        "        current_d = ct_tensor.shape[1]\n",
        "        if current_d >= target_d:\n",
        "            # Tumor-focused cropping\n",
        "            mask_sum = mask_tensor.sum(dim=(2, 3)).squeeze(0)  # shape: D\n",
        "            non_zero = torch.nonzero(mask_sum > 0).squeeze()\n",
        "\n",
        "            if non_zero.numel() > 0:\n",
        "                center = int(non_zero.float().mean().item())\n",
        "            else:\n",
        "                center = current_d // 2  # fallback if no tumor\n",
        "\n",
        "            start = max(center - target_d // 2, 0)\n",
        "            end = start + target_d\n",
        "            if end > current_d:\n",
        "                end = current_d\n",
        "                start = end - target_d\n",
        "\n",
        "            ct_tensor = ct_tensor[:, start:end, :, :]\n",
        "            mask_tensor = mask_tensor[:, start:end, :, :]\n",
        "\n",
        "        else:\n",
        "            pad_d = target_d - current_d\n",
        "            pad_before = pad_d // 2\n",
        "            pad_after = pad_d - pad_before\n",
        "            padding = (0, 0, 0, 0, pad_before, pad_after)  # D, H, W\n",
        "            ct_tensor = F.pad(ct_tensor, padding, mode='constant', value=0)\n",
        "            mask_tensor = F.pad(mask_tensor, padding, mode='constant', value=0)\n",
        "\n",
        "        return ct_tensor, mask_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2iHKHfcF3yP"
      },
      "source": [
        "# 2. Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PamAo5NoFsRv"
      },
      "outputs": [],
      "source": [
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpSample3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class EncoderBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv3D(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool3d(2)\n",
        "        self.dropout = nn.Dropout3d(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        p = self.pool(x)\n",
        "        return x, self.dropout(p)\n",
        "\n",
        "class DecoderBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.up = UpSample3D(in_channels, out_channels)\n",
        "        self.conv = DoubleConv3D(out_channels * 2, out_channels)\n",
        "        self.dropout = nn.Dropout3d(p=dropout)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.e1 = EncoderBlock3D(in_channels, 64, dropout)\n",
        "        self.e2 = EncoderBlock3D(64, 128, dropout)\n",
        "        self.e3 = EncoderBlock3D(128, 256, dropout)\n",
        "        self.e4 = EncoderBlock3D(256, 512, dropout)\n",
        "\n",
        "        self.b = DoubleConv3D(512, 1024)\n",
        "        self.dropout_bottleneck = nn.Dropout3d(p=dropout)\n",
        "\n",
        "        self.d1 = DecoderBlock3D(1024, 512, dropout)\n",
        "        self.d2 = DecoderBlock3D(512, 256, dropout)\n",
        "        self.d3 = DecoderBlock3D(256, 128, dropout)\n",
        "        self.d4 = DecoderBlock3D(128, 64, dropout)\n",
        "\n",
        "        self.outputs = nn.Conv3d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.e1(x)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        b = self.dropout_bottleneck(self.b(p4))\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        return self.outputs(d4)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # double_conv = DoubleConv(256, 256)\n",
        "#     # print(double_conv)\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     input_image = torch.randn((1, 1, 512, 512), dtype=torch.float32)\n",
        "#     model = UNet(1, 1).to(device)\n",
        "#     input_image = input_image.to(device)\n",
        "#     out = model(input_image)\n",
        "#     print(out.shape)\n",
        "#     print(device)\n",
        "#     print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## 2. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = torch.sigmoid(preds)\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (preds * targets).sum()\n",
        "        dice_score = (2. * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        return 1 - dice_score\n",
        "\n",
        "class DiceBCELoss3D(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.flatten()\n",
        "        targets = targets.flatten()\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (preds_sigmoid.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# 3. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str,metrics_csv, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.device = device\n",
        "        self.metrics_csv = metrics_csv\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Initialize CSV file with headers\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, mode='w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "        print(f\"Test results will be saved to: {self.test_result_path}\")\n",
        "        print(f\"Using device: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> List[float]:\n",
        "        # Apply sigmoid and threshold at 0.5\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        y_true_np = y_true.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "\n",
        "        # If ground truth is completely empty or prediction is empty, set zero_division=0 for clarity\n",
        "        return [\n",
        "            jaccard_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            f1_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            recall_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            precision_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            accuracy_score(y_true_np, y_pred_np)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def save_result(self, image: torch.Tensor, org_mask: torch.Tensor, predicted_mask: torch.Tensor, sample_id: int) -> None:\n",
        "        predicted_mask = (predicted_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        org_mask = (org_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        image = (image.detach().cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "        h, w = image.shape\n",
        "        line = np.ones((h, 10), dtype=np.uint8) * 128\n",
        "        cat_images = np.concatenate([image, line, org_mask, line, predicted_mask], axis=1)\n",
        "\n",
        "        file_name = os.path.join(self.test_result_path, f\"sample_{sample_id}.png\")\n",
        "        success = cv2.imwrite(file_name, cat_images)\n",
        "\n",
        "        if success:\n",
        "            print(f\"✅ Saved: {file_name}\")\n",
        "        else:\n",
        "            print(f\"❌ Failed to save image: {file_name}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: int, metrics: List[float], elapsed_time: float) -> None:\n",
        "        with open(self.metrics_csv, mode='a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> None:\n",
        "        model.eval()\n",
        "        metrics_score = np.zeros(5)\n",
        "        time_taken = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pid, (x, y) in enumerate(test_loader):\n",
        "                if (pid >=2):\n",
        "                  break\n",
        "                x = x.to(self.device, dtype=torch.float32)\n",
        "                y = y.to(self.device, dtype=torch.float32)\n",
        "\n",
        "                start_time = time.time()\n",
        "                y_pred = torch.sigmoid(model(x))\n",
        "                elapsed_time = time.time() - start_time\n",
        "                time_taken.append(elapsed_time)\n",
        "\n",
        "                batch_metrics = self.calculate_metrics(y, y_pred)\n",
        "                metrics_score += np.array(batch_metrics)\n",
        "\n",
        "                for idx in range(x.size(0)):\n",
        "                    sample_id = pid * x.size(0) + idx\n",
        "                    self.save_result(x[idx], y[idx], y_pred[idx], sample_id)\n",
        "                    self.append_metrics_to_csv(sample_id, batch_metrics, elapsed_time)\n",
        "\n",
        "        num_batches = len(test_loader)\n",
        "        avg_metrics = metrics_score / num_batches\n",
        "\n",
        "        print(f\"\\n🧪 Total Batches in Test Set: {num_batches}\")\n",
        "        print(f\"📊 Jaccard: {avg_metrics[0]:.4f} | F1: {avg_metrics[1]:.4f} | Recall: {avg_metrics[2]:.4f} | \"\n",
        "              f\"Precision: {avg_metrics[3]:.4f} | Accuracy: {avg_metrics[4]:.4f}\")\n",
        "        print(f\"⚡ FPS: {1 / np.mean(time_taken):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.Inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            if self.verbose:\n",
        "                print(f\"✅ Validation loss improved. Saving model...\")\n",
        "            self.save_checkpoint(model, epoch, optimizer, improved=True)\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"⏳ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            self.save_checkpoint(model, epoch, optimizer, improved=False)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None, improved=True):\n",
        "        # Save full checkpoint regardless of improvement\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict() if improved else None,  # Avoid overwriting model if not improved\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "\n",
        "        self.seeding(42)\n",
        "\n",
        "        print(f\"🔧 Training initialized: lr={self.lr}, epochs={self.num_epochs}\")\n",
        "        print(f\"📁 Model will be saved to: {self.model_file}\")\n",
        "        print(f\"📁 Loss log will be saved to: {self.loss_result_path}\")\n",
        "        print(f\"💻 Device in use: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = amp.GradScaler()\n",
        "\n",
        "\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            if (batch_idx >=10):\n",
        "                  break\n",
        "            x, y = x.to(self.device, dtype=torch.float32), y.to(self.device, dtype=torch.float32)\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(device_type=self.device.type):\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x, y) in enumerate(loader):\n",
        "                if (batch_idx >=2):\n",
        "                    break\n",
        "                x, y = x.to(self.device, dtype=torch.float32), y.to(self.device, dtype=torch.float32)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model =UNet3D(in_channels=1, out_channels=1, dropout=0.3).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn =DiceBCELoss3D()\n",
        "\n",
        "        start_epoch = 1\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "\n",
        "        # Resume from checkpoint if exists\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        # Resume CSV loss log\n",
        "        if os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, 'r') as file:\n",
        "                reader = csv.reader(file)\n",
        "                next(reader)  # skip header\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    last_epoch = int(rows[-1][0])\n",
        "                    start_epoch = last_epoch + 1\n",
        "                    history['train_loss'] = [float(r[1]) for r in rows]\n",
        "                    history['valid_loss'] = [float(r[2]) for r in rows]\n",
        "                    if start_val_loss_min is None:\n",
        "                        start_val_loss_min = min(history['valid_loss'])\n",
        "\n",
        "            val_loss_str = f\"{start_val_loss_min:.6f}\" if start_val_loss_min is not None else \"None\"\n",
        "            print(f\"🔁 Resuming from epoch {start_epoch} (val_loss_min={val_loss_str}, patience_counter={start_patience_counter})\")\n",
        "\n",
        "            shutil.copy(self.loss_result_path, self.loss_result_path.replace(\".csv\", \"_backup.csv\"))\n",
        "\n",
        "        # Setup EarlyStopping\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter\n",
        "        )\n",
        "\n",
        "        # Header if new\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # --- Training loop ---\n",
        "        for epoch in tqdm(range(start_epoch, self.num_epochs + 1), desc=\"🏋️ Training\"):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
        "\n",
        "            print(f\"📅 Epoch {epoch:03d} | ⏱️ {epoch_mins}m {epoch_secs}s | 🔥 Train: {train_loss:.8f} | 🎯 Val: {valid_loss:.8f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"🛑 Early stopping triggered.\")\n",
        "                break\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CwcTHPshqu0O",
        "outputId": "b2126bd7-4bf5-4fd9-bc4e-c624f6862081"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "context has already been set",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-2955739462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context has already been set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_paths()\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"📦 Loading datasets...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self.prepare_loaders()\n",
        "\n",
        "    def setup_paths(self):\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "    def prepare_loaders(self):\n",
        "        train_path = os.path.join(self.dataset_dir, \"train_dataset.hdf5\")\n",
        "        valid_path = os.path.join(self.dataset_dir, \"valid_dataset.hdf5\")\n",
        "        test_path = os.path.join(self.dataset_dir, \"test_dataset.hdf5\")\n",
        "\n",
        "        train_transform = StrongJointTransform3D()\n",
        "\n",
        "        train_dataset = HDF5SegmentationDataset3D(train_path, transform=train_transform)\n",
        "        valid_dataset = HDF5SegmentationDataset3D(valid_path, transform=None)\n",
        "        test_dataset  = HDF5SegmentationDataset3D(test_path, transform=None)\n",
        "\n",
        "        sampler = BalancedTumorSampler(\n",
        "            train_dataset,\n",
        "            tumor_ratio=0.5,\n",
        "            shuffle=True,\n",
        "            index_cache_path=os.path.join(self.dataset_dir, 'tumor_indices.pkl')\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "        test_loader  = DataLoader(test_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        print(f\"✅ Dataset sizes — Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    def train(self):\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        model = UNet3D(in_channels=1, out_channels=1).to(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        self.train()\n",
        "        self.test()\n",
        "\n",
        "\n",
        "def main():\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_3D_PreProcessedCT_Uniform_Volume_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\n",
        "        'transformation': \"PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 2,\n",
        "        'num_epochs': 100,\n",
        "        'learning_rate': 1e-5,\n",
        "    }\n",
        "\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMSmkuYHZX7U3MpY05Gfka7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}