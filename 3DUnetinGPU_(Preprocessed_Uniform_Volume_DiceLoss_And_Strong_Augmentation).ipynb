{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Preprocessed_Uniform_Volume_DiceLoss_And_Strong_Augmentation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1350-150]) and the strong augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddeaee4-35cb-4387-f129-271ff413d726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import cv2\n",
        "from typing import List\n",
        "import torch.multiprocessing as mp\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torch.amp as amp\n",
        "import pickle\n",
        "from torch.utils.data import Sampler\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "42eef6e3-b107-4d4f-8ce0-c3c8cf7ee874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4PdRsL8DChf"
      },
      "source": [
        "# (4) Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTo3RxLmjW5r"
      },
      "outputs": [],
      "source": [
        "class StrongJointTransform3D:\n",
        "    def __init__(self, p_flip=0.5, p_rotate=0.5, p_gamma=0.5, p_noise=0.5):\n",
        "        self.p_flip = p_flip\n",
        "        self.p_rotate = p_rotate\n",
        "        self.p_gamma = p_gamma\n",
        "        self.p_noise = p_noise\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        if random.random() < self.p_flip:\n",
        "            if random.random() > 0.5:\n",
        "                image = torch.flip(image, dims=[2])  # Horizontal flip (W)\n",
        "                mask = torch.flip(mask, dims=[2])\n",
        "            else:\n",
        "                image = torch.flip(image, dims=[3])  # Vertical flip (H)\n",
        "                mask = torch.flip(mask, dims=[3])\n",
        "\n",
        "        if random.random() < self.p_rotate:\n",
        "            k = random.randint(0, 3)\n",
        "            image = torch.rot90(image, k, dims=[2, 3])  # Rotate in plane\n",
        "            mask = torch.rot90(mask, k, dims=[2, 3])\n",
        "\n",
        "        if random.random() < self.p_gamma:\n",
        "            gamma = random.uniform(0.7, 1.5)\n",
        "            image = torch.pow(image, gamma)\n",
        "\n",
        "        if random.random() < self.p_noise:\n",
        "            noise = torch.randn_like(image) * 0.05\n",
        "            image = torch.clamp(image + noise, 0, 1)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvhtapeukPgt"
      },
      "outputs": [],
      "source": [
        "class BalancedTumorSampler(Sampler):\n",
        "    def __init__(self, dataset, tumor_ratio=0.5, shuffle=True, index_cache_path=None):\n",
        "        self.dataset = dataset\n",
        "        self.tumor_ratio = tumor_ratio\n",
        "        self.shuffle = shuffle\n",
        "        self.index_cache_path = index_cache_path\n",
        "\n",
        "        self.tumor_indices = []\n",
        "        self.non_tumor_indices = []\n",
        "\n",
        "        if index_cache_path and os.path.exists(index_cache_path):\n",
        "            print(f\"üìÇ Loading cached indices from {index_cache_path}\")\n",
        "            with open(index_cache_path, 'rb') as f:\n",
        "                cached = pickle.load(f)\n",
        "                self.tumor_indices = cached['tumor']\n",
        "                self.non_tumor_indices = cached['non_tumor']\n",
        "            print(f\"‚úÖ Loaded: {len(self.tumor_indices)} tumor, {len(self.non_tumor_indices)} non-tumor\")\n",
        "        else:\n",
        "            print(\"üõ†Ô∏è Computing tumor/non-tumor indices...\")\n",
        "            self._prepare_indices()\n",
        "            if index_cache_path:\n",
        "                print(f\"üíæ Saving indices to {index_cache_path}\")\n",
        "                with open(index_cache_path, 'wb') as f:\n",
        "                    pickle.dump({'tumor': self.tumor_indices, 'non_tumor': self.non_tumor_indices}, f)\n",
        "\n",
        "    def _prepare_indices(self):\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, mask = self.dataset[idx]\n",
        "            if mask.sum() > 0:\n",
        "                self.tumor_indices.append(idx)\n",
        "            else:\n",
        "                self.non_tumor_indices.append(idx)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.tumor_indices)\n",
        "            random.shuffle(self.non_tumor_indices)\n",
        "\n",
        "        total_samples = min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n",
        "        num_tumor = int(self.tumor_ratio * total_samples)\n",
        "        num_non_tumor = total_samples - num_tumor\n",
        "\n",
        "        selected_tumor = self.tumor_indices[:num_tumor]\n",
        "        selected_non_tumor = self.non_tumor_indices[:num_non_tumor]\n",
        "\n",
        "        combined = selected_tumor + selected_non_tumor\n",
        "        if self.shuffle:\n",
        "            random.shuffle(combined)\n",
        "\n",
        "        return iter(combined)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoGkyWq93X-H"
      },
      "outputs": [],
      "source": [
        "class HDF5SegmentationDataset3D(Dataset):\n",
        "    def __init__(self, hdf5_path, transform=None, target_shape=(64, 512, 512)):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.target_shape = target_shape  # (depth, height, width)\n",
        "        self.file = None\n",
        "        self.clip_min = -1350\n",
        "        self.clip_max = 150\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            self.patient_ids = list(f.keys())\n",
        "\n",
        "        if not self.patient_ids:\n",
        "            raise RuntimeError(f\"No patient groups found in HDF5 file: {hdf5_path}\")\n",
        "        print(f\"üìÇ Found {len(self.patient_ids)} patients in {hdf5_path}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.file is None:\n",
        "            self.file = h5py.File(self.hdf5_path, 'r')\n",
        "\n",
        "        pid = self.patient_ids[idx]\n",
        "        ct_volume = self.file[pid]['ct'][()]  # shape: D x H x W\n",
        "        mask_volume = self.file[pid]['mask'][()]  # shape: D x H x W\n",
        "\n",
        "        # Normalize CT\n",
        "        ct_volume = (ct_volume - self.clip_min) / (self.clip_max - self.clip_min + 1e-5)\n",
        "\n",
        "        # Convert to tensors: shape => [1, D, H, W]\n",
        "        ct_tensor = torch.tensor(ct_volume, dtype=torch.float32).unsqueeze(0)\n",
        "        mask_tensor = torch.tensor(mask_volume, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Apply resizing/cropping\n",
        "        ct_tensor, mask_tensor = self._adjust_depth_pair(ct_tensor, mask_tensor)\n",
        "\n",
        "        # Apply transforms (e.g. augmentation)\n",
        "        if self.transform:\n",
        "            ct_tensor, mask_tensor = self.transform(ct_tensor, mask_tensor)\n",
        "\n",
        "        return ct_tensor, mask_tensor\n",
        "\n",
        "    def _adjust_depth_pair(self, ct_tensor, mask_tensor):\n",
        "        target_d, target_h, target_w = self.target_shape\n",
        "\n",
        "        # Add batch dimension\n",
        "        ct_tensor = ct_tensor.unsqueeze(0)   # Shape: (1, 1, D, H, W)\n",
        "        mask_tensor = mask_tensor.unsqueeze(0)\n",
        "\n",
        "        # Resize H and W to 512x512 (keeping D the same for now)\n",
        "        ct_tensor = F.interpolate(ct_tensor, size=(ct_tensor.shape[2], target_h, target_w), mode='trilinear', align_corners=False)\n",
        "        mask_tensor = F.interpolate(mask_tensor, size=(mask_tensor.shape[2], target_h, target_w), mode='nearest')\n",
        "\n",
        "        # Remove batch dimension\n",
        "        ct_tensor = ct_tensor.squeeze(0)     # Back to shape: (1, D, H, W)\n",
        "        mask_tensor = mask_tensor.squeeze(0)\n",
        "\n",
        "        # Crop or pad along depth\n",
        "        current_d = ct_tensor.shape[1]\n",
        "        if current_d >= target_d:\n",
        "            # Tumor-focused cropping\n",
        "            mask_sum = mask_tensor.sum(dim=(2, 3)).squeeze(0)  # shape: D\n",
        "            non_zero = torch.nonzero(mask_sum > 0).squeeze()\n",
        "\n",
        "            if non_zero.numel() > 0:\n",
        "                center = int(non_zero.float().mean().item())\n",
        "            else:\n",
        "                center = current_d // 2  # fallback if no tumor\n",
        "\n",
        "            start = max(center - target_d // 2, 0)\n",
        "            end = start + target_d\n",
        "            if end > current_d:\n",
        "                end = current_d\n",
        "                start = end - target_d\n",
        "\n",
        "            ct_tensor = ct_tensor[:, start:end, :, :]\n",
        "            mask_tensor = mask_tensor[:, start:end, :, :]\n",
        "\n",
        "        else:\n",
        "            pad_d = target_d - current_d\n",
        "            pad_before = pad_d // 2\n",
        "            pad_after = pad_d - pad_before\n",
        "            padding = (0, 0, 0, 0, pad_before, pad_after)  # D, H, W\n",
        "            ct_tensor = F.pad(ct_tensor, padding, mode='constant', value=0)\n",
        "            mask_tensor = F.pad(mask_tensor, padding, mode='constant', value=0)\n",
        "\n",
        "        return ct_tensor, mask_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2iHKHfcF3yP"
      },
      "source": [
        "# 2. Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PamAo5NoFsRv"
      },
      "outputs": [],
      "source": [
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpSample3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class EncoderBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv3D(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool3d(2)\n",
        "        self.dropout = nn.Dropout3d(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        p = self.pool(x)\n",
        "        return x, self.dropout(p)\n",
        "\n",
        "class DecoderBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.up = UpSample3D(in_channels, out_channels)\n",
        "        self.conv = DoubleConv3D(out_channels * 2, out_channels)\n",
        "        self.dropout = nn.Dropout3d(p=dropout)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.e1 = EncoderBlock3D(in_channels, 64, dropout)\n",
        "        self.e2 = EncoderBlock3D(64, 128, dropout)\n",
        "        self.e3 = EncoderBlock3D(128, 256, dropout)\n",
        "        self.e4 = EncoderBlock3D(256, 512, dropout)\n",
        "\n",
        "        self.b = DoubleConv3D(512, 1024)\n",
        "        self.dropout_bottleneck = nn.Dropout3d(p=dropout)\n",
        "\n",
        "        self.d1 = DecoderBlock3D(1024, 512, dropout)\n",
        "        self.d2 = DecoderBlock3D(512, 256, dropout)\n",
        "        self.d3 = DecoderBlock3D(256, 128, dropout)\n",
        "        self.d4 = DecoderBlock3D(128, 64, dropout)\n",
        "\n",
        "        self.outputs = nn.Conv3d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.e1(x)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        b = self.dropout_bottleneck(self.b(p4))\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        return self.outputs(d4)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # double_conv = DoubleConv(256, 256)\n",
        "#     # print(double_conv)\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     input_image = torch.randn((1, 1, 512, 512), dtype=torch.float32)\n",
        "#     model = UNet(1, 1).to(device)\n",
        "#     input_image = input_image.to(device)\n",
        "#     out = model(input_image)\n",
        "#     print(out.shape)\n",
        "#     print(device)\n",
        "#     print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## 2. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = torch.sigmoid(preds)\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (preds * targets).sum()\n",
        "        dice_score = (2. * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        return 1 - dice_score\n",
        "\n",
        "class DiceBCELoss3D(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.flatten()\n",
        "        targets = targets.flatten()\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (preds_sigmoid.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# 3. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str,metrics_csv, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.device = device\n",
        "        self.metrics_csv = metrics_csv\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Initialize CSV file with headers\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, mode='w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "        print(f\"Test results will be saved to: {self.test_result_path}\")\n",
        "        print(f\"Using device: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> List[float]:\n",
        "        # Apply sigmoid and threshold at 0.5\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        y_true_np = y_true.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "\n",
        "        # If ground truth is completely empty or prediction is empty, set zero_division=0 for clarity\n",
        "        return [\n",
        "            jaccard_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            f1_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            recall_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            precision_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            accuracy_score(y_true_np, y_pred_np)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def save_result(self, image: torch.Tensor, org_mask: torch.Tensor, predicted_mask: torch.Tensor, sample_id: int) -> None:\n",
        "        predicted_mask = (predicted_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        org_mask = (org_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        image = (image.detach().cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "        h, w = image.shape\n",
        "        line = np.ones((h, 10), dtype=np.uint8) * 128\n",
        "        cat_images = np.concatenate([image, line, org_mask, line, predicted_mask], axis=1)\n",
        "\n",
        "        file_name = os.path.join(self.test_result_path, f\"sample_{sample_id}.png\")\n",
        "        success = cv2.imwrite(file_name, cat_images)\n",
        "\n",
        "        if success:\n",
        "            print(f\"‚úÖ Saved: {file_name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to save image: {file_name}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: int, metrics: List[float], elapsed_time: float) -> None:\n",
        "        with open(self.metrics_csv, mode='a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> None:\n",
        "        model.eval()\n",
        "        metrics_score = np.zeros(5)\n",
        "        time_taken = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pid, (x, y) in enumerate(test_loader):\n",
        "                if (pid >=2):\n",
        "                  break\n",
        "                x = x.to(self.device, dtype=torch.float32)\n",
        "                y = y.to(self.device, dtype=torch.float32)\n",
        "\n",
        "                start_time = time.time()\n",
        "                y_pred = torch.sigmoid(model(x))\n",
        "                elapsed_time = time.time() - start_time\n",
        "                time_taken.append(elapsed_time)\n",
        "\n",
        "                batch_metrics = self.calculate_metrics(y, y_pred)\n",
        "                metrics_score += np.array(batch_metrics)\n",
        "\n",
        "                for idx in range(x.size(0)):\n",
        "                    sample_id = pid * x.size(0) + idx\n",
        "                    self.save_result(x[idx], y[idx], y_pred[idx], sample_id)\n",
        "                    self.append_metrics_to_csv(sample_id, batch_metrics, elapsed_time)\n",
        "\n",
        "        num_batches = len(test_loader)\n",
        "        avg_metrics = metrics_score / num_batches\n",
        "\n",
        "        print(f\"\\nüß™ Total Batches in Test Set: {num_batches}\")\n",
        "        print(f\"üìä Jaccard: {avg_metrics[0]:.4f} | F1: {avg_metrics[1]:.4f} | Recall: {avg_metrics[2]:.4f} | \"\n",
        "              f\"Precision: {avg_metrics[3]:.4f} | Accuracy: {avg_metrics[4]:.4f}\")\n",
        "        print(f\"‚ö° FPS: {1 / np.mean(time_taken):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.Inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            if self.verbose:\n",
        "                print(f\"‚úÖ Validation loss improved. Saving model...\")\n",
        "            self.save_checkpoint(model, epoch, optimizer, improved=True)\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"‚è≥ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            self.save_checkpoint(model, epoch, optimizer, improved=False)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None, improved=True):\n",
        "        # Save full checkpoint regardless of improvement\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict() if improved else None,  # Avoid overwriting model if not improved\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "\n",
        "        self.seeding(42)\n",
        "\n",
        "        print(f\"üîß Training initialized: lr={self.lr}, epochs={self.num_epochs}\")\n",
        "        print(f\"üìÅ Model will be saved to: {self.model_file}\")\n",
        "        print(f\"üìÅ Loss log will be saved to: {self.loss_result_path}\")\n",
        "        print(f\"üíª Device in use: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = amp.GradScaler()\n",
        "\n",
        "\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            if (batch_idx >=10):\n",
        "                  break\n",
        "            x, y = x.to(self.device, dtype=torch.float32), y.to(self.device, dtype=torch.float32)\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(device_type=self.device.type):\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x, y) in enumerate(loader):\n",
        "                if (batch_idx >=2):\n",
        "                    break\n",
        "                x, y = x.to(self.device, dtype=torch.float32), y.to(self.device, dtype=torch.float32)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model =UNet3D(in_channels=1, out_channels=1, dropout=0.3).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn =DiceBCELoss3D()\n",
        "\n",
        "        start_epoch = 1\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "\n",
        "        # Resume from checkpoint if exists\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        # Resume CSV loss log\n",
        "        if os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, 'r') as file:\n",
        "                reader = csv.reader(file)\n",
        "                next(reader)  # skip header\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    last_epoch = int(rows[-1][0])\n",
        "                    start_epoch = last_epoch + 1\n",
        "                    history['train_loss'] = [float(r[1]) for r in rows]\n",
        "                    history['valid_loss'] = [float(r[2]) for r in rows]\n",
        "                    if start_val_loss_min is None:\n",
        "                        start_val_loss_min = min(history['valid_loss'])\n",
        "\n",
        "            val_loss_str = f\"{start_val_loss_min:.6f}\" if start_val_loss_min is not None else \"None\"\n",
        "            print(f\"üîÅ Resuming from epoch {start_epoch} (val_loss_min={val_loss_str}, patience_counter={start_patience_counter})\")\n",
        "\n",
        "            shutil.copy(self.loss_result_path, self.loss_result_path.replace(\".csv\", \"_backup.csv\"))\n",
        "\n",
        "        # Setup EarlyStopping\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter\n",
        "        )\n",
        "\n",
        "        # Header if new\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # --- Training loop ---\n",
        "        for epoch in tqdm(range(start_epoch, self.num_epochs + 1), desc=\"üèãÔ∏è Training\"):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
        "\n",
        "            print(f\"üìÖ Epoch {epoch:03d} | ‚è±Ô∏è {epoch_mins}m {epoch_secs}s | üî• Train: {train_loss:.8f} | üéØ Val: {valid_loss:.8f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"üõë Early stopping triggered.\")\n",
        "                break\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CwcTHPshqu0O",
        "outputId": "b2126bd7-4bf5-4fd9-bc4e-c624f6862081"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "context has already been set",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-2955739462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context has already been set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_paths()\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"üì¶ Loading datasets...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self.prepare_loaders()\n",
        "\n",
        "    def setup_paths(self):\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
        "\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "    def prepare_loaders(self):\n",
        "        train_path = os.path.join(self.dataset_dir, \"train_dataset.hdf5\")\n",
        "        valid_path = os.path.join(self.dataset_dir, \"valid_dataset.hdf5\")\n",
        "        test_path = os.path.join(self.dataset_dir, \"test_dataset.hdf5\")\n",
        "\n",
        "        train_transform = StrongJointTransform3D()\n",
        "\n",
        "        train_dataset = HDF5SegmentationDataset3D(train_path, transform=train_transform)\n",
        "        valid_dataset = HDF5SegmentationDataset3D(valid_path, transform=None)\n",
        "        test_dataset  = HDF5SegmentationDataset3D(test_path, transform=None)\n",
        "\n",
        "        sampler = BalancedTumorSampler(\n",
        "            train_dataset,\n",
        "            tumor_ratio=0.5,\n",
        "            shuffle=True,\n",
        "            index_cache_path=os.path.join(self.dataset_dir, 'tumor_indices.pkl')\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "        test_loader  = DataLoader(test_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        print(f\"‚úÖ Dataset sizes ‚Äî Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    def train(self):\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        model = UNet3D(in_channels=1, out_channels=1).to(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        self.train()\n",
        "        self.test()\n",
        "\n",
        "\n",
        "def main():\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_3D_PreProcessedCT_Uniform_Volume_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\n",
        "        'transformation': \"PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 2,\n",
        "        'num_epochs': 100,\n",
        "        'learning_rate': 1e-5,\n",
        "    }\n",
        "\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMSmkuYHZX7U3MpY05Gfka7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}