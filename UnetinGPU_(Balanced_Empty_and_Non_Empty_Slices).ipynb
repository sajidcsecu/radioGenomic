{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO3d0DpcInDWgRs1xFMeuiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/UnetinGPU_(Balanced_Empty_and_Non_Empty_Slices).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 2D slices over GPU"
      ],
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) Import Required Libraries"
      ],
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "outputId": "68f9f498-377a-4db7-9797-ce410af97994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.1)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) Import required Libraries"
      ],
      "metadata": {
        "id": "JadHvjQcJ-qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "from typing import List\n",
        "import torch.multiprocessing as mp\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torch.amp as amp\n",
        "import pickle\n",
        "from torch.utils.data import Sampler"
      ],
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) Mount Google Drive"
      ],
      "metadata": {
        "id": "uyzguRDWI9bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lq6jVaaMXZz5",
        "outputId": "4b8d1bd9-02b5-4a30-c75b-9eadc8466657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) Data Preperation"
      ],
      "metadata": {
        "id": "p4PdRsL8DChf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedTumorSampler(Sampler):\n",
        "    def __init__(self, dataset, tumor_ratio=0.5, shuffle=True, index_cache_path=None):\n",
        "        self.dataset = dataset\n",
        "        self.tumor_ratio = tumor_ratio\n",
        "        self.shuffle = shuffle\n",
        "        self.index_cache_path = index_cache_path\n",
        "\n",
        "        self.tumor_indices = []\n",
        "        self.non_tumor_indices = []\n",
        "\n",
        "        if index_cache_path and os.path.exists(index_cache_path):\n",
        "            print(f\"üìÇ Loading cached indices from {index_cache_path}\")\n",
        "            with open(index_cache_path, 'rb') as f:\n",
        "                cached = pickle.load(f)\n",
        "                self.tumor_indices = cached['tumor']\n",
        "                self.non_tumor_indices = cached['non_tumor']\n",
        "            print(f\"‚úÖ Loaded: {len(self.tumor_indices)} tumor, {len(self.non_tumor_indices)} non-tumor\")\n",
        "        else:\n",
        "            print(\"üõ†Ô∏è Computing tumor/non-tumor indices...\")\n",
        "            self._prepare_indices()\n",
        "            if index_cache_path:\n",
        "                print(f\"üíæ Saving indices to {index_cache_path}\")\n",
        "                with open(index_cache_path, 'wb') as f:\n",
        "                    pickle.dump({'tumor': self.tumor_indices, 'non_tumor': self.non_tumor_indices}, f)\n",
        "\n",
        "    def _prepare_indices(self):\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, mask = self.dataset[idx]\n",
        "            if mask.sum() > 0:\n",
        "                self.tumor_indices.append(idx)\n",
        "            else:\n",
        "                self.non_tumor_indices.append(idx)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.tumor_indices)\n",
        "            random.shuffle(self.non_tumor_indices)\n",
        "\n",
        "        total_samples = min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n",
        "        num_tumor = int(self.tumor_ratio * total_samples)\n",
        "        num_non_tumor = total_samples - num_tumor\n",
        "\n",
        "        selected_tumor = self.tumor_indices[:num_tumor]\n",
        "        selected_non_tumor = self.non_tumor_indices[:num_non_tumor]\n",
        "\n",
        "        combined = selected_tumor + selected_non_tumor\n",
        "        if self.shuffle:\n",
        "            random.shuffle(combined)\n",
        "\n",
        "        return iter(combined)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n"
      ],
      "metadata": {
        "id": "FvhtapeukPgt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDF5SegmentationDataset(Dataset):\n",
        "    def __init__(self, hdf5_path, transform=None):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.patient_ids = []\n",
        "\n",
        "        # Read only keys for indexing\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            self.patient_ids = list(f.keys())\n",
        "            self.slice_indices = [(pid, i) for pid in self.patient_ids for i in range(f[pid]['ct'].shape[0])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid, slice_idx = self.slice_indices[idx]\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            ct_slice = f[pid]['ct'][slice_idx]\n",
        "            mask_slice = f[pid]['mask'][slice_idx]\n",
        "\n",
        "        # Normalize CT to [0, 1]\n",
        "        ct_slice = (ct_slice - np.min(ct_slice)) / (np.max(ct_slice) - np.min(ct_slice) + 1e-5)\n",
        "\n",
        "        # Convert to torch tensors and add channel dim\n",
        "        ct_tensor = torch.tensor(ct_slice, dtype=torch.float32).unsqueeze(0)\n",
        "        mask_tensor = torch.tensor(mask_slice, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            ct_tensor, mask_tensor = self.transform(ct_tensor, mask_tensor)\n",
        "\n",
        "        return ct_tensor, mask_tensor"
      ],
      "metadata": {
        "id": "ZoGkyWq93X-H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Unet"
      ],
      "metadata": {
        "id": "h2iHKHfcF3yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        p = self.pool(x)\n",
        "        return x, self.dropout(p)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.up = UpSample(in_channels, out_channels)\n",
        "        self.conv = DoubleConv(out_channels * 2, out_channels)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.e1 = EncoderBlock(in_channels, 64, dropout=dropout)\n",
        "        self.e2 = EncoderBlock(64, 128, dropout=dropout)\n",
        "        self.e3 = EncoderBlock(128, 256, dropout=dropout)\n",
        "        self.e4 = EncoderBlock(256, 512, dropout=dropout)\n",
        "\n",
        "        self.b = DoubleConv(512, 1024)\n",
        "        self.dropout_bottleneck = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.d1 = DecoderBlock(1024, 512, dropout=dropout)\n",
        "        self.d2 = DecoderBlock(512, 256, dropout=dropout)\n",
        "        self.d3 = DecoderBlock(256, 128, dropout=dropout)\n",
        "        self.d4 = DecoderBlock(128, 64, dropout=dropout)\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.e1(x)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        b = self.b(p4)\n",
        "        b = self.dropout_bottleneck(b)\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        return self.outputs(d4)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # double_conv = DoubleConv(256, 256)\n",
        "#     # print(double_conv)\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     input_image = torch.randn((1, 1, 512, 512), dtype=torch.float32)\n",
        "#     model = UNet(1, 1).to(device)\n",
        "#     input_image = input_image.to(device)\n",
        "#     out = model(input_image)\n",
        "#     print(out.shape)\n",
        "#     print(device)\n",
        "#     print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "PamAo5NoFsRv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loss Function"
      ],
      "metadata": {
        "id": "IFrRJqgG7wxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = torch.sigmoid(preds)\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (preds * targets).sum()\n",
        "        dice_score = (2. * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        return 1 - dice_score\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (torch.sigmoid(preds) * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (torch.sigmoid(preds).sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return bce_loss + dice_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Test"
      ],
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str,metrics_csv, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.device = device\n",
        "        self.metrics_csv = metrics_csv\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Initialize CSV file with headers\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, mode='w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "        print(f\"Test results will be saved to: {self.test_result_path}\")\n",
        "        print(f\"Using device: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> List[float]:\n",
        "        # Apply sigmoid and threshold at 0.5\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        y_true_np = y_true.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "\n",
        "        # If ground truth is completely empty or prediction is empty, set zero_division=0 for clarity\n",
        "        return [\n",
        "            jaccard_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            f1_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            recall_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            precision_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            accuracy_score(y_true_np, y_pred_np)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def save_result(self, image: torch.Tensor, org_mask: torch.Tensor, predicted_mask: torch.Tensor, sample_id: int) -> None:\n",
        "        predicted_mask = (predicted_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        org_mask = (org_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        image = (image.detach().cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "        h, w = image.shape\n",
        "        line = np.ones((h, 10), dtype=np.uint8) * 128\n",
        "        cat_images = np.concatenate([image, line, org_mask, line, predicted_mask], axis=1)\n",
        "\n",
        "        file_name = os.path.join(self.test_result_path, f\"sample_{sample_id}.png\")\n",
        "        success = cv2.imwrite(file_name, cat_images)\n",
        "\n",
        "        if success:\n",
        "            print(f\"‚úÖ Saved: {file_name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to save image: {file_name}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: int, metrics: List[float], elapsed_time: float) -> None:\n",
        "        with open(self.metrics_csv, mode='a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> None:\n",
        "        model.eval()\n",
        "        metrics_score = np.zeros(5)\n",
        "        time_taken = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pid, (x, y) in enumerate(test_loader):\n",
        "                if (pid >=2):\n",
        "                  break\n",
        "                x = x.to(self.device, dtype=torch.float32)\n",
        "                y = y.to(self.device, dtype=torch.float32)\n",
        "\n",
        "                start_time = time.time()\n",
        "                y_pred = torch.sigmoid(model(x))\n",
        "                elapsed_time = time.time() - start_time\n",
        "                time_taken.append(elapsed_time)\n",
        "\n",
        "                batch_metrics = self.calculate_metrics(y, y_pred)\n",
        "                metrics_score += np.array(batch_metrics)\n",
        "\n",
        "                for idx in range(x.size(0)):\n",
        "                    sample_id = pid * x.size(0) + idx\n",
        "                    self.save_result(x[idx], y[idx], y_pred[idx], sample_id)\n",
        "                    self.append_metrics_to_csv(sample_id, batch_metrics, elapsed_time)\n",
        "\n",
        "        num_batches = len(test_loader)\n",
        "        avg_metrics = metrics_score / num_batches\n",
        "\n",
        "        print(f\"\\nüß™ Total Batches in Test Set: {num_batches}\")\n",
        "        print(f\"üìä Jaccard: {avg_metrics[0]:.4f} | F1: {avg_metrics[1]:.4f} | Recall: {avg_metrics[2]:.4f} | \"\n",
        "              f\"Precision: {avg_metrics[3]:.4f} | Accuracy: {avg_metrics[4]:.4f}\")\n",
        "        print(f\"‚ö° FPS: {1 / np.mean(time_taken):.2f}\")\n"
      ],
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"‚è≥ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "            self.counter = 0\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, epoch, optimizer):\n",
        "        if self.verbose:\n",
        "            print(f\"‚úÖ Valid loss improved. Saving model...\")\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self,\n",
        "                 model_file: str,\n",
        "                 loss_result_path: str,\n",
        "                 lr: float,\n",
        "                 num_epochs: int,\n",
        "                 device: torch.device):\n",
        "\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "\n",
        "        # For reproducibility\n",
        "        self.seeding(42)\n",
        "\n",
        "        print(f\"üîß Training initialized: lr={self.lr}, epochs={self.num_epochs}\")\n",
        "        print(f\"üìÅ Model will be saved to: {self.model_file}\")\n",
        "        print(f\"üìÅ Loss log will be saved to: {self.loss_result_path}\")\n",
        "        print(f\"üíª Device in use: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "    def train(self, model, loader, optimizer, loss_fn, device):\n",
        "        scaler = amp.GradScaler()\n",
        "        epoch_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            if (batch_idx >=10):\n",
        "                  break\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(device_type=self.device.type):\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn, device):\n",
        "        epoch_loss = 0.0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x, y) in enumerate(loader):\n",
        "                if (batch_idx >=2):\n",
        "                    break\n",
        "                x = x.to(device, dtype=torch.float32)\n",
        "                y = y.to(device, dtype=torch.float32)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = UNet(in_channels=1, out_channels=1, dropout=0.3).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = DiceBCELoss()\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=10, min_delta=0.001, path=self.model_file)\n",
        "        results = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        for epoch in tqdm(range(1, self.num_epochs + 1), desc=\"üèãÔ∏è Training\"):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train(model, train_loader, optimizer, loss_fn, self.device)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn, self.device)\n",
        "            scheduler.step()\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "            results[\"train_loss\"].append(train_loss)\n",
        "            results[\"valid_loss\"].append(valid_loss)\n",
        "\n",
        "            print(f\"üìÖ Epoch {epoch:03d} | ‚è±Ô∏è {epoch_mins}m {epoch_secs}s | üî• Train: {train_loss:.4f} | üéØ Val: {valid_loss:.4f}\")\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"üõë Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Save train/val loss history to CSV\n",
        "        with open(self.loss_result_path, \"w\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\"] + list(range(1, len(results[\"train_loss\"]) + 1)))\n",
        "            writer.writerow([\"Train Loss\"] + results[\"train_loss\"])\n",
        "            writer.writerow([\"Valid Loss\"] + results[\"valid_loss\"])\n"
      ],
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Set working directory\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    print(\"üìÅ Current Directory:\", os.getcwd())\n",
        "\n",
        "    # Training configuration\n",
        "    batch_size = 16\n",
        "    num_epochs = 100\n",
        "    lr = 1e-4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transformation = \"OriginalCT_With_Empty_NonEmpty_slices_In_Train\"\n",
        "\n",
        "    # Define paths\n",
        "    output_dir = os.path.join(\".\",\"results\",f\"Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    loss_result_file = os.path.join(output_dir, \"train_and_valid_loss_results.csv\")\n",
        "    model_file = os.path.join(output_dir, \"model.pth\")\n",
        "    test_metrics_file = os.path.join(output_dir, \"test_metrics.csv\")\n",
        "    test_result_path = os.path.join(output_dir, \"test_outputs\")\n",
        "    os.makedirs(test_result_path, exist_ok=True)\n",
        "\n",
        "    DATASET_DIR = f\"./datasets/Datasets_{transformation}\"\n",
        "    train_path = os.path.join(DATASET_DIR, \"train_dataset.hdf5\")\n",
        "    valid_path = os.path.join(DATASET_DIR, \"valid_dataset.hdf5\")\n",
        "    test_path = os.path.join(DATASET_DIR, \"test_dataset.hdf5\")\n",
        "\n",
        "    print(\"üì¶ Loading datasets...\")\n",
        "    train_dataset = HDF5SegmentationDataset(train_path)\n",
        "    valid_dataset = HDF5SegmentationDataset(valid_path)\n",
        "    test_dataset = HDF5SegmentationDataset(test_path)\n",
        "\n",
        "    sampler = BalancedTumorSampler(train_dataset,\n",
        "                               tumor_ratio=0.5,\n",
        "                               shuffle=True,\n",
        "                               index_cache_path=f'{DATASET_DIR}/tumor_indices.pkl')\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,num_workers=0, pin_memory=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    print(f\"‚úÖ Dataset sizes ‚Äî Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize and run training\n",
        "    trainer = UnetTrain(\n",
        "        model_file=model_file,\n",
        "        loss_result_path=loss_result_file,\n",
        "        lr=lr,\n",
        "        num_epochs=num_epochs,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    trainer.execute(train_loader, valid_loader)\n",
        "\n",
        "    # Load best model for testing\n",
        "    model = UNet(in_channels=1, out_channels=1).to(device)\n",
        "    checkpoint = torch.load(model_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Test and save metrics\n",
        "    tester = UnetTest(test_result_path,test_metrics_file,device)\n",
        "    tester.test(model, test_loader)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')  # Required for some multiprocessing backends\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwcTHPshqu0O",
        "outputId": "80ff4b01-e6a5-41b2-c1d7-bdff44030e52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "üì¶ Loading datasets...\n",
            "üìÇ Loading cached indices from ./datasets/Datasets_OriginalCT_With_Empty_NonEmpty_slices_In_Train/tumor_indices.pkl\n",
            "‚úÖ Loaded: 5858 tumor, 35476 non-tumor\n",
            "‚úÖ Dataset sizes ‚Äî Train: 41334, Valid: 5141, Test: 4653\n",
            "üîß Training initialized: lr=0.0001, epochs=100\n",
            "üìÅ Model will be saved to: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/model.pth\n",
            "üìÅ Loss log will be saved to: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/train_and_valid_loss_results.csv\n",
            "üíª Device in use: cuda (CUDA available: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 001 | ‚è±Ô∏è 1m 6s | üî• Train: 0.0233 | üéØ Val: 0.0108\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:   2%|‚ñè         | 2/100 [01:56<1:32:44, 56.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 002 | ‚è±Ô∏è 0m 49s | üî• Train: 0.0214 | üéØ Val: 0.0109\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 003 | ‚è±Ô∏è 0m 37s | üî• Train: 0.0204 | üéØ Val: 0.0097\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:   4%|‚ñç         | 4/100 [03:24<1:17:59, 48.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 004 | ‚è±Ô∏è 0m 49s | üî• Train: 0.0198 | üéØ Val: 0.0090\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   5%|‚ñå         | 5/100 [03:58<1:09:02, 43.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 005 | ‚è±Ô∏è 0m 34s | üî• Train: 0.0195 | üéØ Val: 0.0088\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "üìÖ Epoch 006 | ‚è±Ô∏è 0m 34s | üî• Train: 0.0192 | üéØ Val: 0.0087\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:   7%|‚ñã         | 7/100 [05:11<1:01:21, 39.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 007 | ‚è±Ô∏è 0m 36s | üî• Train: 0.0192 | üéØ Val: 0.0087\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   8%|‚ñä         | 8/100 [05:40<55:38, 36.29s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 008 | ‚è±Ô∏è 0m 29s | üî• Train: 0.0191 | üéØ Val: 0.0086\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   9%|‚ñâ         | 9/100 [06:07<50:47, 33.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 009 | ‚è±Ô∏è 0m 27s | üî• Train: 0.0190 | üéØ Val: 0.0086\n",
            "‚è≥ EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  10%|‚ñà         | 10/100 [06:35<47:21, 31.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 010 | ‚è±Ô∏è 0m 27s | üî• Train: 0.0190 | üéØ Val: 0.0086\n",
            "‚è≥ EarlyStopping counter: 4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  11%|‚ñà         | 11/100 [07:02<44:43, 30.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 011 | ‚è±Ô∏è 0m 26s | üî• Train: 0.0189 | üéØ Val: 0.0085\n",
            "‚è≥ EarlyStopping counter: 5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  12%|‚ñà‚ñè        | 12/100 [07:30<43:26, 29.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 012 | ‚è±Ô∏è 0m 28s | üî• Train: 0.0187 | üéØ Val: 0.0084\n",
            "‚è≥ EarlyStopping counter: 6 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  13%|‚ñà‚ñé        | 13/100 [07:54<40:31, 27.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 013 | ‚è±Ô∏è 0m 24s | üî• Train: 0.0186 | üéØ Val: 0.0084\n",
            "‚è≥ EarlyStopping counter: 7 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  14%|‚ñà‚ñç        | 14/100 [08:20<39:04, 27.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 014 | ‚è±Ô∏è 0m 25s | üî• Train: 0.0185 | üéØ Val: 0.0084\n",
            "‚è≥ EarlyStopping counter: 8 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  15%|‚ñà‚ñå        | 15/100 [08:44<37:19, 26.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 015 | ‚è±Ô∏è 0m 24s | üî• Train: 0.0184 | üéØ Val: 0.0084\n",
            "‚è≥ EarlyStopping counter: 9 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  15%|‚ñà‚ñå        | 15/100 [09:08<51:50, 36.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 016 | ‚è±Ô∏è 0m 24s | üî• Train: 0.0183 | üéØ Val: 0.0084\n",
            "‚è≥ EarlyStopping counter: 10 out of 10\n",
            "üõë Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results will be saved to: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs\n",
            "Using device: cuda (CUDA available: True)\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_0.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_1.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_2.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_3.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_4.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_5.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_6.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_7.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_8.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_9.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_10.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_11.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_12.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_13.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_14.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_15.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_16.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_17.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_18.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_19.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_20.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_21.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_22.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_23.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_24.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_25.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_26.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_27.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_28.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_29.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_30.png\n",
            "‚úÖ Saved: ./results/Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train/test_outputs/sample_31.png\n",
            "\n",
            "üß™ Total Batches in Test Set: 291\n",
            "üìä Jaccard: 0.0000 | F1: 0.0000 | Recall: 0.0000 | Precision: 0.0000 | Accuracy: 0.0069\n",
            "‚ö° FPS: 219.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}