{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPy8fqQxlmLCbzBC+9yJU3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/UnetinGPU_(Empty_and_Non_Empty_Slices).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 2D slices over GPU. The train dataset is considered in empty and nonempty slices."
      ],
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) Import Required Libraries"
      ],
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "outputId": "530ec3ec-6cfc-4ba6-db65-6847b89d831e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.1)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.1.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.1.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) Import required Libraries"
      ],
      "metadata": {
        "id": "JadHvjQcJ-qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "from typing import List\n",
        "import torch.multiprocessing as mp\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torch.amp as amp\n",
        "from torch.utils.data import Sampler\n",
        "import random"
      ],
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) Mount Google Drive"
      ],
      "metadata": {
        "id": "uyzguRDWI9bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lq6jVaaMXZz5",
        "outputId": "0ba1a240-86bb-44fe-aec2-9418ddcda61a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) Data Preperation"
      ],
      "metadata": {
        "id": "p4PdRsL8DChf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HDF5SegmentationDataset(Dataset):\n",
        "    def __init__(self, hdf5_path, transform=None):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.patient_ids = []\n",
        "\n",
        "        # Read only keys for indexing\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            self.patient_ids = list(f.keys())\n",
        "            self.slice_indices = [(pid, i) for pid in self.patient_ids for i in range(f[pid]['ct'].shape[0])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid, slice_idx = self.slice_indices[idx]\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            ct_slice = f[pid]['ct'][slice_idx]\n",
        "            mask_slice = f[pid]['mask'][slice_idx]\n",
        "\n",
        "        # Normalize CT to [0, 1]\n",
        "        ct_slice = (ct_slice - np.min(ct_slice)) / (np.max(ct_slice) - np.min(ct_slice) + 1e-5)\n",
        "\n",
        "        # Convert to torch tensors and add channel dim\n",
        "        ct_tensor = torch.tensor(ct_slice, dtype=torch.float32).unsqueeze(0)\n",
        "        mask_tensor = torch.tensor(mask_slice, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            ct_tensor, mask_tensor = self.transform(ct_tensor, mask_tensor)\n",
        "\n",
        "        return ct_tensor, mask_tensor"
      ],
      "metadata": {
        "id": "ZoGkyWq93X-H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Unet"
      ],
      "metadata": {
        "id": "h2iHKHfcF3yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        p = self.pool(x)\n",
        "        return x, self.dropout(p)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.up = UpSample(in_channels, out_channels)\n",
        "        self.conv = DoubleConv(out_channels * 2, out_channels)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.e1 = EncoderBlock(in_channels, 64, dropout=dropout)\n",
        "        self.e2 = EncoderBlock(64, 128, dropout=dropout)\n",
        "        self.e3 = EncoderBlock(128, 256, dropout=dropout)\n",
        "        self.e4 = EncoderBlock(256, 512, dropout=dropout)\n",
        "\n",
        "        self.b = DoubleConv(512, 1024)\n",
        "        self.dropout_bottleneck = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.d1 = DecoderBlock(1024, 512, dropout=dropout)\n",
        "        self.d2 = DecoderBlock(512, 256, dropout=dropout)\n",
        "        self.d3 = DecoderBlock(256, 128, dropout=dropout)\n",
        "        self.d4 = DecoderBlock(128, 64, dropout=dropout)\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.e1(x)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        b = self.b(p4)\n",
        "        b = self.dropout_bottleneck(b)\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        return self.outputs(d4)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # double_conv = DoubleConv(256, 256)\n",
        "#     # print(double_conv)\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     input_image = torch.randn((1, 1, 512, 512), dtype=torch.float32)\n",
        "#     model = UNet(1, 1).to(device)\n",
        "#     input_image = input_image.to(device)\n",
        "#     out = model(input_image)\n",
        "#     print(out.shape)\n",
        "#     print(device)\n",
        "#     print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "PamAo5NoFsRv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loss Function"
      ],
      "metadata": {
        "id": "IFrRJqgG7wxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = torch.sigmoid(preds)\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (preds * targets).sum()\n",
        "        dice_score = (2. * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        return 1 - dice_score\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (torch.sigmoid(preds) * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (torch.sigmoid(preds).sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return bce_loss + dice_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Test"
      ],
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str,metrics_csv, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.device = device\n",
        "        self.metrics_csv = metrics_csv\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Initialize CSV file with headers\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, mode='w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "        print(f\"Test results will be saved to: {self.test_result_path}\")\n",
        "        print(f\"Using device: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> List[float]:\n",
        "        # Apply sigmoid and threshold at 0.5\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        y_true_np = y_true.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "\n",
        "        # If ground truth is completely empty or prediction is empty, set zero_division=0 for clarity\n",
        "        return [\n",
        "            jaccard_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            f1_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            recall_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            precision_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            accuracy_score(y_true_np, y_pred_np)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def save_result(self, image: torch.Tensor, org_mask: torch.Tensor, predicted_mask: torch.Tensor, sample_id: int) -> None:\n",
        "        predicted_mask = (predicted_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        org_mask = (org_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        image = (image.detach().cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "        h, w = image.shape\n",
        "        line = np.ones((h, 10), dtype=np.uint8) * 128\n",
        "        cat_images = np.concatenate([image, line, org_mask, line, predicted_mask], axis=1)\n",
        "\n",
        "        file_name = os.path.join(self.test_result_path, f\"sample_{sample_id}.png\")\n",
        "        success = cv2.imwrite(file_name, cat_images)\n",
        "\n",
        "        if success:\n",
        "            print(f\"✅ Saved: {file_name}\")\n",
        "        else:\n",
        "            print(f\"❌ Failed to save image: {file_name}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: int, metrics: List[float], elapsed_time: float) -> None:\n",
        "        with open(self.metrics_csv, mode='a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> None:\n",
        "        model.eval()\n",
        "        metrics_score = np.zeros(5)\n",
        "        time_taken = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pid, (x, y) in enumerate(test_loader):\n",
        "                if (pid >=2):\n",
        "                  break\n",
        "                x = x.to(self.device, dtype=torch.float32)\n",
        "                y = y.to(self.device, dtype=torch.float32)\n",
        "\n",
        "                start_time = time.time()\n",
        "                y_pred = torch.sigmoid(model(x))\n",
        "                elapsed_time = time.time() - start_time\n",
        "                time_taken.append(elapsed_time)\n",
        "\n",
        "                batch_metrics = self.calculate_metrics(y, y_pred)\n",
        "                metrics_score += np.array(batch_metrics)\n",
        "\n",
        "                for idx in range(x.size(0)):\n",
        "                    sample_id = pid * x.size(0) + idx\n",
        "                    self.save_result(x[idx], y[idx], y_pred[idx], sample_id)\n",
        "                    self.append_metrics_to_csv(sample_id, batch_metrics, elapsed_time)\n",
        "\n",
        "        num_batches = len(test_loader)\n",
        "        avg_metrics = metrics_score / num_batches\n",
        "\n",
        "        print(f\"\\n🧪 Total Batches in Test Set: {num_batches}\")\n",
        "        print(f\"📊 Jaccard: {avg_metrics[0]:.4f} | F1: {avg_metrics[1]:.4f} | Recall: {avg_metrics[2]:.4f} | \"\n",
        "              f\"Precision: {avg_metrics[3]:.4f} | Accuracy: {avg_metrics[4]:.4f}\")\n",
        "        print(f\"⚡ FPS: {1 / np.mean(time_taken):.2f}\")\n"
      ],
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"⏳ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "            self.counter = 0\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, epoch, optimizer):\n",
        "        if self.verbose:\n",
        "            print(f\"✅ Valid loss improved. Saving model...\")\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self,\n",
        "                 model_file: str,\n",
        "                 loss_result_path: str,\n",
        "                 lr: float,\n",
        "                 num_epochs: int,\n",
        "                 device: torch.device):\n",
        "\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "\n",
        "        # For reproducibility\n",
        "        self.seeding(42)\n",
        "\n",
        "        print(f\"🔧 Training initialized: lr={self.lr}, epochs={self.num_epochs}\")\n",
        "        print(f\"📁 Model will be saved to: {self.model_file}\")\n",
        "        print(f\"📁 Loss log will be saved to: {self.loss_result_path}\")\n",
        "        print(f\"💻 Device in use: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "    def train(self, model, loader, optimizer, loss_fn, device):\n",
        "        scaler = amp.GradScaler()\n",
        "        epoch_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            if (batch_idx >=10):\n",
        "                  break\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(device_type=self.device.type):\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn, device):\n",
        "        epoch_loss = 0.0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x, y) in enumerate(loader):\n",
        "                if (batch_idx >=2):\n",
        "                    break\n",
        "                x = x.to(device, dtype=torch.float32)\n",
        "                y = y.to(device, dtype=torch.float32)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = UNet(in_channels=1, out_channels=1, dropout=0.3).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = DiceBCELoss()\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=10, min_delta=0.001, path=self.model_file)\n",
        "        results = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        for epoch in tqdm(range(1, self.num_epochs + 1), desc=\"🏋️ Training\"):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train(model, train_loader, optimizer, loss_fn, self.device)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn, self.device)\n",
        "            scheduler.step()\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "            results[\"train_loss\"].append(train_loss)\n",
        "            results[\"valid_loss\"].append(valid_loss)\n",
        "\n",
        "            print(f\"📅 Epoch {epoch:03d} | ⏱️ {epoch_mins}m {epoch_secs}s | 🔥 Train: {train_loss:.4f} | 🎯 Val: {valid_loss:.4f}\")\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"🛑 Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Save train/val loss history to CSV\n",
        "        with open(self.loss_result_path, \"w\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\"] + list(range(1, len(results[\"train_loss\"]) + 1)))\n",
        "            writer.writerow([\"Train Loss\"] + results[\"train_loss\"])\n",
        "            writer.writerow([\"Valid Loss\"] + results[\"valid_loss\"])\n"
      ],
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Set working directory\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    print(\"📁 Current Directory:\", os.getcwd())\n",
        "\n",
        "    # Training configuration\n",
        "    batch_size = 16\n",
        "    num_epochs = 50\n",
        "    lr = 1e-4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transformation = \"OriginalCT_With_Empty_NonEmpty_slices_In_Train\"\n",
        "\n",
        "    # Define paths\n",
        "    output_dir = os.path.join(\".\",\"results\",f\"Results_{transformation}\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    loss_result_file = os.path.join(output_dir, \"train_and_valid_loss_results.csv\")\n",
        "    model_file = os.path.join(output_dir, \"model.pth\")\n",
        "    test_metrics_file = os.path.join(output_dir, \"test_metrics.csv\")\n",
        "    test_result_path = os.path.join(output_dir, \"test_outputs\")\n",
        "    os.makedirs(test_result_path, exist_ok=True)\n",
        "\n",
        "    DATASET_DIR = f\"./datasets/Datasets_{transformation}\"\n",
        "    train_path = os.path.join(DATASET_DIR, \"train_dataset.hdf5\")\n",
        "    valid_path = os.path.join(DATASET_DIR, \"valid_dataset.hdf5\")\n",
        "    test_path = os.path.join(DATASET_DIR, \"test_dataset.hdf5\")\n",
        "\n",
        "    print(\"📦 Loading datasets...\")\n",
        "    train_dataset = HDF5SegmentationDataset(train_path)\n",
        "    valid_dataset = HDF5SegmentationDataset(valid_path)\n",
        "    test_dataset = HDF5SegmentationDataset(test_path)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    print(f\"✅ Dataset sizes — Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize and run training\n",
        "    trainer = UnetTrain(\n",
        "        model_file=model_file,\n",
        "        loss_result_path=loss_result_file,\n",
        "        lr=lr,\n",
        "        num_epochs=num_epochs,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    trainer.execute(train_loader, valid_loader)\n",
        "\n",
        "    # Load best model for testing\n",
        "    model = UNet(in_channels=1, out_channels=1).to(device)\n",
        "    checkpoint = torch.load(model_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Test and save metrics\n",
        "    tester = UnetTest(test_result_path,test_metrics_file,device)\n",
        "    tester.test(model, test_loader)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')  # Required for some multiprocessing backends\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwcTHPshqu0O",
        "outputId": "42b6b6ea-6d9c-4dad-9d07-231841f4c553"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "📦 Loading datasets...\n",
            "✅ Dataset sizes — Train: 41334, Valid: 5141, Test: 4653\n",
            "🔧 Training initialized: lr=0.0001, epochs=50\n",
            "📁 Model will be saved to: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/model.pth\n",
            "📁 Loss log will be saved to: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/train_and_valid_loss_results.csv\n",
            "💻 Device in use: cuda (CUDA available: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:   0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 001 | ⏱️ 1m 2s | 🔥 Train: 0.0066 | 🎯 Val: 0.0108\n",
            "✅ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🏋️ Training:   4%|▍         | 2/50 [02:09<51:06, 63.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 002 | ⏱️ 0m 59s | 🔥 Train: 0.0061 | 🎯 Val: 0.0108\n",
            "⏳ EarlyStopping counter: 1 out of 10\n",
            "📅 Epoch 003 | ⏱️ 0m 44s | 🔥 Train: 0.0058 | 🎯 Val: 0.0097\n",
            "✅ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🏋️ Training:   8%|▊         | 4/50 [03:38<38:56, 50.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 004 | ⏱️ 0m 43s | 🔥 Train: 0.0057 | 🎯 Val: 0.0090\n",
            "⏳ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  10%|█         | 5/50 [04:15<34:15, 45.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 005 | ⏱️ 0m 36s | 🔥 Train: 0.0056 | 🎯 Val: 0.0088\n",
            "⏳ EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  12%|█▏        | 6/50 [04:48<30:21, 41.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 006 | ⏱️ 0m 33s | 🔥 Train: 0.0055 | 🎯 Val: 0.0087\n",
            "⏳ EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  14%|█▍        | 7/50 [05:23<28:08, 39.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 007 | ⏱️ 0m 34s | 🔥 Train: 0.0055 | 🎯 Val: 0.0087\n",
            "⏳ EarlyStopping counter: 4 out of 10\n",
            "📅 Epoch 008 | ⏱️ 0m 34s | 🔥 Train: 0.0054 | 🎯 Val: 0.0086\n",
            "✅ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🏋️ Training:  18%|█▊        | 9/50 [06:33<25:21, 37.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 009 | ⏱️ 0m 34s | 🔥 Train: 0.0054 | 🎯 Val: 0.0086\n",
            "⏳ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  20%|██        | 10/50 [07:05<23:42, 35.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 010 | ⏱️ 0m 32s | 🔥 Train: 0.0054 | 🎯 Val: 0.0086\n",
            "⏳ EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  22%|██▏       | 11/50 [07:39<22:42, 34.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 011 | ⏱️ 0m 33s | 🔥 Train: 0.0055 | 🎯 Val: 0.0088\n",
            "⏳ EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  24%|██▍       | 12/50 [08:08<21:04, 33.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 012 | ⏱️ 0m 29s | 🔥 Train: 0.0054 | 🎯 Val: 0.0086\n",
            "⏳ EarlyStopping counter: 4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  26%|██▌       | 13/50 [08:45<21:14, 34.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 013 | ⏱️ 0m 37s | 🔥 Train: 0.0053 | 🎯 Val: 0.0086\n",
            "⏳ EarlyStopping counter: 5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  28%|██▊       | 14/50 [09:12<19:14, 32.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 014 | ⏱️ 0m 26s | 🔥 Train: 0.0053 | 🎯 Val: 0.0084\n",
            "⏳ EarlyStopping counter: 6 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  30%|███       | 15/50 [09:38<17:41, 30.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 015 | ⏱️ 0m 26s | 🔥 Train: 0.0053 | 🎯 Val: 0.0084\n",
            "⏳ EarlyStopping counter: 7 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  32%|███▏      | 16/50 [10:02<16:04, 28.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 016 | ⏱️ 0m 23s | 🔥 Train: 0.0052 | 🎯 Val: 0.0084\n",
            "⏳ EarlyStopping counter: 8 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  34%|███▍      | 17/50 [10:27<15:00, 27.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 017 | ⏱️ 0m 24s | 🔥 Train: 0.0052 | 🎯 Val: 0.0083\n",
            "⏳ EarlyStopping counter: 9 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🏋️ Training:  34%|███▍      | 17/50 [10:52<21:06, 38.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📅 Epoch 018 | ⏱️ 0m 24s | 🔥 Train: 0.0052 | 🎯 Val: 0.0083\n",
            "⏳ EarlyStopping counter: 10 out of 10\n",
            "🛑 Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-9-3c5cc5e9d18a>:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results will be saved to: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs\n",
            "Using device: cuda (CUDA available: True)\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_0.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_1.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_2.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_3.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_4.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_5.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_6.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_7.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_8.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_9.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_10.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_11.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_12.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_13.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_14.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_15.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_16.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_17.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_18.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_19.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_20.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_21.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_22.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_23.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_24.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_25.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_26.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_27.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_28.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_29.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_30.png\n",
            "✅ Saved: ./results/Results_OriginalCT_With_Empty_NonEmpty_slices_In_Train/test_outputs/sample_31.png\n",
            "\n",
            "🧪 Total Batches in Test Set: 291\n",
            "📊 Jaccard: 0.0000 | F1: 0.0000 | Recall: 0.0000 | Precision: 0.0000 | Accuracy: 0.0069\n",
            "⚡ FPS: 207.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}