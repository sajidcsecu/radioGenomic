{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DGPU(SS_3DCapsNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU using self-supervised 3D Capsule Net. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the strong augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db420fe-7d80-4218-9b36-62cf22ecd2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (1.26.4)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (1.26.4)\n",
            "Collecting torch<2.7.0,>=2.4.1 (from monai)\n",
            "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.7.0,>=2.4.1->monai) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\n",
            "Downloading monai-1.5.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, monai\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed monai-1.5.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import csv\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.networks.nets import UNet  # keep available if needed elsewhere\n",
        "from monai.networks.layers import Norm\n",
        "from glob import glob\n",
        "from monai.transforms import (\n",
        "            Compose, LoadImaged, EnsureChannelFirstD, Spacingd, Orientationd,\n",
        "            ScaleIntensityRanged, CropForegroundd, Resized, ToTensord,\n",
        "            RandFlipd, RandAffined, RandGaussianNoised, RandScaleIntensityd\n",
        "        )\n",
        "from monai.data import Dataset, DataLoader\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.metrics import DiceMetric"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXsiy9OBTdnk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "05d93e9b-ce58-4fdd-8586-0c913cd2d41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceBCELoss3D(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.flatten()\n",
        "        targets = targets.flatten()\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Validation loss improved. Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"â³ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # Always save a full checkpoint\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6)Squash Function"
      ],
      "metadata": {
        "id": "9uBNJKASgn3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def squash(s, dim=-1, eps=1e-8):\n",
        "    norm = torch.norm(s, dim=dim, keepdim=True)\n",
        "    scale = (norm ** 2) / (1.0 + norm ** 2)\n",
        "    return scale * s / (norm + eps)"
      ],
      "metadata": {
        "id": "FTwuTlFaglo0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (7). Routing By Agreement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class CapsuleLayer3D(nn.Module):\n",
        "    \"\"\"\n",
        "    Capsule layer with dynamic routing.\n",
        "\n",
        "    Args:\n",
        "        num_input_caps (int): Number of input capsules (I).\n",
        "        dim_input_caps (int): Dimensionality of each input capsule (D).\n",
        "        num_output_caps (int): Number of output capsules (O).\n",
        "        dim_output_caps (int): Dimensionality of each output capsule (H).\n",
        "        routing_iters (int): Number of routing iterations.\n",
        "\n",
        "    Inputs:\n",
        "        u: Tensor of shape [B, I, D] (input capsules).\n",
        "\n",
        "    Outputs:\n",
        "        v: Tensor of shape [B, O, H] (output capsules after routing).\n",
        "        c: Tensor of shape [B, I, O] (final coupling coefficients).\n",
        "    \"\"\"\n",
        "    def __init__(self, num_input_caps, dim_input_caps,\n",
        "                 num_output_caps, dim_output_caps,\n",
        "                 routing_iters=3):\n",
        "        super().__init__()\n",
        "        self.num_input_caps = num_input_caps\n",
        "        self.dim_input_caps = dim_input_caps\n",
        "        self.num_output_caps = num_output_caps\n",
        "        self.dim_output_caps = dim_output_caps\n",
        "        self.routing_iters = routing_iters\n",
        "\n",
        "        # Weight matrix W: transforms each input capsule into each output capsule space\n",
        "        # Shape: [I, O, H, D]\n",
        "        self.W = nn.Parameter(\n",
        "            0.01 * torch.randn(num_input_caps, num_output_caps, dim_output_caps, dim_input_caps)\n",
        "        )\n",
        "\n",
        "    def forward(self, u):\n",
        "        \"\"\"\n",
        "        Forward pass through the capsule layer.\n",
        "\n",
        "        Args:\n",
        "            u: [B, I, D] input capsules.\n",
        "\n",
        "        Returns:\n",
        "            v: [B, O, H] output capsules.\n",
        "            c: [B, I, O] coupling coefficients.\n",
        "        \"\"\"\n",
        "        B, I, D = u.shape\n",
        "        O, H = self.num_output_caps, self.dim_output_caps\n",
        "\n",
        "        # (1) Transform input capsules into output capsule space\n",
        "        # Expand u to [B, I, O, D] so it can interact with W\n",
        "        u_expand = u.unsqueeze(2).expand(-1, -1, O, -1)   # [B, I, O, D]\n",
        "        # Predicted capsules u_hat = u Â· W\n",
        "        u_hat = torch.einsum(\"biod,iodh->bioh\", u_expand, self.W)  # [B, I, O, H]\n",
        "\n",
        "        # (2) Routing logits (initially zeros)\n",
        "        b = u.new_zeros(B, I, O)  # [B, I, O]\n",
        "\n",
        "        # (3) Dynamic routing\n",
        "        for r in range(self.routing_iters):\n",
        "            # Coupling coefficients (softmax over output capsules)\n",
        "            c = F.softmax(b, dim=-1)  # [B, I, O]\n",
        "\n",
        "            # Weighted sum of predictions\n",
        "            s = (c.unsqueeze(-1) * u_hat).sum(dim=1)  # [B, O, H]\n",
        "\n",
        "            # Apply squash non-linearity\n",
        "            v = squash(s, dim=-1)\n",
        "\n",
        "            if r < self.routing_iters - 1:\n",
        "                # Update routing logits with agreement\n",
        "                b = b + (u_hat * v.unsqueeze(1)).sum(dim=-1)  # [B, I, O]\n",
        "\n",
        "        return v, c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (8). Converting CT Features into primary capsule"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CwcTHPshqu0O"
      },
      "outputs": [],
      "source": [
        "class PrimaryCaps3DStem(nn.Module):\n",
        "    \"\"\"\n",
        "    Conv3D stem that produces primary capsules from an input patch.\n",
        "    - in_channels: 1 (CT)\n",
        "    - conv_channels: internal feature width\n",
        "    - num_capsules: how many capsule types per spatial location\n",
        "    - capsule_dim: dimension of each primary capsule vector\n",
        "    - downsample: number of stride-2 convs to reduce spatial resolution before forming capsules\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, conv_channels=32, num_capsules=4, capsule_dim=8, downsample=2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        c = conv_channels\n",
        "        layers.append(nn.Conv3d(in_channels, c, kernel_size=3, padding=1, stride=1))\n",
        "        layers.append(nn.InstanceNorm3d(c)); layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(downsample):\n",
        "            layers.append(nn.Conv3d(c, c, kernel_size=3, padding=1, stride=2))\n",
        "            layers.append(nn.InstanceNorm3d(c)); layers.append(nn.ReLU(inplace=True))\n",
        "        # additional conv(s)\n",
        "        layers.append(nn.Conv3d(c, c, kernel_size=3, padding=1, stride=1))\n",
        "        layers.append(nn.InstanceNorm3d(c)); layers.append(nn.ReLU(inplace=True))\n",
        "        self.stem = nn.Sequential(*layers)\n",
        "\n",
        "        # final conv produces num_capsules * capsule_dim channels\n",
        "        self.to_caps = nn.Conv3d(c, num_capsules * capsule_dim, kernel_size=1)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.capsule_dim = capsule_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, D, H, W]\n",
        "        f = self.stem(x)  # f: [B, C, D', H', W']  <-- return this for reconstruction\n",
        "        caps = self.to_caps(f)  # [B, num_caps*capsdim, D', H', W']\n",
        "        B, Ch, Dp, Hp, Wp = caps.shape\n",
        "        caps = caps.view(B, self.num_capsules, self.capsule_dim, Dp, Hp, Wp)\n",
        "        # permute to [B, num_capsules, D', H', W', cap_dim]\n",
        "        caps = caps.permute(0, 1, 3, 4, 5, 2).contiguous()\n",
        "        B, NC, d, h, w, dim = caps.shape\n",
        "        I = NC * d * h * w\n",
        "        caps = caps.view(B, I, dim)  # [B, I, capsule_dim]\n",
        "        spatial_info = (Dp, Hp, Wp, NC) # required to reshape couplings back\n",
        "        return caps, spatial_info, f     # <-- return f"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (9) Decoder"
      ],
      "metadata": {
        "id": "jZeKvkREib-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegCaps3D(nn.Module):\n",
        "    \"\"\"\n",
        "    SegCaps-like 3D segmentation model:\n",
        "      Input patch -> PrimaryCaps3DStem -> CapsuleLayer3D (with W param)\n",
        "      -> voxelwise decision map -> decoder upsampling -> segmentation logits.\n",
        "      Also provides an optional reconstruction head for self-supervised pretraining.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_channels=1,\n",
        "                 conv_channels=32,\n",
        "                 num_capsules=4,\n",
        "                 capsule_dim=8,\n",
        "                 region_caps=2,\n",
        "                 region_dim=8,\n",
        "                 routing_iters=3,\n",
        "                 upsample_mode='trilinear'):\n",
        "        super().__init__()\n",
        "\n",
        "        # Stem: extract low-level conv features + primary capsules\n",
        "        self.stem = PrimaryCaps3DStem(\n",
        "            in_channels, conv_channels, num_capsules, capsule_dim, downsample=2\n",
        "        )\n",
        "\n",
        "        # Capsule layer (lazy init)\n",
        "        self.capsule_layer = None\n",
        "        self.region_caps = region_caps\n",
        "        self.region_dim = region_dim\n",
        "        self.routing_iters = routing_iters\n",
        "        self.upsample_mode = upsample_mode\n",
        "\n",
        "        # Decoder: upsample capsule map to voxel resolution\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose3d(1, 8, kernel_size=2, stride=2),\n",
        "            nn.InstanceNorm3d(8), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose3d(8, 8, kernel_size=2, stride=2),\n",
        "            nn.InstanceNorm3d(8), nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(8, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Reconstruction head (optional, for SS pretraining)\n",
        "        self.recon_head = nn.Sequential(\n",
        "            nn.Conv3d(conv_channels, conv_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm3d(conv_channels), nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(conv_channels, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def _init_capsule_layer(self, num_input_caps, dim_input_caps):\n",
        "        \"\"\"Lazy init capsule layer when input size is known.\"\"\"\n",
        "        if self.capsule_layer is None:\n",
        "            self.capsule_layer = CapsuleLayer3D(\n",
        "                num_input_caps, dim_input_caps,\n",
        "                self.region_caps, self.region_dim,\n",
        "                routing_iters=self.routing_iters\n",
        "            ).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input tensor [B, C, D, H, W]\n",
        "        Returns:\n",
        "            logits: segmentation logits [B, 1, D, H, W]\n",
        "            recon:  reconstruction of input [B, 1, D, H, W]\n",
        "        \"\"\"\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # --- Stem features ---\n",
        "        primary_caps, spatial_info, feat_map = self.stem(x)\n",
        "        Dp, Hp, Wp, NC = spatial_info\n",
        "        I = primary_caps.shape[1]  # number of input capsules\n",
        "        dim = primary_caps.shape[2]\n",
        "\n",
        "        # --- Capsules ---\n",
        "        self._init_capsule_layer(I, dim)\n",
        "        v, c = self.capsule_layer(primary_caps)\n",
        "\n",
        "        # Pick tumor capsule (index 0)\n",
        "        tumor_index = 0\n",
        "        c_tumor = c[..., tumor_index]  # [B, I]\n",
        "\n",
        "        # Reshape to decision map\n",
        "        c_map = c_tumor.view(B, NC, Dp, Hp, Wp)\n",
        "        c_map_avg = c_map.mean(dim=1, keepdim=True)  # [B,1,Dp,Hp,Wp]\n",
        "\n",
        "        # --- Decoder upsampling ---\n",
        "        logits = self.decoder_conv(c_map_avg)  # [B,1,D,H,W]\n",
        "\n",
        "        # --- Reconstruction head ---\n",
        "        recon_coarse = self.recon_head(feat_map)  # [B,1,Dp,Hp,Wp]\n",
        "        recon = F.interpolate(\n",
        "            recon_coarse, size=x.shape[2:], mode=self.upsample_mode, align_corners=False\n",
        "        )  # [B,1,D,H,W]\n",
        "\n",
        "        return logits, recon\n",
        "\n"
      ],
      "metadata": {
        "id": "2pT0lqBmibV7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (10) Test"
      ],
      "metadata": {
        "id": "hjPtR6OUm-wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegCapsTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "        self._init_metrics_csv()\n",
        "\n",
        "    def _init_metrics_csv(self):\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        y_true = y_true.astype(bool).flatten()\n",
        "        y_pred = y_pred.astype(bool).flatten()\n",
        "        return [\n",
        "            jaccard_score(y_true, y_pred, zero_division=0),\n",
        "            f1_score(y_true, y_pred, zero_division=0),\n",
        "            recall_score(y_true, y_pred, zero_division=0),\n",
        "            precision_score(y_true, y_pred, zero_division=0),\n",
        "            accuracy_score(y_true, y_pred)\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image: np.ndarray, pred_mask: np.ndarray, true_mask: np.ndarray, sample_id: str):\n",
        "        sample_dir = os.path.join(self.test_result_path, sample_id)\n",
        "        os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "        for i in range(image.shape[0]):\n",
        "            try:\n",
        "                fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "                ax[0].imshow(image[i], cmap='gray')\n",
        "                ax[0].set_title('Image')\n",
        "\n",
        "                ax[1].imshow(true_mask[i], cmap='gray')\n",
        "                ax[1].set_title('Ground Truth')\n",
        "\n",
        "                ax[2].imshow(pred_mask[i], cmap='gray')\n",
        "                ax[2].set_title('Prediction')\n",
        "\n",
        "                for a in ax: a.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(sample_dir, f'slice_{i:03d}.png'))\n",
        "                plt.close()\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Could not save slice {i} for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(5)\n",
        "        total_times = []\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5  # Binary thresholding\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy()\n",
        "\n",
        "                # Metrics\n",
        "                metrics = self.calculate_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "\n",
        "                # Sample ID\n",
        "                sample_id = os.path.basename(batch[\"vol_meta_dict\"][\"filename_or_obj\"][0]).replace(\".nii.gz\", \"\")\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "        # Print summary\n",
        "        num_samples = len(test_loader)\n",
        "        print(\"\\nðŸ“Š Average Test Metrics:\")\n",
        "        print(f\"Jaccard:  {total_metrics[0]/num_samples:.4f}\")\n",
        "        print(f\"F1:       {total_metrics[1]/num_samples:.4f}\")\n",
        "        print(f\"Recall:   {total_metrics[2]/num_samples:.4f}\")\n",
        "        print(f\"Precision:{total_metrics[3]/num_samples:.4f}\")\n",
        "        print(f\"Accuracy: {total_metrics[4]/num_samples:.4f}\")\n",
        "        print(f\"âš¡ FPS:    {1 / np.mean(total_times):.2f}\")"
      ],
      "metadata": {
        "id": "NwLF1Cigm8Ut"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (11) Training"
      ],
      "metadata": {
        "id": "dqABn_83jIq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Trainer adapted for SegCaps ----------\n",
        "class SegCapsTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device, self_supervised=False, ss_weight=0.1):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        self.self_supervised = self_supervised\n",
        "        self.ss_weight = ss_weight\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        scaler = torch.amp.GradScaler()\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        for batch in loader:\n",
        "            inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast(device_type=device_type):\n",
        "                logits, recon = model(inputs)  # logits: [B,1,D,H,W]\n",
        "                seg_loss = loss_fn(logits, labels)\n",
        "                if self.self_supervised:\n",
        "                    # reconstruction MSE on voxel intensities (compare input and recon)\n",
        "                    recon_loss = F.mse_loss(recon, inputs)\n",
        "                    loss = seg_loss + self.ss_weight * recon_loss\n",
        "                else:\n",
        "                    loss = seg_loss\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                logits, recon = model(inputs)\n",
        "                seg_loss = loss_fn(logits, labels)\n",
        "                if self.self_supervised:\n",
        "                    recon_loss = F.mse_loss(recon, inputs)\n",
        "                    loss = seg_loss + self.ss_weight * recon_loss\n",
        "                else:\n",
        "                    loss = seg_loss\n",
        "                epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = SegCaps3D(\n",
        "            in_channels=1,\n",
        "            conv_channels=32,\n",
        "            num_capsules=4,\n",
        "            capsule_dim=8,\n",
        "            region_caps=2,\n",
        "            region_dim=8,\n",
        "            routing_iters=3\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = DiceBCELoss3D()\n",
        "\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        # resume checkpoint if exists\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        if os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, 'r') as f:\n",
        "                reader = csv.reader(f)\n",
        "                next(reader)\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    last_epoch = int(rows[-1][0])\n",
        "                    start_epoch = last_epoch + 1\n",
        "                    history['train_loss'] = [float(r[1]) for r in rows]\n",
        "                    history['valid_loss'] = [float(r[2]) for r in rows]\n",
        "                    if start_val_loss_min is None:\n",
        "                        start_val_loss_min = min(history['valid_loss'])\n",
        "            backup_path = self.loss_result_path.replace(\".csv\", \"_backup.csv\")\n",
        "            shutil.copy(self.loss_result_path, backup_path)\n",
        "\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "            train_loss = self.train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
        "            print(f\"Epoch {epoch:03d} | Time: {epoch_mins}m {epoch_secs}s | Train: {train_loss:.6f} | Val: {valid_loss:.6f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss); history['valid_loss'].append(valid_loss)\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"ðŸ›‘ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1PXtF5h2jIUF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (12) Pipeline"
      ],
      "metadata": {
        "id": "_1xB5W1Gjb49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Pipeline that mirrors your UnetPipeline but for SegCaps ----------\n",
        "class SegCapsPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.setup_paths()\n",
        "        print(\"ðŸ“¦ Loading datasets...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self.prepare_loaders()\n",
        "\n",
        "    def setup_paths(self):\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "    def prepare_loaders(self):\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        spatial_size = (96, 96, 96)\n",
        "\n",
        "        def get_files(split):\n",
        "            ct = sorted(glob(os.path.join(self.dataset_dir, split, \"ct\", \"*.nii.gz\")))\n",
        "            seg = sorted(glob(os.path.join(self.dataset_dir, split, \"segment\", \"*.nii.gz\")))\n",
        "            return [{\"vol\": c, \"seg\": s} for c, s in zip(ct, seg)]\n",
        "\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=0),\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=1),\n",
        "            RandAffined(keys=[\"vol\", \"seg\"], prob=0.3, rotate_range=(0.1,0.1,0.1), scale_range=(0.1,0.1,0.1), mode=(\"bilinear\",\"nearest\")),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.1),\n",
        "            RandScaleIntensityd(keys=[\"vol\"], factors=0.1, prob=0.5),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"])\n",
        "        ])\n",
        "\n",
        "        base_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"])\n",
        "        ])\n",
        "\n",
        "        train_loader = DataLoader(Dataset(get_files(\"train\"), train_transforms), batch_size=self.config['batch_size'], shuffle=True)\n",
        "        valid_loader = DataLoader(Dataset(get_files(\"valid\"), base_transforms), batch_size=self.config['batch_size'])\n",
        "        test_loader = DataLoader(Dataset(get_files(\"test\"), base_transforms), batch_size=1)\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    def train(self):\n",
        "        trainer = SegCapsTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device,\n",
        "            self_supervised=self.config.get('self_supervised_pretrain', False),\n",
        "            ss_weight=self.config.get('ss_weight', 0.1)\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        # Load model\n",
        "        model = SegCaps3D(\n",
        "            in_channels=1,\n",
        "            conv_channels=32,\n",
        "            num_capsules=4,\n",
        "            capsule_dim=8,\n",
        "            region_caps=2,\n",
        "            region_dim=8,\n",
        "            routing_iters=3\n",
        "        ).to(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
        "\n",
        "        # Run test using SegCapsTest\n",
        "        tester = SegCapsTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        self.train()\n",
        "        self.test()\n",
        "\n",
        "# ---- Example main (adapt config as you had before) ----\n",
        "def main():\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_SegCaps_Augmented\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 2,\n",
        "        'num_epochs': 100,\n",
        "        'learning_rate': 1e-4,\n",
        "        'self_supervised_pretrain': False,\n",
        "        'ss_weight': 0.1\n",
        "    }\n",
        "    pipeline = SegCapsPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TOZ5nlQYjjN5",
        "outputId": "870f513a-68bc-4dd7-db1a-e2d9a116b84f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Loading datasets...\n",
            "Epoch 052 | Time: 80m 2s | Train: 1.058874 | Val: 1.058432\n",
            "âœ… Validation loss improved. Saving model...\n",
            "Epoch 053 | Time: 77m 23s | Train: 1.056699 | Val: 1.055222\n",
            "âœ… Validation loss improved. Saving model...\n",
            "Epoch 054 | Time: 77m 46s | Train: 1.053670 | Val: 1.052430\n",
            "âœ… Validation loss improved. Saving model...\n",
            "Epoch 055 | Time: 78m 11s | Train: 1.051080 | Val: 1.050078\n",
            "âœ… Validation loss improved. Saving model...\n",
            "Epoch 056 | Time: 78m 22s | Train: 1.048905 | Val: 1.048107\n",
            "âœ… Validation loss improved. Saving model...\n",
            "Epoch 057 | Time: 78m 48s | Train: 1.047247 | Val: 1.046712\n",
            "âœ… Validation loss improved. Saving model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    Resized,\n",
        "    CopyItemsd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    SaveImaged,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "# from monai.transforms.utils import SaveTransform\n",
        "\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_ct_dir, input_seg_dir, output_dir, device=\"cuda:0\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_ct_dir = input_ct_dir\n",
        "        self.input_seg_dir = input_seg_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.ct_out_dir = os.path.join(output_dir, \"ct\")\n",
        "        self.seg_out_dir = os.path.join(output_dir, \"segment\")\n",
        "        os.makedirs(self.ct_out_dir, exist_ok=True)\n",
        "        os.makedirs(self.seg_out_dir, exist_ok=True)\n",
        "        self.model_path = model_path\n",
        "        self.model = self._load_model()\n",
        "        set_determinism(seed=42)\n",
        "        self.forward_transforms = self._get_forward_transforms()\n",
        "        self.inverse_transforms = None\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        model.load_state_dict(state_dict.get('model_state_dict', state_dict))\n",
        "\n",
        "        print(f\"âœ… Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_forward_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            CopyItemsd(keys=[\"vol\"], names=[\"vol_meta_dict\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\"], spatial_size=(96, 96, 96)),\n",
        "            EnsureTyped(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _get_inverse_transforms(self):\n",
        "        return Compose([\n",
        "            Invertd(\n",
        "                keys=[\"seg\"],\n",
        "                transform=self.forward_transforms,\n",
        "                orig_keys=[\"vol\"],\n",
        "                meta_keys=[\"vol_meta_dict\"],\n",
        "                nearest_interp=True,\n",
        "                to_tensor=False,\n",
        "            ),\n",
        "            EnsureTyped(keys=[\"seg\"])\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        data = []\n",
        "        for f in os.listdir(self.input_ct_dir):\n",
        "            if f.endswith(('.nii', '.nii.gz')):\n",
        "                ct_path = os.path.join(self.input_ct_dir, f)\n",
        "                data.append({\"vol\": ct_path})\n",
        "        print(f\"ðŸ” Found {len(data)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data, transform=self.forward_transforms), batch_size=1, num_workers=0)\n",
        "\n",
        "    def infer(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                batch = decollate_batch(batch)[0]\n",
        "                vol_meta = batch[\"vol_meta_dict\"]\n",
        "                ct = batch[\"vol\"]\n",
        "\n",
        "                if ct.dim() == 4:\n",
        "                    ct = ct.unsqueeze(0)\n",
        "                ct = ct.to(self.device)\n",
        "\n",
        "                filename = os.path.basename(vol_meta.meta[\"filename_or_obj\"])\n",
        "                orig_vol = nib.load(vol_meta.meta[\"filename_or_obj\"]).get_fdata()\n",
        "                print(f\"ðŸ” Inference on [{i+1}] {filename} | shape = {ct.shape}\")\n",
        "                print(f\"ðŸ” Original volume shape = {orig_vol.shape}\")\n",
        "                pred = self.model(ct)\n",
        "                pred = (torch.sigmoid(pred) > 0.5).float()\n",
        "\n",
        "                print(f\"âœ… Predicted mask shape: {pred.shape}\")\n",
        "\n",
        "                batch[\"seg\"] = pred.cpu().squeeze(0)\n",
        "                print(f\"âœ… Batch shape: {batch['seg'].shape}\")\n",
        "\n",
        "                if self.inverse_transforms is None:\n",
        "                    self.inverse_transforms = self._get_inverse_transforms()\n",
        "\n",
        "                inverted = self.inverse_transforms(batch)\n",
        "                inv_seg = inverted[\"seg\"].squeeze(0).numpy()\n",
        "                inv_seg = (inv_seg > 0.5).astype(np.uint8)\n",
        "                print(f\"âœ… Inverted mask shape: {inv_seg.shape}\")\n",
        "\n",
        "                self._save_nifti(inv_seg, vol_meta, self.seg_out_dir, filename, is_segmentation=True)\n",
        "\n",
        "\n",
        "    def _save_nifti(self, array, meta_tensor, out_dir, filename, is_segmentation=False):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        affine = meta_tensor.meta.get(\"original_affine\", meta_tensor.meta.get(\"affine\", np.eye(4)))\n",
        "        dtype = np.uint8 if is_segmentation else np.float32\n",
        "        nib_img = nib.Nifti1Image(array.astype(dtype), affine)\n",
        "        nib.save(nib_img, os.path.join(out_dir, filename))\n",
        "        print(f\"âœ… Saved: {os.path.join(out_dir, filename)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "z6a0G1DXTIV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a85b9f-c61a-4fd8-b379-3bd00e32c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 89 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG3-01.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (59, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (59, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-01.nii.gz\n",
            "ðŸ” Inference on [2] LUNG3-02.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (57, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (57, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-02.nii.gz\n",
            "ðŸ” Inference on [3] LUNG3-03.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-03.nii.gz\n",
            "ðŸ” Inference on [4] LUNG3-04.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-04.nii.gz\n",
            "ðŸ” Inference on [5] LUNG3-05.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (229, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (229, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-05.nii.gz\n",
            "ðŸ” Inference on [6] LUNG3-06.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-06.nii.gz\n",
            "ðŸ” Inference on [7] LUNG3-07.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (86, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (86, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-07.nii.gz\n",
            "ðŸ” Inference on [8] LUNG3-08.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-08.nii.gz\n",
            "ðŸ” Inference on [9] LUNG3-09.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (140, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (140, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-09.nii.gz\n",
            "ðŸ” Inference on [10] LUNG3-10.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-10.nii.gz\n",
            "ðŸ” Inference on [11] LUNG3-11.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (252, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (252, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-11.nii.gz\n",
            "ðŸ” Inference on [12] LUNG3-12.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (206, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (206, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-12.nii.gz\n",
            "ðŸ” Inference on [13] LUNG3-13.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (71, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (71, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-13.nii.gz\n",
            "ðŸ” Inference on [14] LUNG3-14.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (325, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (325, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-14.nii.gz\n",
            "ðŸ” Inference on [15] LUNG3-15.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (234, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (234, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-15.nii.gz\n",
            "ðŸ” Inference on [16] LUNG3-16.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (192, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (192, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-16.nii.gz\n",
            "ðŸ” Inference on [17] LUNG3-17.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (226, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (226, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-17.nii.gz\n",
            "ðŸ” Inference on [18] LUNG3-18.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-18.nii.gz\n",
            "ðŸ” Inference on [19] LUNG3-19.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-19.nii.gz\n",
            "ðŸ” Inference on [20] LUNG3-20.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (176, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (176, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-20.nii.gz\n",
            "ðŸ” Inference on [21] LUNG3-21.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-21.nii.gz\n",
            "ðŸ” Inference on [22] LUNG3-22.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (236, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (236, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-22.nii.gz\n",
            "ðŸ” Inference on [23] LUNG3-23.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (52, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (52, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-23.nii.gz\n",
            "ðŸ” Inference on [24] LUNG3-24.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-24.nii.gz\n",
            "ðŸ” Inference on [25] LUNG3-25.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (202, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (202, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-25.nii.gz\n",
            "ðŸ” Inference on [26] LUNG3-26.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (83, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (83, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-26.nii.gz\n",
            "ðŸ” Inference on [27] LUNG3-27.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (149, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (149, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-27.nii.gz\n",
            "ðŸ” Inference on [28] LUNG3-28.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (86, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (86, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-28.nii.gz\n",
            "ðŸ” Inference on [29] LUNG3-29.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (173, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (173, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-29.nii.gz\n",
            "ðŸ” Inference on [30] LUNG3-30.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (72, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (72, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-30.nii.gz\n",
            "ðŸ” Inference on [31] LUNG3-31.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (242, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (242, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-31.nii.gz\n",
            "ðŸ” Inference on [32] LUNG3-32.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (58, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (58, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-32.nii.gz\n",
            "ðŸ” Inference on [33] LUNG3-33.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (276, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (276, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-33.nii.gz\n",
            "ðŸ” Inference on [34] LUNG3-34.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-34.nii.gz\n",
            "ðŸ” Inference on [35] LUNG3-35.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (253, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (253, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-35.nii.gz\n",
            "ðŸ” Inference on [36] LUNG3-36.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (356, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (356, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-36.nii.gz\n",
            "ðŸ” Inference on [37] LUNG3-37.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (97, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (97, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-37.nii.gz\n",
            "ðŸ” Inference on [38] LUNG3-38.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (223, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (223, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-38.nii.gz\n",
            "ðŸ” Inference on [39] LUNG3-39.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (82, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (82, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-39.nii.gz\n",
            "ðŸ” Inference on [40] LUNG3-40.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (239, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (239, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-40.nii.gz\n",
            "ðŸ” Inference on [41] LUNG3-41.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (110, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (110, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-41.nii.gz\n",
            "ðŸ” Inference on [42] LUNG3-42.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-42.nii.gz\n",
            "ðŸ” Inference on [43] LUNG3-43.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (68, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (68, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-43.nii.gz\n",
            "ðŸ” Inference on [44] LUNG3-44.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (227, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (227, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-44.nii.gz\n",
            "ðŸ” Inference on [45] LUNG3-45.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-45.nii.gz\n",
            "ðŸ” Inference on [46] LUNG3-46.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (184, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (184, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-46.nii.gz\n",
            "ðŸ” Inference on [47] LUNG3-47.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (275, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (275, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-47.nii.gz\n",
            "ðŸ” Inference on [48] LUNG3-48.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (157, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (157, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-48.nii.gz\n",
            "ðŸ” Inference on [49] LUNG3-49.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (89, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (89, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-49.nii.gz\n",
            "ðŸ” Inference on [50] LUNG3-50.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-50.nii.gz\n",
            "ðŸ” Inference on [51] LUNG3-51.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (76, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (76, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-51.nii.gz\n",
            "ðŸ” Inference on [52] LUNG3-52.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (50, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (50, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-52.nii.gz\n",
            "ðŸ” Inference on [53] LUNG3-53.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-53.nii.gz\n",
            "ðŸ” Inference on [54] LUNG3-54.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (175, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (175, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-54.nii.gz\n",
            "ðŸ” Inference on [55] LUNG3-55.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (72, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (72, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-55.nii.gz\n",
            "ðŸ” Inference on [56] LUNG3-56.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-56.nii.gz\n",
            "ðŸ” Inference on [57] LUNG3-57.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-57.nii.gz\n",
            "ðŸ” Inference on [58] LUNG3-58.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (64, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (64, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-58.nii.gz\n",
            "ðŸ” Inference on [59] LUNG3-59.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (62, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (62, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-59.nii.gz\n",
            "ðŸ” Inference on [60] LUNG3-60.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-60.nii.gz\n",
            "ðŸ” Inference on [61] LUNG3-61.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (203, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (203, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-61.nii.gz\n",
            "ðŸ” Inference on [62] LUNG3-62.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (66, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (66, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-62.nii.gz\n",
            "ðŸ” Inference on [63] LUNG3-63.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (57, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (57, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-63.nii.gz\n",
            "ðŸ” Inference on [64] LUNG3-64.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (172, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (172, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-64.nii.gz\n",
            "ðŸ” Inference on [65] LUNG3-65.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (175, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (175, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-65.nii.gz\n",
            "ðŸ” Inference on [66] LUNG3-66.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (69, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (69, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-66.nii.gz\n",
            "ðŸ” Inference on [67] LUNG3-67.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-67.nii.gz\n",
            "ðŸ” Inference on [68] LUNG3-68.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (60, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (60, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-68.nii.gz\n",
            "ðŸ” Inference on [69] LUNG3-69.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-69.nii.gz\n",
            "ðŸ” Inference on [70] LUNG3-70.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (258, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (258, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-70.nii.gz\n",
            "ðŸ” Inference on [71] LUNG3-71.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (287, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (287, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-71.nii.gz\n",
            "ðŸ” Inference on [72] LUNG3-72.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (84, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (84, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-72.nii.gz\n",
            "ðŸ” Inference on [73] LUNG3-73.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (218, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (218, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-73.nii.gz\n",
            "ðŸ” Inference on [74] LUNG3-74.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (67, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (67, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-74.nii.gz\n",
            "ðŸ” Inference on [75] LUNG3-75.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (88, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (88, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-75.nii.gz\n",
            "ðŸ” Inference on [76] LUNG3-76.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-76.nii.gz\n",
            "ðŸ” Inference on [77] LUNG3-77.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-77.nii.gz\n",
            "ðŸ” Inference on [78] LUNG3-78.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-78.nii.gz\n",
            "ðŸ” Inference on [79] LUNG3-79.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (240, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (240, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-79.nii.gz\n",
            "ðŸ” Inference on [80] LUNG3-80.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (59, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (59, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-80.nii.gz\n",
            "ðŸ” Inference on [81] LUNG3-81.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (307, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (307, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-81.nii.gz\n",
            "ðŸ” Inference on [82] LUNG3-82.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (78, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (78, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-82.nii.gz\n",
            "ðŸ” Inference on [83] LUNG3-83.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-83.nii.gz\n",
            "ðŸ” Inference on [84] LUNG3-84.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (66, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (66, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-84.nii.gz\n",
            "ðŸ” Inference on [85] LUNG3-85.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (234, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (234, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-85.nii.gz\n",
            "ðŸ” Inference on [86] LUNG3-86.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (78, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (78, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-86.nii.gz\n",
            "ðŸ” Inference on [87] LUNG3-87.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (79, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (79, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-87.nii.gz\n",
            "ðŸ” Inference on [88] LUNG3-88.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (154, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (154, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-88.nii.gz\n",
            "ðŸ” Inference on [89] LUNG3-89.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-89.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "b54762e0-6093-45f5-86b6-48c278f39d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 38 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG1-001.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-001.nii.gz\n",
            "ðŸ” Inference on [2] LUNG1-025.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-025.nii.gz\n",
            "ðŸ” Inference on [3] LUNG1-027.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (108, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (108, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-027.nii.gz\n",
            "ðŸ” Inference on [4] LUNG1-034.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-034.nii.gz\n",
            "ðŸ” Inference on [5] LUNG1-039.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-039.nii.gz\n",
            "ðŸ” Inference on [6] LUNG1-066.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-066.nii.gz\n",
            "ðŸ” Inference on [7] LUNG1-078.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-078.nii.gz\n",
            "ðŸ” Inference on [8] LUNG1-088.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (123, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (123, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-088.nii.gz\n",
            "ðŸ” Inference on [9] LUNG1-107.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (116, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (116, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-107.nii.gz\n",
            "ðŸ” Inference on [10] LUNG1-132.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (114, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (114, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-132.nii.gz\n",
            "ðŸ” Inference on [11] LUNG1-133.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (184, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (184, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-133.nii.gz\n",
            "ðŸ” Inference on [12] LUNG1-143.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-143.nii.gz\n",
            "ðŸ” Inference on [13] LUNG1-149.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (118, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (118, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-149.nii.gz\n",
            "ðŸ” Inference on [14] LUNG1-151.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (118, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (118, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-151.nii.gz\n",
            "ðŸ” Inference on [15] LUNG1-158.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-158.nii.gz\n",
            "ðŸ” Inference on [16] LUNG1-168.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-168.nii.gz\n",
            "ðŸ” Inference on [17] LUNG1-175.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (112, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (112, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-175.nii.gz\n",
            "ðŸ” Inference on [18] LUNG1-176.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-176.nii.gz\n",
            "ðŸ” Inference on [19] LUNG1-201.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-201.nii.gz\n",
            "ðŸ” Inference on [20] LUNG1-224.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-224.nii.gz\n",
            "ðŸ” Inference on [21] LUNG1-225.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-225.nii.gz\n",
            "ðŸ” Inference on [22] LUNG1-235.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (129, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (129, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-235.nii.gz\n",
            "ðŸ” Inference on [23] LUNG1-239.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-239.nii.gz\n",
            "ðŸ” Inference on [24] LUNG1-246.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-246.nii.gz\n",
            "ðŸ” Inference on [25] LUNG1-263.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-263.nii.gz\n",
            "ðŸ” Inference on [26] LUNG1-266.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-266.nii.gz\n",
            "ðŸ” Inference on [27] LUNG1-281.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (101, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (101, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-281.nii.gz\n",
            "ðŸ” Inference on [28] LUNG1-286.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-286.nii.gz\n",
            "ðŸ” Inference on [29] LUNG1-312.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-312.nii.gz\n",
            "ðŸ” Inference on [30] LUNG1-338.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-338.nii.gz\n",
            "ðŸ” Inference on [31] LUNG1-352.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-352.nii.gz\n",
            "ðŸ” Inference on [32] LUNG1-353.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-353.nii.gz\n",
            "ðŸ” Inference on [33] LUNG1-365.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-365.nii.gz\n",
            "ðŸ” Inference on [34] LUNG1-374.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (130, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (130, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-374.nii.gz\n",
            "ðŸ” Inference on [35] LUNG1-383.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-383.nii.gz\n",
            "ðŸ” Inference on [36] LUNG1-405.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-405.nii.gz\n",
            "ðŸ” Inference on [37] LUNG1-408.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (107, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (107, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-408.nii.gz\n",
            "ðŸ” Inference on [38] LUNG1-410.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-410.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIi6GZ347x8",
        "outputId": "5b5fc90e-eeaf-4b07-d6a5-bf3197b8e4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 43 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG1-010.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (91, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (91, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-010.nii.gz\n",
            "ðŸ” Inference on [2] LUNG1-031.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (153, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (153, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-031.nii.gz\n",
            "ðŸ” Inference on [3] LUNG1-040.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-040.nii.gz\n",
            "ðŸ” Inference on [4] LUNG1-056.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-056.nii.gz\n",
            "ðŸ” Inference on [5] LUNG1-057.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (101, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (101, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-057.nii.gz\n",
            "ðŸ” Inference on [6] LUNG1-071.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (135, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (135, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-071.nii.gz\n",
            "ðŸ” Inference on [7] LUNG1-073.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (176, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (176, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-073.nii.gz\n",
            "ðŸ” Inference on [8] LUNG1-074.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-074.nii.gz\n",
            "ðŸ” Inference on [9] LUNG1-076.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-076.nii.gz\n",
            "ðŸ” Inference on [10] LUNG1-077.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (117, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (117, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-077.nii.gz\n",
            "ðŸ” Inference on [11] LUNG1-080.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-080.nii.gz\n",
            "ðŸ” Inference on [12] LUNG1-091.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (135, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (135, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-091.nii.gz\n",
            "ðŸ” Inference on [13] LUNG1-095.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-095.nii.gz\n",
            "ðŸ” Inference on [14] LUNG1-117.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (90, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (90, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-117.nii.gz\n",
            "ðŸ” Inference on [15] LUNG1-134.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (108, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (108, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-134.nii.gz\n",
            "ðŸ” Inference on [16] LUNG1-139.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (107, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (107, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-139.nii.gz\n",
            "ðŸ” Inference on [17] LUNG1-147.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-147.nii.gz\n",
            "ðŸ” Inference on [18] LUNG1-170.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (110, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (110, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-170.nii.gz\n",
            "ðŸ” Inference on [19] LUNG1-177.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-177.nii.gz\n",
            "ðŸ” Inference on [20] LUNG1-186.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-186.nii.gz\n",
            "ðŸ” Inference on [21] LUNG1-194.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (127, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (127, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-194.nii.gz\n",
            "ðŸ” Inference on [22] LUNG1-196.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-196.nii.gz\n",
            "ðŸ” Inference on [23] LUNG1-198.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (131, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (131, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-198.nii.gz\n",
            "ðŸ” Inference on [24] LUNG1-210.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (131, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (131, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-210.nii.gz\n",
            "ðŸ” Inference on [25] LUNG1-220.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-220.nii.gz\n",
            "ðŸ” Inference on [26] LUNG1-230.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-230.nii.gz\n",
            "ðŸ” Inference on [27] LUNG1-233.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-233.nii.gz\n",
            "ðŸ” Inference on [28] LUNG1-241.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-241.nii.gz\n",
            "ðŸ” Inference on [29] LUNG1-249.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-249.nii.gz\n",
            "ðŸ” Inference on [30] LUNG1-264.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (130, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (130, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-264.nii.gz\n",
            "ðŸ” Inference on [31] LUNG1-273.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-273.nii.gz\n",
            "ðŸ” Inference on [32] LUNG1-299.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-299.nii.gz\n",
            "ðŸ” Inference on [33] LUNG1-329.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-329.nii.gz\n",
            "ðŸ” Inference on [34] LUNG1-337.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-337.nii.gz\n",
            "ðŸ” Inference on [35] LUNG1-340.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-340.nii.gz\n",
            "ðŸ” Inference on [36] LUNG1-356.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-356.nii.gz\n",
            "ðŸ” Inference on [37] LUNG1-371.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (173, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (173, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-371.nii.gz\n",
            "ðŸ” Inference on [38] LUNG1-372.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-372.nii.gz\n",
            "ðŸ” Inference on [39] LUNG1-412.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-412.nii.gz\n",
            "ðŸ” Inference on [40] LUNG1-415.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (122, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (122, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-415.nii.gz\n",
            "ðŸ” Inference on [41] LUNG1-418.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (133, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (133, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-418.nii.gz\n",
            "ðŸ” Inference on [42] LUNG1-419.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-419.nii.gz\n",
            "ðŸ” Inference on [43] LUNG1-421.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-421.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"ðŸ“ Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyP4yguiOZPKsu0AG1DExLjc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}