{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Nifti_MONAI6_3Balanced_TverskyLoss).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. This is the improved of Model 6\n",
        "1. the architecture is 3DUNet\n",
        "2. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the\n",
        "3. strong augmentation is used in the code...\n",
        "4. Dice Loss is 1 and Binary classification Entropy is 1\n",
        "5. Number of positive pixels is for all patients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09755192-7481-40c3-893d-569b4e68c01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (1.26.4)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import AsDiscrete\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    ResizeWithPadOrCropd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandFlipd,\n",
        "    RandAffined,\n",
        "    RandGaussianNoised,\n",
        "    RandScaleIntensityd,\n",
        "    ToTensord,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstD,\n",
        "    SpatialPadd,\n",
        "    Rand3DElasticd,\n",
        "    NormalizeIntensityd,\n",
        "    RandGaussianSmoothd,\n",
        "    RandAdjustContrastd\n",
        "\n",
        ")\n",
        "import monai\n",
        "from monai.losses import TverskyLoss\n",
        "from monai.losses import DiceLoss, DiceFocalLoss\n",
        "import json\n",
        "from monai.data import CacheDataset\n",
        "from monai.transforms import Transform\n",
        "from monai.data import CacheDataset\n",
        "import torch.nn.functional as F\n",
        "from monai.data import Dataset, DataLoader, CacheDataset, pad_list_data_collate\n",
        "from monai.networks.layers import Norm\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from monai.transforms import EnsureTyped\n",
        "from monai.transforms import SaveImaged\n",
        "from monai.utils import set_determinism\n",
        "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Num foregrounds 0, Num backgrounds.*unable to generate class balanced samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "4ba60227-51ec-4261-c0db-0936e1a2a570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Safe Unet"
      ],
      "metadata": {
        "id": "Z0WDdyUd12ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SafeUNet(torch.nn.Module):\n",
        "    def __init__(self, base_unet):\n",
        "        super().__init__()\n",
        "        self.unet = base_unet\n",
        "\n",
        "    def forward(self, x):\n",
        "        try:\n",
        "            # Try normal forward pass\n",
        "            return self.unet(x)\n",
        "        except RuntimeError as e:\n",
        "            if \"Sizes of tensors must match\" in str(e):\n",
        "                print(f\"⚠️ Size mismatch detected! Input: {x.shape}\")\n",
        "                print(\"🔄 Attempting automatic resize...\")\n",
        "\n",
        "                # Emergency resize to compatible size\n",
        "                compatible_size = self.find_compatible_size(x.shape[2:])\n",
        "                x_resized = F.interpolate(\n",
        "                    x,\n",
        "                    size=compatible_size,\n",
        "                    mode='trilinear',\n",
        "                    align_corners=False\n",
        "                )\n",
        "\n",
        "                # Forward pass with resized input\n",
        "                output = self.unet(x_resized)\n",
        "\n",
        "                # Resize output back to original size\n",
        "                output = F.interpolate(\n",
        "                    output,\n",
        "                    size=x.shape[2:],\n",
        "                    mode='trilinear',\n",
        "                    align_corners=False\n",
        "                )\n",
        "                print(f\"✅ Resize successful: {x.shape[2:]} → {compatible_size} → {x.shape[2:]}\")\n",
        "                return output\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    def find_compatible_size(self, original_size):\n",
        "        \"\"\"Find a size compatible with UNet architecture (divisible by 16)\"\"\"\n",
        "        # UNet needs sizes divisible by 2^num_downsampling (16 for 4 downsamples)\n",
        "        compatible_size = tuple((s // 16) * 16 for s in original_size)\n",
        "\n",
        "        # Ensure minimum size\n",
        "        compatible_size = tuple(max(16, s) for s in compatible_size)\n",
        "\n",
        "        print(f\"🎯 Original: {original_size}, Compatible: {compatible_size}\")\n",
        "        return compatible_size"
      ],
      "metadata": {
        "id": "cGu3zWdW3jje"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class ImprovedDiceFocalLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, dice_weight=0.7, focal_weight=0.3, gamma=2.0, alpha=0.25, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.dice_weight = dice_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.pos_weight = pos_weight  # Store pos_weight\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "\n",
        "        # Dice Loss\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth\n",
        "        )\n",
        "\n",
        "        # Focal Loss with pos_weight\n",
        "        if self.pos_weight is not None:\n",
        "            # Apply pos_weight to the focal loss\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(\n",
        "                preds, targets,\n",
        "                reduction='none',\n",
        "                pos_weight=self.pos_weight  # This is the key change!\n",
        "            )\n",
        "        else:\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(preds, targets, reduction='none')\n",
        "\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
        "\n",
        "        return self.dice_weight * dice_loss + self.focal_weight * focal_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        # Remove super().__init__() since there's no parent class\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "        self.hd95_metric = HausdorffDistanceMetric(include_background=False, percentile=95, reduction=\"mean\")\n",
        "        self.asd_metric = SurfaceDistanceMetric(include_background=False, reduction=\"mean\")\n",
        "\n",
        "        # Create test output directory\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Update CSV headers to include new metrics\n",
        "        self._init_enhanced_metrics_csv()\n",
        "\n",
        "    def _init_enhanced_metrics_csv(self):\n",
        "        \"\"\"Initialize CSV with additional metric columns\"\"\"\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\n",
        "                    \"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\",\n",
        "                    \"Dice\", \"HD95\", \"ASD\", \"Time\"\n",
        "                ])\n",
        "\n",
        "    def calculate_basic_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate basic segmentation metrics (replacement for missing parent class)\"\"\"\n",
        "        # If you had a parent class with calculate_metrics, implement it here\n",
        "        eps = 1e-8\n",
        "\n",
        "        tp = np.sum(y_true * y_pred)\n",
        "        fp = np.sum((1 - y_true) * y_pred)\n",
        "        fn = np.sum(y_true * (1 - y_pred))\n",
        "        tn = np.sum((1 - y_true) * (1 - y_pred))\n",
        "\n",
        "        jaccard = tp / (tp + fp + fn + eps)\n",
        "        f1 = 2 * tp / (2 * tp + fp + fn + eps)\n",
        "        recall = tp / (tp + fn + eps)\n",
        "        precision = tp / (tp + fp + eps)\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn + eps)\n",
        "\n",
        "        return [jaccard, f1, recall, precision, accuracy]\n",
        "\n",
        "    def calculate_comprehensive_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate both basic and medical image metrics\"\"\"\n",
        "        # Use the new basic metrics method\n",
        "        basic_metrics = self.calculate_basic_metrics(y_true, y_pred)\n",
        "\n",
        "        # Convert to torch tensors for MONAI metrics\n",
        "        y_true_t = torch.from_numpy(y_true.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "        y_pred_t = torch.from_numpy(y_pred.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Calculate MONAI metrics\n",
        "        dice_value = self.dice_metric(y_pred_t, y_true_t)\n",
        "        hd95_value = self.hd95_metric(y_pred_t, y_true_t)\n",
        "        asd_value = self.asd_metric(y_pred_t, y_true_t)\n",
        "\n",
        "        # Reset metrics for next calculation\n",
        "        self.dice_metric.reset()\n",
        "        self.hd95_metric.reset()\n",
        "        self.asd_metric.reset()\n",
        "\n",
        "        return basic_metrics + [\n",
        "            dice_value.item() if not dice_value.isnan() else 0.0,\n",
        "            hd95_value.item() if not hd95_value.isnan() else 0.0,\n",
        "            asd_value.item() if not asd_value.isnan() else 0.0\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image_np: np.ndarray, pred_np: np.ndarray, label_np: np.ndarray, sample_id: str):\n",
        "        \"\"\"Save sample slices for visualization\"\"\"\n",
        "        try:\n",
        "            # Find slices with predictions for better visualization\n",
        "            pred_slices = np.where(np.any(pred_np, axis=(0, 1)))[0]\n",
        "            label_slices = np.where(np.any(label_np, axis=(0, 1)))[0]\n",
        "\n",
        "            # Combine and get unique slices of interest\n",
        "            slices_of_interest = np.unique(np.concatenate([pred_slices, label_slices]))\n",
        "\n",
        "            # If no positive slices, use center slices\n",
        "            if len(slices_of_interest) == 0:\n",
        "                slices_of_interest = [pred_np.shape[2] // 2 - 1, pred_np.shape[2] // 2, pred_np.shape[2] // 2 + 1]\n",
        "\n",
        "            # Save a few representative slices\n",
        "            for i, slice_idx in enumerate(slices_of_interest[:3]):  # Save max 3 slices\n",
        "                if 0 <= slice_idx < pred_np.shape[2]:\n",
        "                    # Create a simple visualization\n",
        "                    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "                    axes[0].imshow(image_np[:, :, slice_idx], cmap='gray')\n",
        "                    axes[0].set_title(f'Image - Slice {slice_idx}')\n",
        "                    axes[0].axis('off')\n",
        "\n",
        "                    axes[1].imshow(label_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[1].set_title('Ground Truth')\n",
        "                    axes[1].axis('off')\n",
        "\n",
        "                    axes[2].imshow(pred_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[2].set_title('Prediction')\n",
        "                    axes[2].axis('off')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    save_path = os.path.join(self.test_result_path, f\"{sample_id}_slice_{slice_idx}.png\")\n",
        "                    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not save slices for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        \"\"\"Override to handle extended metrics\"\"\"\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            # Now metrics should have: [jaccard, f1, recall, precision, accuracy, dice, hd95, asd]\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(8)  # Now 8 metrics total\n",
        "        total_times = []\n",
        "\n",
        "        # Count samples with actual predictions\n",
        "        samples_with_predictions = 0\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                # Skip if no predictions AND no ground truth (empty case)\n",
        "                if pred_np.sum() == 0 and label_np.sum() == 0:\n",
        "                    print(f\"📝 Sample {batch_idx}: No predictions and no ground truth - skipping\")\n",
        "                    continue\n",
        "\n",
        "                # Enhanced metrics calculation\n",
        "                metrics = self.calculate_comprehensive_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "                samples_with_predictions += 1\n",
        "\n",
        "                sample_id = f\"sample_{batch_idx:03d}\"\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "                # Print sample-level results\n",
        "                print(f\"📊 Sample {batch_idx}: Dice={metrics[5]:.4f}, HD95={metrics[6]:.2f}mm, Time={elapsed:.2f}s\")\n",
        "\n",
        "        # Print enhanced summary (only for samples with meaningful data)\n",
        "        if samples_with_predictions > 0:\n",
        "            num_samples = samples_with_predictions\n",
        "            metric_names = [\"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Dice\", \"HD95\", \"ASD\"]\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"📊 ENHANCED TEST METRICS SUMMARY:\")\n",
        "            print(\"=\"*60)\n",
        "            for i, name in enumerate(metric_names):\n",
        "                print(f\"{name:<12}: {total_metrics[i]/num_samples:.4f}\")\n",
        "            print(f\"📈 Samples evaluated: {num_samples}/{len(test_loader)}\")\n",
        "            print(f\"⚡ Average FPS: {1 / np.mean(total_times):.2f}\")\n",
        "            print(f\"⏱️  Average time per sample: {np.mean(total_times):.2f}s\")\n",
        "        else:\n",
        "            print(\"❌ No samples with meaningful predictions to evaluate!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) Early Stopping"
      ],
      "metadata": {
        "id": "3JLRqnw5L7xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0, pos_weight=None):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "        self.pos_weight = pos_weight  # Store pos_weight\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None, pos_weight=None):\n",
        "        # Update pos_weight if provided\n",
        "        # if pos_weight is not None:\n",
        "        #     self.pos_weight = pos_weight\n",
        "\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"✅ Validation loss improved ({self.val_loss_min:.6f}). Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"⏳ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # Always save a full checkpoint with pos_weight\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter,\n",
        "            # 'pos_weight': self.pos_weight  # Save pos_weight here\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        # if self.verbose and self.pos_weight is not None:\n",
        "        #     print(f\"💾 Checkpoint saved with pos_weight: {self.pos_weight:.4f}\")"
      ],
      "metadata": {
        "id": "LA4lGL-xL6st"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (7). Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------- Trainer ----------\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        # Initialize pos_weight_file\n",
        "        self.pos_weight_file = model_file.replace('.pth', '_pos_weight.json')\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, accumulation_steps, loss_fn):  # Remove scheduler parameter\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = torch.amp.GradScaler()\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        # Initialize patch monitoring variables\n",
        "        positive_patches = 0\n",
        "        total_patches = 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            inputs, labels = batch[\"vol\"].to(self.device, non_blocking=True), batch[\"seg\"].to(self.device, non_blocking=True)\n",
        "\n",
        "            # Monitor patch quality\n",
        "            batch_positives = labels.sum().item()\n",
        "            if batch_positives > 0:\n",
        "                positive_patches += 1\n",
        "\n",
        "            total_patches += 1\n",
        "\n",
        "            with torch.amp.autocast(device_type=device_type, enabled=True):\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels) / accumulation_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                # Remove scheduler.step() from here\n",
        "\n",
        "            epoch_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"  Batch {i+1}/{len(loader)}, Loss: {loss.item() * accumulation_steps:.4f}\")\n",
        "\n",
        "        print(f\"  Patch Quality: {positive_patches}/{total_patches} ({positive_patches/total_patches*100:.1f}%) with positives\")\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def dice_score(self, preds, targets, epsilon=1e-6):\n",
        "        \"\"\"Calculate Dice score for binary segmentation\"\"\"\n",
        "        # Ensure predictions are binary (0 or 1)\n",
        "        if preds.dtype != torch.float or preds.max() > 1 or preds.min() < 0:\n",
        "            preds = (torch.sigmoid(preds) > 0.5).float()\n",
        "\n",
        "        # Flatten the tensors to 1D\n",
        "        preds_flat = preds.contiguous().view(-1)\n",
        "        targets_flat = targets.contiguous().view(-1)\n",
        "\n",
        "        # Calculate intersection and union\n",
        "        intersection = (preds_flat * targets_flat).sum()\n",
        "        union = preds_flat.sum() + targets_flat.sum()\n",
        "\n",
        "        # Avoid division by zero\n",
        "        if union == 0:\n",
        "            return torch.tensor(1.0)  # Perfect score if both are empty\n",
        "\n",
        "        dice = (2. * intersection + epsilon) / (union + epsilon)\n",
        "        return dice\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        total_dice = 0\n",
        "        samples_with_tumors = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Calculate Dice score\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                dice = self.dice_score(preds, labels)\n",
        "\n",
        "                if labels.sum() > 0:  # Only count samples with tumors\n",
        "                    total_dice += dice.item()\n",
        "                    samples_with_tumors += 1\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        avg_dice = total_dice / samples_with_tumors if samples_with_tumors > 0 else 0\n",
        "\n",
        "        return avg_loss, avg_dice, samples_with_tumors\n",
        "\n",
        "\n",
        "    def save_pos_weight(self, pos_weight):\n",
        "        \"\"\"Save pos_weight to JSON file\"\"\"\n",
        "        with open(self.pos_weight_file, 'w') as f:\n",
        "            json.dump({'pos_weight': pos_weight, 'timestamp': time.time()}, f)\n",
        "        print(f\"💾 Saved pos_weight: {pos_weight:.4f}\")\n",
        "\n",
        "    def load_pos_weight(self):\n",
        "        \"\"\"Load pos_weight from JSON file\"\"\"\n",
        "        if os.path.exists(self.pos_weight_file):\n",
        "            try:\n",
        "                with open(self.pos_weight_file, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    pos_weight = data['pos_weight']\n",
        "                    print(f\"📂 Loaded pos_weight: {pos_weight:.4f}\")\n",
        "                    return pos_weight\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error loading pos_weight: {e}\")\n",
        "        return None\n",
        "\n",
        "    def get_pos_weight(self, train_loader, force_recompute=False):\n",
        "        \"\"\"Get pos_weight - load if exists, otherwise compute and save\"\"\"\n",
        "        if not force_recompute:\n",
        "            pos_weight = self.load_pos_weight()\n",
        "            if pos_weight is not None:\n",
        "                return pos_weight\n",
        "\n",
        "        # Compute new pos_weight\n",
        "        pos_weight = self.compute_pos_weight(train_loader, max_batches=None)\n",
        "        self.save_pos_weight(pos_weight)\n",
        "        return pos_weight\n",
        "\n",
        "    def compute_pos_weight(self, train_loader, max_batches=None):\n",
        "        \"\"\"Compute pos_weight with better diagnostics\"\"\"\n",
        "        pos, neg = 0, 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            seg = batch[\"seg\"].to(self.device)\n",
        "            batch_pos = seg.sum().item()\n",
        "            batch_neg = seg.numel() - batch_pos\n",
        "\n",
        "            pos += batch_pos\n",
        "            neg += batch_neg\n",
        "            total_samples += 1\n",
        "\n",
        "            print(f\"Batch {i}: pos={batch_pos}, neg={batch_neg}, pos_ratio={batch_pos/seg.numel():.6f}\")\n",
        "\n",
        "            if max_batches and (i + 1) >= max_batches:\n",
        "                break\n",
        "\n",
        "        pos_ratio = pos / (pos + neg) if (pos + neg) > 0 else 0\n",
        "        pos_weight = neg / (pos + 1e-8)\n",
        "\n",
        "        print(f\"📊 Final Stats:\")\n",
        "        print(f\"  Total pos voxels: {pos}\")\n",
        "        print(f\"  Total neg voxels: {neg}\")\n",
        "        print(f\"  Positive ratio: {pos_ratio:.6f} ({pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Computed pos_weight: {pos_weight:.4f}\")\n",
        "        return pos_weight\n",
        "\n",
        "    def execute(self, model, train_loader, valid_loader):\n",
        "        # Use the smaller, faster model as I suggested\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-3)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
        "        print(\"🎯 Switching to DiceFocalLoss for better learning\")\n",
        "        loss_fn = TverskyLoss(\n",
        "            sigmoid=True,\n",
        "            alpha=0.3,    # Weight for false positives\n",
        "            beta=0.7,     # Weight for false negatives (penalize missing tumors more)\n",
        "        )\n",
        "\n",
        "        accumulation_steps = 4\n",
        "\n",
        "        # ---- Resume training state ----\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        print(\"✅ Checkpoint loaded successfully\")\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=20,\n",
        "            min_delta=0.0002,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter,\n",
        "            # pos_weight=reasonable_pos_weight  # Use the capped value\n",
        "        )\n",
        "\n",
        "\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # ---- Training loop ----\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(\n",
        "                model, train_loader, optimizer, accumulation_steps, loss_fn\n",
        "            )\n",
        "            valid_loss, valid_dice, tumor_samples = self.evaluate(model, valid_loader, loss_fn)\n",
        "            print(f\"Epoch {epoch:03d} | Train: {train_loss:.6f} | Val: {valid_loss:.6f} | Val Dice: {valid_dice:.4f} | Tumor samples: {tumor_samples}\")\n",
        "            scheduler.step()\n",
        "            mins, secs = self.epoch_time(start_time, time.time())\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            # if early_stopping(valid_loss, model, epoch, optimizer, reasonable_pos_weight):\n",
        "            if early_stopping(valid_dice, model, epoch, optimizer):\n",
        "                print(\"🛑 Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (8). Pipeline"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CwcTHPshqu0O",
        "outputId": "b0dcd54f-a314-4673-be1c-f4bfa6353b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "📦 Preparing datasets and transforms...\n",
            "🔄 Loading training dataset...\n",
            "📊 Filtered 340 -> 340 non-empty samples\n",
            "📁 train: Loaded 340 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 34/34 [05:15<00:00,  9.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading validation dataset...\n",
            "📁 valid: Loaded 43 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 8/8 [01:26<00:00, 10.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading test dataset...\n",
            "📁 test: Loaded 38 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 7/7 [01:12<00:00, 10.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Filtered 340 -> 340 non-empty samples\n",
            "📁 train: Loaded 340 samples\n",
            "✅ Dataset sizes — Train: 340, Valid: 43, Test: 38\n",
            "🚀 Starting pipeline with:\n",
            "   - Train samples: 340\n",
            "   - Valid samples: 43\n",
            "   - Test samples: 38\n",
            "   - Device: cuda\n",
            "   - Output directory: ./results/Results_Nifti_MONAI6_3Original\n",
            "⚠️ DynamicUNet not available, using SafeUNet wrapper\n",
            "🎯 GPU Memory allocated: 0.04 GB\n",
            "🎯 GPU Memory cached: 0.44 GB\n",
            "\n",
            "🔍 Final shape check before training...\n",
            "\n",
            "============================================================\n",
            "🔍 DEBUGGING MODEL SHAPES\n",
            "============================================================\n",
            "📐 Input data shape: torch.Size([4, 1, 96, 96, 96])\n",
            "🎯 Target segmentation shape: torch.Size([4, 1, 96, 96, 96])\n",
            "💻 Input device: cuda:0\n",
            "⚠️ DynamicUNet not available, using SafeUNet wrapper\n",
            "🤖 Model device: cuda:0\n",
            "🤖 Current model output shape: torch.Size([4, 1, 96, 96, 96])\n",
            "✅ Shapes match perfectly!\n",
            "🎯 Switching to DiceFocalLoss for better learning\n",
            "✅ Checkpoint loaded successfully\n",
            "  Batch 50/340, Loss: 0.9953\n",
            "  Batch 100/340, Loss: 0.9399\n",
            "  Batch 150/340, Loss: 0.9915\n",
            "⚠️ Size mismatch detected! Input: torch.Size([4, 1, 93, 96, 96])\n",
            "🔄 Attempting automatic resize...\n",
            "🎯 Original: torch.Size([93, 96, 96]), Compatible: (80, 96, 96)\n",
            "✅ Resize successful: torch.Size([93, 96, 96]) → (80, 96, 96) → torch.Size([93, 96, 96])\n",
            "  Batch 200/340, Loss: 0.9630\n",
            "  Batch 250/340, Loss: 0.9348\n",
            "  Batch 300/340, Loss: 0.7477\n",
            "  Patch Quality: 340/340 (100.0%) with positives\n",
            "Epoch 001 | Train: 0.887028 | Val: 0.991143 | Val Dice: 0.0222 | Tumor samples: 14\n",
            "❌ Pipeline failed: LRScheduler.step() got an unexpected keyword argument 'metrics'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LRScheduler.step() got an unexpected keyword argument 'metrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-189829345.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-189829345.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnetPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-189829345.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_current_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-189829345.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         )\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdice_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1895303143.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, model, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtumor_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch:03d} | Train: {train_loss:.6f} | Val: {valid_loss:.6f} | Val Dice: {valid_dice:.4f} | Tumor samples: {tumor_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LRScheduler.step() got an unexpected keyword argument 'metrics'"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        set_determinism(seed=42)\n",
        "\n",
        "        # Setup paths\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "        # Prepare loaders\n",
        "        print(\"📦 Preparing datasets and transforms...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader, self.full_train_loader = self.prepare_loaders()\n",
        "        # self.debug_model_shapes()\n",
        "        # Dataset quality analysis\n",
        "        # print(\"\\n\" + \"=\"*60)\n",
        "        # print(\"🔍 RUNNING DATASET QUALITY ANALYSIS...\")\n",
        "        # print(\"=\"*60)\n",
        "        # self.analyze_dataset_quality()\n",
        "\n",
        "        # # 🔥 ADD COMPREHENSIVE SANITY CHECKS\n",
        "        # print(\"\\n\" + \"=\"*60)\n",
        "        # print(\"✅ RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        # print(\"=\"*60)\n",
        "        # self.check_data_sanity(max_batches=2)\n",
        "        # self.check_data_distributions()\n",
        "        # self.check_spatial_consistency()\n",
        "\n",
        "\n",
        "    def create_unet_model(self, device):\n",
        "        \"\"\"Create a robust UNet model that handles size variations\"\"\"\n",
        "        try:\n",
        "            from monai.networks.nets import DynamicUNet\n",
        "            print(\"✅ Using DynamicUNet (most robust)\")\n",
        "            return DynamicUNet(\n",
        "                spatial_dims=3,\n",
        "                in_channels=1,\n",
        "                out_channels=1,\n",
        "                channels=(16, 32, 64, 128, 256),\n",
        "                strides=(2, 2, 2, 2),\n",
        "                num_res_units=2,\n",
        "                norm=Norm.INSTANCE,\n",
        "                dropout=0.1,\n",
        "                act='PRELU'\n",
        "            ).to(device)\n",
        "        except ImportError:\n",
        "            print(\"⚠️ DynamicUNet not available, using SafeUNet wrapper\")\n",
        "            base_model = UNet(\n",
        "                spatial_dims=3,\n",
        "                in_channels=1,\n",
        "                out_channels=1,\n",
        "                channels=(16, 32, 64, 128, 256),\n",
        "                strides=(2, 2, 2, 2),\n",
        "                num_res_units=2,\n",
        "                norm=Norm.INSTANCE,\n",
        "                dropout=0.1,\n",
        "                act='PRELU'\n",
        "            )\n",
        "            return SafeUNet(base_model).to(device)\n",
        "\n",
        "\n",
        "    def analyze_dataset_quality(self):\n",
        "        \"\"\"Comprehensive dataset quality analysis\"\"\"\n",
        "        print(\"📊 Analyzing dataset quality...\")\n",
        "\n",
        "        # Analyze full volumes (before patch sampling)\n",
        "        self._analyze_loader_quality(self.full_train_loader, \"TRAIN (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.valid_loader, \"VALID (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.test_loader, \"TEST (Full Volumes)\")\n",
        "\n",
        "        # Analyze training patches (after patch sampling)\n",
        "        print(\"\\n\" + \"🔍 Analyzing Training Patches (After Sampling):\")\n",
        "        self._analyze_patch_quality(self.train_loader, \"TRAIN PATCHES\")\n",
        "\n",
        "    def debug_model_shapes(self):\n",
        "        \"\"\"Debug method to identify shape mismatches between model and data\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 DEBUGGING MODEL SHAPES\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Get a sample batch\n",
        "        sample_batch = next(iter(self.train_loader))\n",
        "        images, segs = sample_batch[\"vol\"], sample_batch[\"seg\"]\n",
        "\n",
        "        # 🔥 FIX: Move data to the same device as model\n",
        "        images = images.to(self.device)\n",
        "        segs = segs.to(self.device)\n",
        "\n",
        "        print(f\"📐 Input data shape: {images.shape}\")\n",
        "        print(f\"🎯 Target segmentation shape: {segs.shape}\")\n",
        "        print(f\"💻 Input device: {images.device}\")\n",
        "\n",
        "        # Test current model configuration\n",
        "\n",
        "\n",
        "        current_model = self.create_unet_model(self.device)\n",
        "\n",
        "        print(f\"🤖 Model device: {next(current_model.parameters()).device}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = current_model(images)\n",
        "            print(f\"🤖 Current model output shape: {output.shape}\")\n",
        "\n",
        "            # Check for mismatch\n",
        "            if output.shape[2:] != segs.shape[2:]:\n",
        "                print(f\"❌ SHAPE MISMATCH DETECTED!\")\n",
        "                print(f\"   Model output: {output.shape[2:]}\")\n",
        "                print(f\"   Target: {segs.shape[2:]}\")\n",
        "                print(f\"   Difference: {tuple(o-t for o,t in zip(output.shape[2:], segs.shape[2:]))}\")\n",
        "\n",
        "                # 🔥 Calculate what the input size should be\n",
        "                print(f\"\\n💡 SOLUTION: Your input size {images.shape[2:]} needs to be divisible by 16\")\n",
        "                print(f\"   Try using: (96, 96, 96) → divisible by 16? {all(s % 16 == 0 for s in images.shape[2:])}\")\n",
        "            else:\n",
        "                print(\"✅ Shapes match perfectly!\")\n",
        "\n",
        "        return output.shape, segs.shape\n",
        "\n",
        "\n",
        "    def _analyze_loader_quality(self, loader, name: str):\n",
        "        \"\"\"Analyze a specific data loader\"\"\"\n",
        "        print(f\"\\n📊 {name} Dataset Analysis:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        total_volumes = 0\n",
        "        volumes_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each volume in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                volume_seg = seg[i]\n",
        "                total_volumes += 1\n",
        "                volume_positives = volume_seg.sum().item()\n",
        "                volume_voxels = volume_seg.numel()\n",
        "\n",
        "                if volume_positives > 0:\n",
        "                    volumes_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += volume_positives\n",
        "                total_voxels += volume_voxels\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"  Total volumes: {total_volumes}\")\n",
        "        print(f\"  Volumes with positives: {volumes_with_positives} ({volumes_with_positives/total_volumes*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Total positive voxels: {total_pos_voxels:,}\")\n",
        "        print(f\"  Total voxels: {total_voxels:,}\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def _analyze_patch_quality(self, loader, name: str, max_batches: int = 20):\n",
        "        \"\"\"Analyze patch distribution in training loader\"\"\"\n",
        "        print(f\"\\n📊 {name} Patch Analysis (first {max_batches} batches):\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        total_patches = 0\n",
        "        patches_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            if batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each patch in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                patch_seg = seg[i]\n",
        "                total_patches += 1\n",
        "                patch_positives = patch_seg.sum().item()\n",
        "                patch_voxels = patch_seg.numel()\n",
        "\n",
        "                if patch_positives > 0:\n",
        "                    patches_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += patch_positives\n",
        "                total_voxels += patch_voxels\n",
        "\n",
        "                pos_ratio = patch_positives / patch_voxels if patch_voxels > 0 else 0\n",
        "                if patch_positives > 0:  # Only print patches with positives for clarity\n",
        "                    print(f\"  Batch {batch_idx}, Patch {i}: {patch_positives}/{patch_voxels} \"\n",
        "                          f\"({pos_ratio*100:.3f}% positive)\")\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"\\n📈 {name} Patch Summary:\")\n",
        "        print(f\"  Total patches analyzed: {total_patches}\")\n",
        "        print(f\"  Patches with positives: {patches_with_positives} ({patches_with_positives/total_patches*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def check_data_sanity(self, max_batches: int = 3):\n",
        "        \"\"\"Comprehensive data sanity checks for all loaders\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check training data\n",
        "        print(\"\\n📊 TRAINING DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.train_loader, \"train\", max_batches)\n",
        "\n",
        "        # Check validation data\n",
        "        print(\"\\n📊 VALIDATION DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.valid_loader, \"valid\", max_batches)\n",
        "\n",
        "        # Check test data\n",
        "        print(\"\\n📊 TEST DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.test_loader, \"test\", max_batches)\n",
        "\n",
        "        # Check full volumes (before patch sampling)\n",
        "        print(\"\\n📊 FULL VOLUME SANITY CHECK (Before Patch Sampling):\")\n",
        "        self._check_loader_sanity(self.full_train_loader, \"full_train\", max_batches)\n",
        "\n",
        "    def _check_loader_sanity(self, loader, name: str, max_batches: int):\n",
        "        \"\"\"Check a specific loader for data sanity\"\"\"\n",
        "        print(f\"🔍 Checking {name} loader...\")\n",
        "\n",
        "        batch_count = 0\n",
        "        total_positives = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "\n",
        "            vol = batch[\"vol\"]\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            print(f\"\\n  Batch {i}:\")\n",
        "            print(f\"    Volume shape: {vol.shape}\")\n",
        "            print(f\"    Volume range: [{vol.min():.4f}, {vol.max():.4f}]\")\n",
        "            print(f\"    Volume mean: {vol.mean():.4f} ± {vol.std():.4f}\")\n",
        "            print(f\"    Segmentation shape: {seg.shape}\")\n",
        "            print(f\"    Segmentation unique values: {torch.unique(seg)}\")\n",
        "\n",
        "            # Check for NaNs or Infs\n",
        "            if torch.isnan(vol).any():\n",
        "                print(\"    ⚠️ WARNING: Volume contains NaN values!\")\n",
        "            if torch.isinf(vol).any():\n",
        "                print(\"    ⚠️ WARNING: Volume contains Inf values!\")\n",
        "\n",
        "            # Check segmentation values are binary\n",
        "            unique_vals = torch.unique(seg)\n",
        "            if not all(val in [0, 1] for val in unique_vals):\n",
        "                print(f\"    ⚠️ WARNING: Segmentation has non-binary values: {unique_vals}\")\n",
        "\n",
        "            # Calculate positives\n",
        "            batch_positives = seg.sum().item()\n",
        "            batch_voxels = seg.numel()\n",
        "            pos_ratio = batch_positives / batch_voxels if batch_voxels > 0 else 0\n",
        "\n",
        "            print(f\"    Positives: {batch_positives:,}/{batch_voxels:,} ({pos_ratio*100:.4f}%)\")\n",
        "\n",
        "            total_positives += batch_positives\n",
        "            total_voxels += batch_voxels\n",
        "            batch_count += 1\n",
        "\n",
        "        # Summary for this loader\n",
        "        if batch_count > 0:\n",
        "            overall_ratio = total_positives / total_voxels if total_voxels > 0 else 0\n",
        "            print(f\"\\n  📈 {name} Summary ({batch_count} batches):\")\n",
        "            print(f\"    Total positives: {total_positives:,}\")\n",
        "            print(f\"    Total voxels: {total_voxels:,}\")\n",
        "            print(f\"    Overall positive ratio: {overall_ratio:.6f} ({overall_ratio*100:.4f}%)\")\n",
        "\n",
        "    def check_data_distributions(self):\n",
        "        \"\"\"Check intensity distributions and data consistency\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📊 CHECKING DATA DISTRIBUTIONS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check intensity distributions\n",
        "        self._check_intensity_distribution(self.train_loader, \"Training\")\n",
        "        self._check_intensity_distribution(self.valid_loader, \"Validation\")\n",
        "        self._check_intensity_distribution(self.test_loader, \"Test\")\n",
        "\n",
        "    def _check_intensity_distribution(self, loader, name: str):\n",
        "        \"\"\"Check intensity distribution for a loader\"\"\"\n",
        "        print(f\"\\n📈 {name} Intensity Distribution:\")\n",
        "\n",
        "        all_values = []\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= 5:  # Check first 5 batches for speed\n",
        "                break\n",
        "            vol = batch[\"vol\"]\n",
        "            all_values.extend(vol.flatten().cpu().numpy())\n",
        "\n",
        "        if all_values:\n",
        "            all_values = np.array(all_values)\n",
        "            print(f\"  Range: [{np.min(all_values):.4f}, {np.max(all_values):.4f}]\")\n",
        "            print(f\"  Mean: {np.mean(all_values):.4f} ± {np.std(all_values):.4f}\")\n",
        "            print(f\"  Median: {np.median(all_values):.4f}\")\n",
        "            print(f\"  Non-zero values: {np.sum(all_values != 0):,}/{len(all_values):,} \"\n",
        "                  f\"({np.sum(all_values != 0)/len(all_values)*100:.2f}%)\")\n",
        "\n",
        "    def check_spatial_consistency(self):\n",
        "        \"\"\"Check that all volumes have consistent spatial properties\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📏 CHECKING SPATIAL CONSISTENCY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        loaders = {\n",
        "            \"Training\": self.train_loader,\n",
        "            \"Validation\": self.valid_loader,\n",
        "            \"Test\": self.test_loader\n",
        "        }\n",
        "\n",
        "        for name, loader in loaders.items():\n",
        "            print(f\"\\n📐 {name} Spatial Properties:\")\n",
        "            shapes = []\n",
        "            for i, batch in enumerate(loader):\n",
        "                if i >= 3:  # Check first 3 batches\n",
        "                    break\n",
        "                vol = batch[\"vol\"]\n",
        "                shapes.append(vol.shape[2:])  # Get spatial dimensions (D, H, W)\n",
        "                print(f\"  Batch {i} shape: {vol.shape}\")\n",
        "\n",
        "            # Check consistency\n",
        "            if len(shapes) > 1:\n",
        "                if all(shape == shapes[0] for shape in shapes):\n",
        "                    print(f\"  ✅ All batches have consistent shape: {shapes[0]}\")\n",
        "                else:\n",
        "                    print(f\"  ⚠️ Shape inconsistency: {shapes}\")\n",
        "\n",
        "    def filter_empty_samples(self, file_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Remove samples that have no positive segmentation labels\"\"\"\n",
        "        filtered_files = []\n",
        "\n",
        "        for file_pair in file_list:\n",
        "            # Load just the segmentation to check if it's empty\n",
        "            seg_loader = Compose([\n",
        "                LoadImaged(keys=[\"seg\"]),\n",
        "                EnsureChannelFirstd(keys=[\"seg\"]),\n",
        "            ])\n",
        "\n",
        "            try:\n",
        "                seg_data = seg_loader(file_pair)[\"seg\"]\n",
        "                if seg_data.sum() > 0:  # Only keep if has positive voxels\n",
        "                    filtered_files.append(file_pair)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error loading {file_pair['seg']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"📊 Filtered {len(file_list)} -> {len(filtered_files)} non-empty samples\")\n",
        "        return filtered_files\n",
        "\n",
        "    def prepare_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader]:\n",
        "        \"\"\"Prepare data loaders for training, validation, and testing\"\"\"\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        patch_size = (96, 96, 96)\n",
        "\n",
        "        def get_files(split: str) -> List[Dict]:\n",
        "            \"\"\"Get file paths for a specific split with validation\"\"\"\n",
        "            ct_dir = os.path.join(self.dataset_dir, split, \"ct\")\n",
        "            seg_dir = os.path.join(self.dataset_dir, split, \"segment\")\n",
        "\n",
        "            # Validate directories exist\n",
        "            if not os.path.exists(ct_dir):\n",
        "                raise FileNotFoundError(f\"CT directory not found: {ct_dir}\")\n",
        "            if not os.path.exists(seg_dir):\n",
        "                raise FileNotFoundError(f\"Segmentation directory not found: {seg_dir}\")\n",
        "\n",
        "            ct_files = sorted(glob(os.path.join(ct_dir, \"*.nii.gz\")))\n",
        "            seg_files = sorted(glob(os.path.join(seg_dir, \"*.nii.gz\")))\n",
        "\n",
        "            if len(ct_files) == 0:\n",
        "                raise RuntimeError(f\"No CT files found in {ct_dir}\")\n",
        "            if len(seg_files) == 0:\n",
        "                raise RuntimeError(f\"No segmentation files found in {seg_dir}\")\n",
        "            if len(ct_files) != len(seg_files):\n",
        "                raise RuntimeError(f\"Mismatch CT/SEG for {split}: {len(ct_files)} vs {len(seg_files)}\")\n",
        "\n",
        "            # Create file pairs\n",
        "            files = []\n",
        "            for ct_file, seg_file in zip(ct_files, seg_files):\n",
        "                # Verify file correspondence\n",
        "                ct_id = os.path.basename(ct_file).replace('.nii.gz', '')\n",
        "                seg_id = os.path.basename(seg_file).replace('.nii.gz', '')\n",
        "                if ct_id != seg_id:\n",
        "                    print(f\"⚠️ Warning: File name mismatch - CT: {ct_id}, SEG: {seg_id}\")\n",
        "                files.append({\"vol\": ct_file, \"seg\": seg_file})\n",
        "\n",
        "            # Filter out empty samples for training\n",
        "            if split == \"train\":\n",
        "                files = self.filter_empty_samples(files)\n",
        "\n",
        "            print(f\"📁 {split}: Loaded {len(files)} samples\")\n",
        "            return files\n",
        "\n",
        "        # Common base transforms for ALL datasets\n",
        "        base_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\", margin=10),  # allow_smaller=True by default\n",
        "            ResizeWithPadOrCropd(keys=[\"vol\", \"seg\"], spatial_size=patch_size, mode=\"constant\"),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\",\"seg\"], track_meta=True),\n",
        "        ])\n",
        "\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\", margin=10),  # allow_smaller=True by default\n",
        "\n",
        "            RandCropByPosNegLabeld(\n",
        "                keys=[\"vol\", \"seg\"],\n",
        "                label_key=\"seg\",\n",
        "                spatial_size=patch_size,  # Now (96,96,96)\n",
        "                pos=1.0,\n",
        "                neg=0.1,\n",
        "                num_samples=4,\n",
        "                image_key=\"vol\",\n",
        "                image_threshold=0,\n",
        "                allow_smaller=True,  # ← Keep this as True\n",
        "            ),\n",
        "\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=[0, 1, 2]),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.05),\n",
        "\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\", \"seg\"]),\n",
        "        ])\n",
        "\n",
        "        # Create datasets with optimized cache rates for 3D data\n",
        "        print(\"🔄 Loading training dataset...\")\n",
        "        train_ds = CacheDataset(\n",
        "            data=get_files(\"train\"),\n",
        "            transform=train_transforms,\n",
        "            cache_rate=0.1,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        print(\"🔄 Loading validation dataset...\")\n",
        "        valid_ds = CacheDataset(\n",
        "            data=get_files(\"valid\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        print(\"🔄 Loading test dataset...\")\n",
        "        test_ds = CacheDataset(\n",
        "            data=get_files(\"test\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,  # Reduced for 3D data\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        # Create data loaders with optimized settings\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=True,\n",
        "            num_workers=2,  # Moderate for training\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            persistent_workers=False,  # Disabled to avoid cleanup issues\n",
        "            prefetch_factor=2,\n",
        "            collate_fn=pad_list_data_collate,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=self.config['batch_size'],  # or use 1 for individual volume evaluation\n",
        "            shuffle=False,  # No shuffle for validation\n",
        "            num_workers=1,  # Minimal workers\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            persistent_workers=False,  # Definitely disabled\n",
        "            prefetch_factor=1,  # Minimal prefetch\n",
        "            collate_fn=pad_list_data_collate\n",
        "            # No drop_last for validation - evaluate all samples\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_ds,\n",
        "            batch_size=1,  # Usually batch_size=1 for inference\n",
        "            shuffle=False,  # No shuffle for testing\n",
        "            num_workers=0,  # Single process to avoid multiprocessing issues\n",
        "            pin_memory=False,  # Often disabled for test\n",
        "            persistent_workers=False,\n",
        "            prefetch_factor=None,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        # Full volume train loader for sanity checks (no patching)\n",
        "        full_train_ds = Dataset(get_files(\"train\"), base_transforms)\n",
        "        full_train_loader = DataLoader(\n",
        "            full_train_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=0,  # Single process\n",
        "            pin_memory=False,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Dataset sizes — Train: {len(train_ds)}, Valid: {len(valid_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "        return train_loader, valid_loader, test_loader, full_train_loader\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Execute training with resource monitoring\"\"\"\n",
        "        model = self.create_unet_model(self.device)\n",
        "        # Monitor resources\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"🎯 GPU Memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "            print(f\"🎯 GPU Memory cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n",
        "        print(\"\\n🔍 Final shape check before training...\")\n",
        "        self.debug_model_shapes()\n",
        "        # Validate we have data\n",
        "\n",
        "        if len(self.train_loader.dataset) == 0:\n",
        "            raise ValueError(\"No training data available!\")\n",
        "        if len(self.valid_loader.dataset) == 0:\n",
        "            raise ValueError(\"No validation data available!\")\n",
        "\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(model,self.train_loader, self.valid_loader)\n",
        "\n",
        "    def dice_score(self, preds, targets, epsilon=1e-6):\n",
        "        \"\"\"Calculate Dice score for binary segmentation\"\"\"\n",
        "        # Ensure predictions are binary (0 or 1)\n",
        "        if preds.dtype != torch.float or preds.max() > 1 or preds.min() < 0:\n",
        "            preds = (torch.sigmoid(preds) > 0.5).float()\n",
        "\n",
        "        # Flatten the tensors to 1D\n",
        "        preds_flat = preds.contiguous().view(-1)\n",
        "        targets_flat = targets.contiguous().view(-1)\n",
        "\n",
        "        # Calculate intersection and union\n",
        "        intersection = (preds_flat * targets_flat).sum()\n",
        "        union = preds_flat.sum() + targets_flat.sum()\n",
        "\n",
        "        # Avoid division by zero\n",
        "        if union == 0:\n",
        "            return torch.tensor(1.0)  # Perfect score if both are empty\n",
        "\n",
        "        dice = (2. * intersection + epsilon) / (union + epsilon)\n",
        "        return dice\n",
        "\n",
        "\n",
        "    def quick_threshold_test(self):\n",
        "        \"\"\"Quick test with different thresholds\"\"\"\n",
        "        model = self.create_unet_model(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        print(\"🚀 QUICK THRESHOLD SENSITIVITY TEST\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "        results = {}\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            print(f\"\\n🧪 Testing threshold: {threshold}\")\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                dice_scores = []\n",
        "                for i, batch in enumerate(self.test_loader):\n",
        "                    if i >= 10:  # Test first 10 samples for speed\n",
        "                        break\n",
        "\n",
        "                    inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                    outputs = model(inputs)\n",
        "                    preds = (torch.sigmoid(outputs) > threshold).float()\n",
        "\n",
        "                    if labels.sum() > 0:  # Only samples with tumors\n",
        "                        dice = self.dice_score(preds, labels)\n",
        "                        dice_scores.append(dice.item())\n",
        "\n",
        "                        if dice > 0.1:  # Print successes\n",
        "                            print(f\"  Sample {i}: Dice = {dice:.4f} ✅\")\n",
        "\n",
        "                if dice_scores:\n",
        "                    avg_dice = np.mean(dice_scores)\n",
        "                    results[threshold] = avg_dice\n",
        "                    print(f\"  Average Dice: {avg_dice:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  No tumors detected in first 10 samples\")\n",
        "\n",
        "        # Find best threshold\n",
        "        if results:\n",
        "            best_threshold = max(results, key=results.get)\n",
        "            print(f\"\\n🎯 BEST THRESHOLD: {best_threshold} (Dice: {results[best_threshold]:.4f})\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def debug_test_set_comprehensive(self):\n",
        "        \"\"\"Comprehensive test set analysis\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 COMPREHENSIVE TEST SET ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        tumor_volumes = 0\n",
        "        total_tumor_voxels = 0\n",
        "        total_voxels = 0\n",
        "        tumor_ratios = []\n",
        "\n",
        "        for i, batch in enumerate(self.test_loader):\n",
        "            seg = batch[\"seg\"]\n",
        "            vol = batch[\"vol\"]\n",
        "\n",
        "            tumor_voxels = seg.sum().item()\n",
        "            volume_voxels = seg.numel()\n",
        "            tumor_ratio = tumor_voxels / volume_voxels if volume_voxels > 0 else 0\n",
        "\n",
        "            if tumor_voxels > 0:\n",
        "                tumor_volumes += 1\n",
        "                total_tumor_voxels += tumor_voxels\n",
        "                tumor_ratios.append(tumor_ratio)\n",
        "\n",
        "                print(f\"📊 Test Sample {i}:\")\n",
        "                print(f\"   Volume shape: {vol.shape}\")\n",
        "                print(f\"   Tumor voxels: {tumor_voxels:,}/{volume_voxels:,}\")\n",
        "                print(f\"   Tumor ratio: {tumor_ratio:.6f} ({tumor_ratio*100:.4f}%)\")\n",
        "                print(f\"   Volume range: [{vol.min():.3f}, {vol.max():.3f}]\")\n",
        "                print(f\"   Unique values: {torch.unique(seg)}\")\n",
        "\n",
        "            total_voxels += volume_voxels\n",
        "\n",
        "        # Summary\n",
        "        print(f\"\\n📈 TEST SET SUMMARY:\")\n",
        "        print(f\"   Total volumes: {len(self.test_loader)}\")\n",
        "        print(f\"   Volumes with tumors: {tumor_volumes} ({tumor_volumes/len(self.test_loader)*100:.1f}%)\")\n",
        "        print(f\"   Overall tumor ratio: {total_tumor_voxels/total_voxels:.6f}\")\n",
        "\n",
        "        if tumor_ratios:\n",
        "            print(f\"   Average tumor ratio (positive volumes): {np.mean(tumor_ratios):.6f}\")\n",
        "            print(f\"   Min tumor ratio: {np.min(tumor_ratios):.6f}\")\n",
        "            print(f\"   Max tumor ratio: {np.max(tumor_ratios):.6f}\")\n",
        "\n",
        "        return tumor_volumes, total_tumor_voxels/total_voxels, np.mean(tumor_ratios) if tumor_ratios else 0, np.min(tumor_ratios) if tumor_ratios else 0, np.max(tumor_ratios) if tumor_ratios else 0\n",
        "    def test(self):\n",
        "        \"\"\"Execute testing with checkpoint validation\"\"\"\n",
        "         # Run diagnostics first\n",
        "        self.debug_test_set_comprehensive()\n",
        "        # Use consistent architecture with training\n",
        "        model = self.create_unet_model(self.device)\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            print(\"📂 Loading checkpoint...\")\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "\n",
        "            # Validate checkpoint\n",
        "            if 'model_state_dict' not in checkpoint:\n",
        "                raise ValueError(\"Invalid checkpoint: missing 'model_state_dict'\")\n",
        "\n",
        "            try:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                print(\"✅ Checkpoint loaded successfully\")\n",
        "\n",
        "                # Print training info if available\n",
        "                if 'epoch' in checkpoint:\n",
        "                    print(f\"📅 Checkpoint from epoch: {checkpoint['epoch']}\")\n",
        "                if 'val_loss' in checkpoint:\n",
        "                    print(f\"📉 Checkpoint validation loss: {checkpoint['val_loss']:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Checkpoint loading failed: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Model file not found: {self.model_file}\")\n",
        "\n",
        "        # 🔥 ADD THIS RIGHT HERE - After model loads, before normal testing\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🚀 RUNNING QUICK THRESHOLD SENSITIVITY TEST\")\n",
        "        print(\"=\"*60)\n",
        "        threshold_results = self.quick_threshold_test()\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def check_current_predictions(self):\n",
        "        \"\"\"Check what the current model is predicting\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🔍 CHECKING CURRENT MODEL PREDICTIONS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        model = self.create_unet_model(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.train_loader):\n",
        "                if i >= 2: break  # Check only first 2 batches\n",
        "\n",
        "                inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "\n",
        "                print(f\"\\n📊 Sample {i}:\")\n",
        "                print(f\"  Input shape: {inputs.shape}\")\n",
        "                print(f\"  GT tumors: {labels.sum().item():,} voxels\")\n",
        "                print(f\"  Pred tumors: {preds.sum().item():,} voxels\")\n",
        "                print(f\"  Raw output range: [{outputs.min():.3f}, {outputs.max():.3f}]\")\n",
        "                print(f\"  Sigmoid range: [{torch.sigmoid(outputs).min():.3f}, {torch.sigmoid(outputs).max():.3f}]\")\n",
        "\n",
        "                # Check prediction distribution\n",
        "                unique_preds, counts = torch.unique(preds, return_counts=True)\n",
        "                print(f\"  Prediction distribution: {dict(zip(unique_preds.tolist(), counts.tolist()))}\")\n",
        "\n",
        "                # Calculate actual Dice for this sample\n",
        "                if labels.sum() > 0:\n",
        "                    dice = self.dice_score(preds, labels)\n",
        "                    print(f\"  Dice score: {dice:.4f}\")\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Execute full pipeline with validation\"\"\"\n",
        "        print(\"🚀 Starting pipeline with:\")\n",
        "        print(f\"   - Train samples: {len(self.train_loader.dataset)}\")\n",
        "        print(f\"   - Valid samples: {len(self.valid_loader.dataset)}\")\n",
        "        print(f\"   - Test samples: {len(self.test_loader.dataset)}\")\n",
        "        print(f\"   - Device: {self.device}\")\n",
        "        print(f\"   - Output directory: {self.output_dir}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            self.train()\n",
        "            self.check_current_predictions()\n",
        "            self.test()\n",
        "\n",
        "            total_time = time.time() - start_time\n",
        "            print(f\"✅ Pipeline completed in {total_time/60:.2f} minutes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Pipeline failed: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "# ---------- Run ----------\n",
        "def main():\n",
        "    import multiprocessing as mp\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_Nifti_MONAI6_3Original\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 1,   # Effective patches per step = num_samples * batch_size\n",
        "        'num_epochs': 200,\n",
        "        'learning_rate': 1e-4,\n",
        "    }\n",
        "\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    Resized,\n",
        "    CopyItemsd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    SaveImaged,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "# from monai.transforms.utils import SaveTransform\n",
        "\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_ct_dir, input_seg_dir, output_dir, device=\"cuda:0\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_ct_dir = input_ct_dir\n",
        "        self.input_seg_dir = input_seg_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.ct_out_dir = os.path.join(output_dir, \"ct\")\n",
        "        self.seg_out_dir = os.path.join(output_dir, \"segment\")\n",
        "        os.makedirs(self.ct_out_dir, exist_ok=True)\n",
        "        os.makedirs(self.seg_out_dir, exist_ok=True)\n",
        "        self.model_path = model_path\n",
        "        self.model = self._load_model()\n",
        "        set_determinism(seed=42)\n",
        "        self.forward_transforms = self._get_forward_transforms()\n",
        "        self.inverse_transforms = None\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        model.load_state_dict(state_dict.get('model_state_dict', state_dict))\n",
        "\n",
        "        print(f\"✅ Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_forward_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            CopyItemsd(keys=[\"vol\"], names=[\"vol_meta_dict\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\"], spatial_size=(96, 96, 96)),\n",
        "            EnsureTyped(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _get_inverse_transforms(self):\n",
        "        return Compose([\n",
        "            Invertd(\n",
        "                keys=[\"seg\"],\n",
        "                transform=self.forward_transforms,\n",
        "                orig_keys=[\"vol\"],\n",
        "                meta_keys=[\"vol_meta_dict\"],\n",
        "                nearest_interp=True,\n",
        "                to_tensor=False,\n",
        "            ),\n",
        "            EnsureTyped(keys=[\"seg\"])\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        data = []\n",
        "        for f in os.listdir(self.input_ct_dir):\n",
        "            if f.endswith(('.nii', '.nii.gz')):\n",
        "                ct_path = os.path.join(self.input_ct_dir, f)\n",
        "                data.append({\"vol\": ct_path})\n",
        "        print(f\"🔍 Found {len(data)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data, transform=self.forward_transforms), batch_size=1, num_workers=0)\n",
        "\n",
        "    def infer(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                batch = decollate_batch(batch)[0]\n",
        "                vol_meta = batch[\"vol_meta_dict\"]\n",
        "                ct = batch[\"vol\"]\n",
        "\n",
        "                if ct.dim() == 4:\n",
        "                    ct = ct.unsqueeze(0)\n",
        "                ct = ct.to(self.device)\n",
        "\n",
        "                filename = os.path.basename(vol_meta.meta[\"filename_or_obj\"])\n",
        "                orig_vol = nib.load(vol_meta.meta[\"filename_or_obj\"]).get_fdata()\n",
        "                print(f\"🔍 Inference on [{i+1}] {filename} | shape = {ct.shape}\")\n",
        "                print(f\"🔍 Original volume shape = {orig_vol.shape}\")\n",
        "                pred = self.model(ct)\n",
        "                pred = (torch.sigmoid(pred) > 0.5).float()\n",
        "\n",
        "                print(f\"✅ Predicted mask shape: {pred.shape}\")\n",
        "\n",
        "                batch[\"seg\"] = pred.cpu().squeeze(0)\n",
        "                print(f\"✅ Batch shape: {batch['seg'].shape}\")\n",
        "\n",
        "                if self.inverse_transforms is None:\n",
        "                    self.inverse_transforms = self._get_inverse_transforms()\n",
        "\n",
        "                inverted = self.inverse_transforms(batch)\n",
        "                inv_seg = inverted[\"seg\"].squeeze(0).numpy()\n",
        "                inv_seg = (inv_seg > 0.5).astype(np.uint8)\n",
        "                print(f\"✅ Inverted mask shape: {inv_seg.shape}\")\n",
        "\n",
        "                self._save_nifti(inv_seg, vol_meta, self.seg_out_dir, filename, is_segmentation=True)\n",
        "\n",
        "\n",
        "    def _save_nifti(self, array, meta_tensor, out_dir, filename, is_segmentation=False):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        affine = meta_tensor.meta.get(\"original_affine\", meta_tensor.meta.get(\"affine\", np.eye(4)))\n",
        "        dtype = np.uint8 if is_segmentation else np.float32\n",
        "        nib_img = nib.Nifti1Image(array.astype(dtype), affine)\n",
        "        nib.save(nib_img, os.path.join(out_dir, filename))\n",
        "        print(f\"✅ Saved: {os.path.join(out_dir, filename)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "z6a0G1DXTIV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a85b9f-c61a-4fd8-b379-3bd00e32c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 89 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG3-01.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (59, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (59, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-01.nii.gz\n",
            "🔍 Inference on [2] LUNG3-02.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (57, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (57, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-02.nii.gz\n",
            "🔍 Inference on [3] LUNG3-03.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-03.nii.gz\n",
            "🔍 Inference on [4] LUNG3-04.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-04.nii.gz\n",
            "🔍 Inference on [5] LUNG3-05.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (229, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (229, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-05.nii.gz\n",
            "🔍 Inference on [6] LUNG3-06.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (61, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (61, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-06.nii.gz\n",
            "🔍 Inference on [7] LUNG3-07.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (86, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (86, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-07.nii.gz\n",
            "🔍 Inference on [8] LUNG3-08.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-08.nii.gz\n",
            "🔍 Inference on [9] LUNG3-09.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (140, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (140, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-09.nii.gz\n",
            "🔍 Inference on [10] LUNG3-10.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-10.nii.gz\n",
            "🔍 Inference on [11] LUNG3-11.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (252, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (252, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-11.nii.gz\n",
            "🔍 Inference on [12] LUNG3-12.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (206, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (206, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-12.nii.gz\n",
            "🔍 Inference on [13] LUNG3-13.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (71, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (71, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-13.nii.gz\n",
            "🔍 Inference on [14] LUNG3-14.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (325, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (325, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-14.nii.gz\n",
            "🔍 Inference on [15] LUNG3-15.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (234, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (234, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-15.nii.gz\n",
            "🔍 Inference on [16] LUNG3-16.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (192, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (192, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-16.nii.gz\n",
            "🔍 Inference on [17] LUNG3-17.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (226, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (226, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-17.nii.gz\n",
            "🔍 Inference on [18] LUNG3-18.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-18.nii.gz\n",
            "🔍 Inference on [19] LUNG3-19.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-19.nii.gz\n",
            "🔍 Inference on [20] LUNG3-20.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (176, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (176, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-20.nii.gz\n",
            "🔍 Inference on [21] LUNG3-21.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-21.nii.gz\n",
            "🔍 Inference on [22] LUNG3-22.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (236, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (236, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-22.nii.gz\n",
            "🔍 Inference on [23] LUNG3-23.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (52, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (52, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-23.nii.gz\n",
            "🔍 Inference on [24] LUNG3-24.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-24.nii.gz\n",
            "🔍 Inference on [25] LUNG3-25.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (202, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (202, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-25.nii.gz\n",
            "🔍 Inference on [26] LUNG3-26.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (83, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (83, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-26.nii.gz\n",
            "🔍 Inference on [27] LUNG3-27.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (149, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (149, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-27.nii.gz\n",
            "🔍 Inference on [28] LUNG3-28.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (86, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (86, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-28.nii.gz\n",
            "🔍 Inference on [29] LUNG3-29.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (173, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (173, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-29.nii.gz\n",
            "🔍 Inference on [30] LUNG3-30.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (72, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (72, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-30.nii.gz\n",
            "🔍 Inference on [31] LUNG3-31.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (242, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (242, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-31.nii.gz\n",
            "🔍 Inference on [32] LUNG3-32.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (58, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (58, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-32.nii.gz\n",
            "🔍 Inference on [33] LUNG3-33.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (276, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (276, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-33.nii.gz\n",
            "🔍 Inference on [34] LUNG3-34.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-34.nii.gz\n",
            "🔍 Inference on [35] LUNG3-35.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (253, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (253, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-35.nii.gz\n",
            "🔍 Inference on [36] LUNG3-36.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (356, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (356, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-36.nii.gz\n",
            "🔍 Inference on [37] LUNG3-37.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (97, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (97, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-37.nii.gz\n",
            "🔍 Inference on [38] LUNG3-38.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (223, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (223, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-38.nii.gz\n",
            "🔍 Inference on [39] LUNG3-39.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (82, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (82, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-39.nii.gz\n",
            "🔍 Inference on [40] LUNG3-40.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (239, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (239, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-40.nii.gz\n",
            "🔍 Inference on [41] LUNG3-41.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (110, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (110, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-41.nii.gz\n",
            "🔍 Inference on [42] LUNG3-42.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-42.nii.gz\n",
            "🔍 Inference on [43] LUNG3-43.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (68, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (68, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-43.nii.gz\n",
            "🔍 Inference on [44] LUNG3-44.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (227, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (227, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-44.nii.gz\n",
            "🔍 Inference on [45] LUNG3-45.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-45.nii.gz\n",
            "🔍 Inference on [46] LUNG3-46.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (184, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (184, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-46.nii.gz\n",
            "🔍 Inference on [47] LUNG3-47.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (275, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (275, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-47.nii.gz\n",
            "🔍 Inference on [48] LUNG3-48.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (157, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (157, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-48.nii.gz\n",
            "🔍 Inference on [49] LUNG3-49.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (89, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (89, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-49.nii.gz\n",
            "🔍 Inference on [50] LUNG3-50.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-50.nii.gz\n",
            "🔍 Inference on [51] LUNG3-51.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (76, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (76, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-51.nii.gz\n",
            "🔍 Inference on [52] LUNG3-52.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (50, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (50, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-52.nii.gz\n",
            "🔍 Inference on [53] LUNG3-53.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-53.nii.gz\n",
            "🔍 Inference on [54] LUNG3-54.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (175, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (175, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-54.nii.gz\n",
            "🔍 Inference on [55] LUNG3-55.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (72, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (72, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-55.nii.gz\n",
            "🔍 Inference on [56] LUNG3-56.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-56.nii.gz\n",
            "🔍 Inference on [57] LUNG3-57.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-57.nii.gz\n",
            "🔍 Inference on [58] LUNG3-58.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (64, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (64, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-58.nii.gz\n",
            "🔍 Inference on [59] LUNG3-59.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (62, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (62, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-59.nii.gz\n",
            "🔍 Inference on [60] LUNG3-60.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-60.nii.gz\n",
            "🔍 Inference on [61] LUNG3-61.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (203, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (203, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-61.nii.gz\n",
            "🔍 Inference on [62] LUNG3-62.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (66, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (66, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-62.nii.gz\n",
            "🔍 Inference on [63] LUNG3-63.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (57, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (57, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-63.nii.gz\n",
            "🔍 Inference on [64] LUNG3-64.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (172, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (172, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-64.nii.gz\n",
            "🔍 Inference on [65] LUNG3-65.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (175, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (175, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-65.nii.gz\n",
            "🔍 Inference on [66] LUNG3-66.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (69, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (69, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-66.nii.gz\n",
            "🔍 Inference on [67] LUNG3-67.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-67.nii.gz\n",
            "🔍 Inference on [68] LUNG3-68.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (60, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (60, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-68.nii.gz\n",
            "🔍 Inference on [69] LUNG3-69.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-69.nii.gz\n",
            "🔍 Inference on [70] LUNG3-70.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (258, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (258, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-70.nii.gz\n",
            "🔍 Inference on [71] LUNG3-71.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (287, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (287, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-71.nii.gz\n",
            "🔍 Inference on [72] LUNG3-72.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (84, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (84, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-72.nii.gz\n",
            "🔍 Inference on [73] LUNG3-73.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (218, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (218, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-73.nii.gz\n",
            "🔍 Inference on [74] LUNG3-74.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (67, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (67, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-74.nii.gz\n",
            "🔍 Inference on [75] LUNG3-75.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (88, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (88, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-75.nii.gz\n",
            "🔍 Inference on [76] LUNG3-76.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (74, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (74, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-76.nii.gz\n",
            "🔍 Inference on [77] LUNG3-77.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-77.nii.gz\n",
            "🔍 Inference on [78] LUNG3-78.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (255, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (255, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-78.nii.gz\n",
            "🔍 Inference on [79] LUNG3-79.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (240, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (240, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-79.nii.gz\n",
            "🔍 Inference on [80] LUNG3-80.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (59, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (59, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-80.nii.gz\n",
            "🔍 Inference on [81] LUNG3-81.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (307, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (307, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-81.nii.gz\n",
            "🔍 Inference on [82] LUNG3-82.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (78, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (78, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-82.nii.gz\n",
            "🔍 Inference on [83] LUNG3-83.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (178, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (178, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-83.nii.gz\n",
            "🔍 Inference on [84] LUNG3-84.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (66, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (66, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-84.nii.gz\n",
            "🔍 Inference on [85] LUNG3-85.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (234, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (234, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-85.nii.gz\n",
            "🔍 Inference on [86] LUNG3-86.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (78, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (78, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-86.nii.gz\n",
            "🔍 Inference on [87] LUNG3-87.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (79, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (79, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-87.nii.gz\n",
            "🔍 Inference on [88] LUNG3-88.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (154, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (154, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-88.nii.gz\n",
            "🔍 Inference on [89] LUNG3-89.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (158, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (158, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-89.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "b54762e0-6093-45f5-86b6-48c278f39d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 38 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG1-001.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-001.nii.gz\n",
            "🔍 Inference on [2] LUNG1-025.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-025.nii.gz\n",
            "🔍 Inference on [3] LUNG1-027.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (108, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (108, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-027.nii.gz\n",
            "🔍 Inference on [4] LUNG1-034.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-034.nii.gz\n",
            "🔍 Inference on [5] LUNG1-039.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-039.nii.gz\n",
            "🔍 Inference on [6] LUNG1-066.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-066.nii.gz\n",
            "🔍 Inference on [7] LUNG1-078.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-078.nii.gz\n",
            "🔍 Inference on [8] LUNG1-088.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (123, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (123, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-088.nii.gz\n",
            "🔍 Inference on [9] LUNG1-107.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (116, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (116, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-107.nii.gz\n",
            "🔍 Inference on [10] LUNG1-132.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (114, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (114, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-132.nii.gz\n",
            "🔍 Inference on [11] LUNG1-133.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (184, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (184, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-133.nii.gz\n",
            "🔍 Inference on [12] LUNG1-143.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-143.nii.gz\n",
            "🔍 Inference on [13] LUNG1-149.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (118, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (118, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-149.nii.gz\n",
            "🔍 Inference on [14] LUNG1-151.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (118, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (118, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-151.nii.gz\n",
            "🔍 Inference on [15] LUNG1-158.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-158.nii.gz\n",
            "🔍 Inference on [16] LUNG1-168.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-168.nii.gz\n",
            "🔍 Inference on [17] LUNG1-175.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (112, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (112, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-175.nii.gz\n",
            "🔍 Inference on [18] LUNG1-176.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-176.nii.gz\n",
            "🔍 Inference on [19] LUNG1-201.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-201.nii.gz\n",
            "🔍 Inference on [20] LUNG1-224.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-224.nii.gz\n",
            "🔍 Inference on [21] LUNG1-225.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-225.nii.gz\n",
            "🔍 Inference on [22] LUNG1-235.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (129, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (129, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-235.nii.gz\n",
            "🔍 Inference on [23] LUNG1-239.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-239.nii.gz\n",
            "🔍 Inference on [24] LUNG1-246.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-246.nii.gz\n",
            "🔍 Inference on [25] LUNG1-263.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-263.nii.gz\n",
            "🔍 Inference on [26] LUNG1-266.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-266.nii.gz\n",
            "🔍 Inference on [27] LUNG1-281.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (101, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (101, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-281.nii.gz\n",
            "🔍 Inference on [28] LUNG1-286.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-286.nii.gz\n",
            "🔍 Inference on [29] LUNG1-312.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-312.nii.gz\n",
            "🔍 Inference on [30] LUNG1-338.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-338.nii.gz\n",
            "🔍 Inference on [31] LUNG1-352.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-352.nii.gz\n",
            "🔍 Inference on [32] LUNG1-353.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-353.nii.gz\n",
            "🔍 Inference on [33] LUNG1-365.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-365.nii.gz\n",
            "🔍 Inference on [34] LUNG1-374.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (130, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (130, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-374.nii.gz\n",
            "🔍 Inference on [35] LUNG1-383.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-383.nii.gz\n",
            "🔍 Inference on [36] LUNG1-405.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-405.nii.gz\n",
            "🔍 Inference on [37] LUNG1-408.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (107, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (107, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-408.nii.gz\n",
            "🔍 Inference on [38] LUNG1-410.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-410.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"🎉 Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIi6GZ347x8",
        "outputId": "5b5fc90e-eeaf-4b07-d6a5-bf3197b8e4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "🔍 Found 43 NIfTI files for inference.\n",
            "🔍 Inference on [1] LUNG1-010.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (91, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (91, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-010.nii.gz\n",
            "🔍 Inference on [2] LUNG1-031.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (153, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (153, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-031.nii.gz\n",
            "🔍 Inference on [3] LUNG1-040.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (95, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (95, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-040.nii.gz\n",
            "🔍 Inference on [4] LUNG1-056.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-056.nii.gz\n",
            "🔍 Inference on [5] LUNG1-057.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (101, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (101, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-057.nii.gz\n",
            "🔍 Inference on [6] LUNG1-071.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (135, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (135, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-071.nii.gz\n",
            "🔍 Inference on [7] LUNG1-073.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (176, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (176, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-073.nii.gz\n",
            "🔍 Inference on [8] LUNG1-074.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (115, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (115, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-074.nii.gz\n",
            "🔍 Inference on [9] LUNG1-076.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-076.nii.gz\n",
            "🔍 Inference on [10] LUNG1-077.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (117, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (117, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-077.nii.gz\n",
            "🔍 Inference on [11] LUNG1-080.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-080.nii.gz\n",
            "🔍 Inference on [12] LUNG1-091.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (135, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (135, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-091.nii.gz\n",
            "🔍 Inference on [13] LUNG1-095.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (106, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (106, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-095.nii.gz\n",
            "🔍 Inference on [14] LUNG1-117.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (90, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (90, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-117.nii.gz\n",
            "🔍 Inference on [15] LUNG1-134.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (108, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (108, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-134.nii.gz\n",
            "🔍 Inference on [16] LUNG1-139.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (107, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (107, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-139.nii.gz\n",
            "🔍 Inference on [17] LUNG1-147.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (99, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (99, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-147.nii.gz\n",
            "🔍 Inference on [18] LUNG1-170.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (110, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (110, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-170.nii.gz\n",
            "🔍 Inference on [19] LUNG1-177.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-177.nii.gz\n",
            "🔍 Inference on [20] LUNG1-186.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-186.nii.gz\n",
            "🔍 Inference on [21] LUNG1-194.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (127, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (127, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-194.nii.gz\n",
            "🔍 Inference on [22] LUNG1-196.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-196.nii.gz\n",
            "🔍 Inference on [23] LUNG1-198.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (131, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (131, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-198.nii.gz\n",
            "🔍 Inference on [24] LUNG1-210.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (131, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (131, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-210.nii.gz\n",
            "🔍 Inference on [25] LUNG1-220.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (94, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (94, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-220.nii.gz\n",
            "🔍 Inference on [26] LUNG1-230.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-230.nii.gz\n",
            "🔍 Inference on [27] LUNG1-233.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-233.nii.gz\n",
            "🔍 Inference on [28] LUNG1-241.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-241.nii.gz\n",
            "🔍 Inference on [29] LUNG1-249.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-249.nii.gz\n",
            "🔍 Inference on [30] LUNG1-264.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (130, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (130, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-264.nii.gz\n",
            "🔍 Inference on [31] LUNG1-273.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (136, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (136, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-273.nii.gz\n",
            "🔍 Inference on [32] LUNG1-299.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (93, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (93, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-299.nii.gz\n",
            "🔍 Inference on [33] LUNG1-329.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-329.nii.gz\n",
            "🔍 Inference on [34] LUNG1-337.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-337.nii.gz\n",
            "🔍 Inference on [35] LUNG1-340.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (92, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (92, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-340.nii.gz\n",
            "🔍 Inference on [36] LUNG1-356.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-356.nii.gz\n",
            "🔍 Inference on [37] LUNG1-371.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (173, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (173, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-371.nii.gz\n",
            "🔍 Inference on [38] LUNG1-372.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-372.nii.gz\n",
            "🔍 Inference on [39] LUNG1-412.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-412.nii.gz\n",
            "🔍 Inference on [40] LUNG1-415.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (122, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (122, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-415.nii.gz\n",
            "🔍 Inference on [41] LUNG1-418.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (133, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (133, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-418.nii.gz\n",
            "🔍 Inference on [42] LUNG1-419.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-419.nii.gz\n",
            "🔍 Inference on [43] LUNG1-421.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "🔍 Original volume shape = (134, 512, 512)\n",
            "✅ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "✅ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "✅ Inverted mask shape: (134, 512, 512)\n",
            "✅ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-421.nii.gz\n",
            "🎉 Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"📁 Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMg4QlMuoA7YR7fJ/HYlXFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}