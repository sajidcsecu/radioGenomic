{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Nifti_MONAI2Balanced).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the strong augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29021c8d-45c8-423c-8bc9-d7af09645b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (1.26.4)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import AsDiscrete\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "            Compose, LoadImaged, EnsureChannelFirstD, Spacingd, Orientationd,\n",
        "            ScaleIntensityRanged, CropForegroundd, Resized, ToTensord,RandCropByPosNegLabeld,\n",
        "            RandFlipd, RandAffined, RandGaussianNoised, RandScaleIntensityd,SpatialPadd,ResizeWithPadOrCropd\n",
        "        )\n",
        "from monai.data import Dataset, DataLoader, CacheDataset, pad_list_data_collate\n",
        "from monai.networks.layers import Norm\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "from monai.transforms import EnsureTyped\n",
        "from monai.transforms import SaveImaged\n",
        "from monai.utils import set_determinism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "98369572-227a-4ed5-c4d9-3125bf05907f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceBCELoss3D(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.flatten()\n",
        "        targets = targets.flatten()\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "        self._init_metrics_csv()\n",
        "\n",
        "    def _init_metrics_csv(self):\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        y_true = y_true.astype(bool).flatten()\n",
        "        y_pred = y_pred.astype(bool).flatten()\n",
        "\n",
        "        return [\n",
        "            jaccard_score(y_true, y_pred, zero_division=0),\n",
        "            f1_score(y_true, y_pred, zero_division=0),\n",
        "            recall_score(y_true, y_pred, zero_division=0),\n",
        "            precision_score(y_true, y_pred, zero_division=0),\n",
        "            accuracy_score(y_true, y_pred)\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image: np.ndarray, pred_mask: np.ndarray, true_mask: np.ndarray, sample_id: str):\n",
        "        sample_dir = os.path.join(self.test_result_path, sample_id)\n",
        "        os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "        for i in range(image.shape[0]):\n",
        "            try:\n",
        "                fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "                ax[0].imshow(image[i], cmap='gray')\n",
        "                ax[0].set_title('Image')\n",
        "\n",
        "                ax[1].imshow(true_mask[i], cmap='gray')\n",
        "                ax[1].set_title('Ground Truth')\n",
        "\n",
        "                ax[2].imshow(pred_mask[i], cmap='gray')\n",
        "                ax[2].set_title('Prediction')\n",
        "\n",
        "                for a in ax:\n",
        "                    a.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(sample_dir, f'slice_{i:03d}.png'))\n",
        "                plt.close()\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Could not save slice {i} for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(5)\n",
        "        total_times = []\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5  # Binary thresholding\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy()\n",
        "\n",
        "                # Metrics\n",
        "                metrics = self.calculate_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "\n",
        "                # Identify sample name\n",
        "                sample_id = os.path.basename(batch[\"vol_meta_dict\"][\"filename_or_obj\"][0]).replace(\".nii.gz\", \"\")\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "        # Print summary\n",
        "        num_samples = len(test_loader)\n",
        "        print(\"\\nðŸ“Š Average Test Metrics:\")\n",
        "        print(f\"Jaccard:  {total_metrics[0]/num_samples:.4f}\")\n",
        "        print(f\"F1:       {total_metrics[1]/num_samples:.4f}\")\n",
        "        print(f\"Recall:   {total_metrics[2]/num_samples:.4f}\")\n",
        "        print(f\"Precision:{total_metrics[3]/num_samples:.4f}\")\n",
        "        print(f\"Accuracy: {total_metrics[4]/num_samples:.4f}\")\n",
        "        print(f\"âš¡ FPS:    {1 / np.mean(total_times):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (6). Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Validation loss improved. Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"â³ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # âœ… Always save full checkpoint (model + optimizer + val_loss + patience_counter)\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = torch.amp.GradScaler()  # no device_type here\n",
        "\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        for x in loader:\n",
        "            inputs, labels = x[\"vol\"].to(self.device), x[\"seg\"].to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast(device_type=device_type):\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x in loader:\n",
        "                inputs, labels = x[\"vol\"].to(self.device), x[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = DiceBCELoss3D()\n",
        "\n",
        "        # Initialize state\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        # ðŸ“¦ Restore from model checkpoint if exists\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        # ðŸ“Š Restore training history from loss CSV\n",
        "        if os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, 'r') as f:\n",
        "                reader = csv.reader(f)\n",
        "                next(reader)\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    last_epoch = int(rows[-1][0])\n",
        "                    start_epoch = last_epoch + 1\n",
        "                    history['train_loss'] = [float(r[1]) for r in rows]\n",
        "                    history['valid_loss'] = [float(r[2]) for r in rows]\n",
        "                    if start_val_loss_min is None:\n",
        "                        start_val_loss_min = min(history['valid_loss'])\n",
        "\n",
        "            # ðŸ’¾ Make a backup copy\n",
        "            backup_path = self.loss_result_path.replace(\".csv\", \"_backup.csv\")\n",
        "            shutil.copy(self.loss_result_path, backup_path)\n",
        "\n",
        "        # ðŸ›‘ Initialize EarlyStopping\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter\n",
        "        )\n",
        "\n",
        "        # ðŸ“ If loss file not present, create CSV header\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # ðŸš‚ Training Loop\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
        "            print(f\"Epoch {epoch:03d} | Time: {epoch_mins}m {epoch_secs}s | \"\n",
        "                  f\"Train: {train_loss:.6f} | Val: {valid_loss:.6f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            # ðŸ›‘ Early stopping check\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"ðŸ›‘ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (7). Pipeline"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwcTHPshqu0O",
        "outputId": "86952d4d-8fbd-48d4-98b5-cef89e604401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Loading datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
            "  warn_deprecated(argname, msg, warning_category)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”Ž Running dataset sanity checks...\n",
            "  [train] checked 30 samples. total pos voxels: 488240.0, total voxels: 26542080, pos fraction: 0.0183949\n",
            "  [train] example mask unique values (approx): [0.0, 1.0]\n",
            "  [valid] checked 22 samples. total pos voxels: 121267.0, total voxels: 19464192, pos fraction: 0.00623026\n",
            "  [valid] example mask unique values (approx): [0.0, 1.0]\n",
            "  [test] checked 30 samples. total pos voxels: 86808.0, total voxels: 26542080, pos fraction: 0.00327058\n",
            "  [test] example mask unique values (approx): [0.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.setup_paths()\n",
        "        print(\"ðŸ“¦ Loading datasets...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self.prepare_loaders()\n",
        "        # RUN quick dataset sanity checks immediately\n",
        "        print(\"ðŸ”Ž Running dataset sanity checks...\")\n",
        "        self.print_dataset_stats(self.train_loader, name=\"train\", n=30)\n",
        "        self.print_dataset_stats(self.valid_loader, name=\"valid\", n=30)\n",
        "        self.print_dataset_stats(self.test_loader,  name=\"test\",  n=30)\n",
        "\n",
        "    def print_dataset_stats(self, loader, name=\"train\", n=20):\n",
        "        \"\"\"\n",
        "        Quick estimate of how many positive voxels exist per sample and\n",
        "        checks whether segmentation masks are binary (0/1).\n",
        "        \"\"\"\n",
        "        tot_pos = 0.0\n",
        "        tot_vox = 0\n",
        "        samples = 0\n",
        "        unique_vals = set()\n",
        "        for i, batch in enumerate(loader):\n",
        "            seg = batch[\"seg\"][0, 0]  # [D,H,W] (first sample in batch)\n",
        "            seg_cpu = seg.cpu()\n",
        "            tot_pos += float(seg_cpu.sum().item())\n",
        "            tot_vox += seg_cpu.numel()\n",
        "            samples += 1\n",
        "\n",
        "            # collect unique values (but limit growth)\n",
        "            vals = torch.unique(seg_cpu)\n",
        "            for v in vals.tolist():\n",
        "                unique_vals.add(v)\n",
        "            if i + 1 >= n:\n",
        "                break\n",
        "\n",
        "        frac = tot_pos / (tot_vox + 1e-12)\n",
        "        print(f\"  [{name}] checked {samples} samples. total pos voxels: {tot_pos:.1f}, total voxels: {tot_vox}, pos fraction: {frac:.6g}\")\n",
        "        print(f\"  [{name}] example mask unique values (approx): {sorted(list(unique_vals))[:10]}\")\n",
        "        if frac == 0:\n",
        "            print(f\"  âš ï¸ [{name}] No positives found in the inspected samples. Check that your 'segment' files are correctly paired and not being erased by transforms.\")\n",
        "        if any(v not in (0.0, 1.0) for v in unique_vals):\n",
        "            print(f\"  âš ï¸ [{name}] Found non-binary mask values (not only 0/1). Ensure you use nearest interpolation for segment resizing.\")\n",
        "        return frac\n",
        "\n",
        "\n",
        "    def setup_paths(self):\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "    def prepare_loaders(self):\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        patch_size = (96, 96, 96)\n",
        "\n",
        "        def get_files(split):\n",
        "            ct = sorted(glob(os.path.join(self.dataset_dir, split, \"ct\", \"*.nii.gz\")))\n",
        "            seg = sorted(glob(os.path.join(self.dataset_dir, split, \"segment\", \"*.nii.gz\")))\n",
        "            return [{\"vol\": c, \"seg\": s} for c, s in zip(ct, seg)]\n",
        "\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            SpatialPadd(keys=[\"vol\", \"seg\"], spatial_size=patch_size),\n",
        "\n",
        "            # âœ… Patch-based balanced sampling\n",
        "            RandCropByPosNegLabeld(\n",
        "                keys=[\"vol\", \"seg\"],\n",
        "                label_key=\"seg\",\n",
        "                spatial_size=patch_size,\n",
        "                pos=1,  # force at least one positive patch per sample\n",
        "                neg=1,  # also sample negatives\n",
        "                num_samples=4,  # 4 patches per volume per epoch\n",
        "                image_key=\"vol\",\n",
        "                image_threshold=0,\n",
        "            ),\n",
        "\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=0),\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=1),\n",
        "            RandAffined(keys=[\"vol\", \"seg\"], prob=0.3,\n",
        "                        rotate_range=(0.1, 0.1, 0.1),\n",
        "                        scale_range=(0.1, 0.1, 0.1),\n",
        "                        mode=(\"bilinear\", \"nearest\")),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.1),\n",
        "            RandScaleIntensityd(keys=[\"vol\"], factors=0.1, prob=0.5),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ])\n",
        "\n",
        "        # base_transforms = Compose([\n",
        "        #     LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "        #     EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "        #     Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "        #     Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "        #     ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "        #     CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "        #     # ðŸ”¹ Pad or crop to a fixed size (same as training patch size or larger ROI)\n",
        "        #     SpatialPadd(keys=[\"vol\", \"seg\"], spatial_size=patch_size),\n",
        "        #     ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        # ])\n",
        "\n",
        "        base_transforms = Compose([\n",
        "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "        EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "        CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "        ResizeWithPadOrCropd(keys=[\"vol\", \"seg\"], spatial_size=patch_size),  # ðŸ”¹ ensure fixed shape\n",
        "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ])\n",
        "\n",
        "        train_loader = DataLoader(Dataset(get_files(\"train\"), train_transforms), batch_size=self.config['batch_size'], shuffle=True)\n",
        "        valid_loader = DataLoader(Dataset(get_files(\"valid\"), base_transforms), batch_size=self.config['batch_size'])\n",
        "        test_loader = DataLoader(Dataset(get_files(\"test\"), base_transforms), batch_size=1)\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    def train(self):\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        self.train()\n",
        "        self.test()\n",
        "\n",
        "\n",
        "def main():\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_MONAI_Augmented\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 2,\n",
        "        'num_epochs': 100,\n",
        "        'learning_rate': 1e-4,\n",
        "    }\n",
        "    pipeline = UnetPipeline(config)\n",
        "    # pipeline.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    Resized,\n",
        "    CopyItemsd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    SaveImaged,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "# from monai.transforms.utils import SaveTransform\n",
        "\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_ct_dir, input_seg_dir, output_dir, device=\"cuda:0\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_ct_dir = input_ct_dir\n",
        "        self.input_seg_dir = input_seg_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.ct_out_dir = os.path.join(output_dir, \"ct\")\n",
        "        self.seg_out_dir = os.path.join(output_dir, \"segment\")\n",
        "        os.makedirs(self.ct_out_dir, exist_ok=True)\n",
        "        os.makedirs(self.seg_out_dir, exist_ok=True)\n",
        "        self.model_path = model_path\n",
        "        self.model = self._load_model()\n",
        "        set_determinism(seed=42)\n",
        "        self.forward_transforms = self._get_forward_transforms()\n",
        "        self.inverse_transforms = None\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        model.load_state_dict(state_dict.get('model_state_dict', state_dict))\n",
        "\n",
        "        print(f\"âœ… Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_forward_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            CopyItemsd(keys=[\"vol\"], names=[\"vol_meta_dict\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\"], spatial_size=(96, 96, 96)),\n",
        "            EnsureTyped(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _get_inverse_transforms(self):\n",
        "        return Compose([\n",
        "            Invertd(\n",
        "                keys=[\"seg\"],\n",
        "                transform=self.forward_transforms,\n",
        "                orig_keys=[\"vol\"],\n",
        "                meta_keys=[\"vol_meta_dict\"],\n",
        "                nearest_interp=True,\n",
        "                to_tensor=False,\n",
        "            ),\n",
        "            EnsureTyped(keys=[\"seg\"])\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        data = []\n",
        "        for f in os.listdir(self.input_ct_dir):\n",
        "            if f.endswith(('.nii', '.nii.gz')):\n",
        "                ct_path = os.path.join(self.input_ct_dir, f)\n",
        "                data.append({\"vol\": ct_path})\n",
        "        print(f\"ðŸ” Found {len(data)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data, transform=self.forward_transforms), batch_size=1, num_workers=0)\n",
        "\n",
        "    def infer(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                batch = decollate_batch(batch)[0]\n",
        "                vol_meta = batch[\"vol_meta_dict\"]\n",
        "                ct = batch[\"vol\"]\n",
        "\n",
        "                if ct.dim() == 4:\n",
        "                    ct = ct.unsqueeze(0)\n",
        "                ct = ct.to(self.device)\n",
        "\n",
        "                filename = os.path.basename(vol_meta.meta[\"filename_or_obj\"])\n",
        "                orig_vol = nib.load(vol_meta.meta[\"filename_or_obj\"]).get_fdata()\n",
        "                print(f\"ðŸ” Inference on [{i+1}] {filename} | shape = {ct.shape}\")\n",
        "                print(f\"ðŸ” Original volume shape = {orig_vol.shape}\")\n",
        "                pred = self.model(ct)\n",
        "                pred = (torch.sigmoid(pred) > 0.5).float()\n",
        "\n",
        "                print(f\"âœ… Predicted mask shape: {pred.shape}\")\n",
        "\n",
        "                batch[\"seg\"] = pred.cpu().squeeze(0)\n",
        "                print(f\"âœ… Batch shape: {batch['seg'].shape}\")\n",
        "\n",
        "                if self.inverse_transforms is None:\n",
        "                    self.inverse_transforms = self._get_inverse_transforms()\n",
        "\n",
        "                inverted = self.inverse_transforms(batch)\n",
        "                inv_seg = inverted[\"seg\"].squeeze(0).numpy()\n",
        "                inv_seg = (inv_seg > 0.5).astype(np.uint8)\n",
        "                print(f\"âœ… Inverted mask shape: {inv_seg.shape}\")\n",
        "\n",
        "                self._save_nifti(inv_seg, vol_meta, self.seg_out_dir, filename, is_segmentation=True)\n",
        "\n",
        "\n",
        "    def _save_nifti(self, array, meta_tensor, out_dir, filename, is_segmentation=False):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        affine = meta_tensor.meta.get(\"original_affine\", meta_tensor.meta.get(\"affine\", np.eye(4)))\n",
        "        dtype = np.uint8 if is_segmentation else np.float32\n",
        "        nib_img = nib.Nifti1Image(array.astype(dtype), affine)\n",
        "        nib.save(nib_img, os.path.join(out_dir, filename))\n",
        "        print(f\"âœ… Saved: {os.path.join(out_dir, filename)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "z6a0G1DXTIV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a85b9f-c61a-4fd8-b379-3bd00e32c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 89 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG3-01.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (59, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (59, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-01.nii.gz\n",
            "ðŸ” Inference on [2] LUNG3-02.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (57, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (57, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-02.nii.gz\n",
            "ðŸ” Inference on [3] LUNG3-03.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-03.nii.gz\n",
            "ðŸ” Inference on [4] LUNG3-04.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-04.nii.gz\n",
            "ðŸ” Inference on [5] LUNG3-05.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (229, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (229, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-05.nii.gz\n",
            "ðŸ” Inference on [6] LUNG3-06.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (61, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (61, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-06.nii.gz\n",
            "ðŸ” Inference on [7] LUNG3-07.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (86, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (86, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-07.nii.gz\n",
            "ðŸ” Inference on [8] LUNG3-08.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-08.nii.gz\n",
            "ðŸ” Inference on [9] LUNG3-09.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (140, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (140, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-09.nii.gz\n",
            "ðŸ” Inference on [10] LUNG3-10.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-10.nii.gz\n",
            "ðŸ” Inference on [11] LUNG3-11.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (252, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (252, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-11.nii.gz\n",
            "ðŸ” Inference on [12] LUNG3-12.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (206, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (206, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-12.nii.gz\n",
            "ðŸ” Inference on [13] LUNG3-13.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (71, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (71, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-13.nii.gz\n",
            "ðŸ” Inference on [14] LUNG3-14.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (325, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (325, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-14.nii.gz\n",
            "ðŸ” Inference on [15] LUNG3-15.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (234, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (234, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-15.nii.gz\n",
            "ðŸ” Inference on [16] LUNG3-16.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (192, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (192, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-16.nii.gz\n",
            "ðŸ” Inference on [17] LUNG3-17.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (226, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (226, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-17.nii.gz\n",
            "ðŸ” Inference on [18] LUNG3-18.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-18.nii.gz\n",
            "ðŸ” Inference on [19] LUNG3-19.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-19.nii.gz\n",
            "ðŸ” Inference on [20] LUNG3-20.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (176, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (176, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-20.nii.gz\n",
            "ðŸ” Inference on [21] LUNG3-21.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-21.nii.gz\n",
            "ðŸ” Inference on [22] LUNG3-22.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (236, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (236, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-22.nii.gz\n",
            "ðŸ” Inference on [23] LUNG3-23.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (52, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (52, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-23.nii.gz\n",
            "ðŸ” Inference on [24] LUNG3-24.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-24.nii.gz\n",
            "ðŸ” Inference on [25] LUNG3-25.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (202, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (202, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-25.nii.gz\n",
            "ðŸ” Inference on [26] LUNG3-26.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (83, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (83, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-26.nii.gz\n",
            "ðŸ” Inference on [27] LUNG3-27.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (149, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (149, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-27.nii.gz\n",
            "ðŸ” Inference on [28] LUNG3-28.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (86, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (86, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-28.nii.gz\n",
            "ðŸ” Inference on [29] LUNG3-29.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (173, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (173, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-29.nii.gz\n",
            "ðŸ” Inference on [30] LUNG3-30.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (72, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (72, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-30.nii.gz\n",
            "ðŸ” Inference on [31] LUNG3-31.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (242, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (242, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-31.nii.gz\n",
            "ðŸ” Inference on [32] LUNG3-32.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (58, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (58, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-32.nii.gz\n",
            "ðŸ” Inference on [33] LUNG3-33.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (276, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (276, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-33.nii.gz\n",
            "ðŸ” Inference on [34] LUNG3-34.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-34.nii.gz\n",
            "ðŸ” Inference on [35] LUNG3-35.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (253, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (253, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-35.nii.gz\n",
            "ðŸ” Inference on [36] LUNG3-36.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (356, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (356, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-36.nii.gz\n",
            "ðŸ” Inference on [37] LUNG3-37.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (97, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (97, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-37.nii.gz\n",
            "ðŸ” Inference on [38] LUNG3-38.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (223, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (223, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-38.nii.gz\n",
            "ðŸ” Inference on [39] LUNG3-39.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (82, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (82, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-39.nii.gz\n",
            "ðŸ” Inference on [40] LUNG3-40.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (239, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (239, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-40.nii.gz\n",
            "ðŸ” Inference on [41] LUNG3-41.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (110, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (110, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-41.nii.gz\n",
            "ðŸ” Inference on [42] LUNG3-42.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-42.nii.gz\n",
            "ðŸ” Inference on [43] LUNG3-43.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (68, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (68, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-43.nii.gz\n",
            "ðŸ” Inference on [44] LUNG3-44.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (227, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (227, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-44.nii.gz\n",
            "ðŸ” Inference on [45] LUNG3-45.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-45.nii.gz\n",
            "ðŸ” Inference on [46] LUNG3-46.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (184, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (184, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-46.nii.gz\n",
            "ðŸ” Inference on [47] LUNG3-47.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (275, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (275, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-47.nii.gz\n",
            "ðŸ” Inference on [48] LUNG3-48.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (157, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (157, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-48.nii.gz\n",
            "ðŸ” Inference on [49] LUNG3-49.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (89, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (89, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-49.nii.gz\n",
            "ðŸ” Inference on [50] LUNG3-50.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-50.nii.gz\n",
            "ðŸ” Inference on [51] LUNG3-51.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (76, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (76, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-51.nii.gz\n",
            "ðŸ” Inference on [52] LUNG3-52.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (50, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (50, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-52.nii.gz\n",
            "ðŸ” Inference on [53] LUNG3-53.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-53.nii.gz\n",
            "ðŸ” Inference on [54] LUNG3-54.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (175, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (175, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-54.nii.gz\n",
            "ðŸ” Inference on [55] LUNG3-55.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (72, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (72, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-55.nii.gz\n",
            "ðŸ” Inference on [56] LUNG3-56.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-56.nii.gz\n",
            "ðŸ” Inference on [57] LUNG3-57.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-57.nii.gz\n",
            "ðŸ” Inference on [58] LUNG3-58.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (64, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (64, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-58.nii.gz\n",
            "ðŸ” Inference on [59] LUNG3-59.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (62, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (62, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-59.nii.gz\n",
            "ðŸ” Inference on [60] LUNG3-60.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-60.nii.gz\n",
            "ðŸ” Inference on [61] LUNG3-61.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (203, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (203, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-61.nii.gz\n",
            "ðŸ” Inference on [62] LUNG3-62.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (66, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (66, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-62.nii.gz\n",
            "ðŸ” Inference on [63] LUNG3-63.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (57, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (57, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-63.nii.gz\n",
            "ðŸ” Inference on [64] LUNG3-64.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (172, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (172, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-64.nii.gz\n",
            "ðŸ” Inference on [65] LUNG3-65.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (175, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (175, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-65.nii.gz\n",
            "ðŸ” Inference on [66] LUNG3-66.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (69, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (69, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-66.nii.gz\n",
            "ðŸ” Inference on [67] LUNG3-67.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-67.nii.gz\n",
            "ðŸ” Inference on [68] LUNG3-68.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (60, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (60, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-68.nii.gz\n",
            "ðŸ” Inference on [69] LUNG3-69.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-69.nii.gz\n",
            "ðŸ” Inference on [70] LUNG3-70.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (258, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (258, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-70.nii.gz\n",
            "ðŸ” Inference on [71] LUNG3-71.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (287, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (287, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-71.nii.gz\n",
            "ðŸ” Inference on [72] LUNG3-72.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (84, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (84, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-72.nii.gz\n",
            "ðŸ” Inference on [73] LUNG3-73.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (218, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (218, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-73.nii.gz\n",
            "ðŸ” Inference on [74] LUNG3-74.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (67, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (67, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-74.nii.gz\n",
            "ðŸ” Inference on [75] LUNG3-75.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (88, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (88, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-75.nii.gz\n",
            "ðŸ” Inference on [76] LUNG3-76.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (74, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (74, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-76.nii.gz\n",
            "ðŸ” Inference on [77] LUNG3-77.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-77.nii.gz\n",
            "ðŸ” Inference on [78] LUNG3-78.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (255, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (255, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-78.nii.gz\n",
            "ðŸ” Inference on [79] LUNG3-79.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (240, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (240, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-79.nii.gz\n",
            "ðŸ” Inference on [80] LUNG3-80.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (59, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (59, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-80.nii.gz\n",
            "ðŸ” Inference on [81] LUNG3-81.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (307, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (307, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-81.nii.gz\n",
            "ðŸ” Inference on [82] LUNG3-82.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (78, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (78, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-82.nii.gz\n",
            "ðŸ” Inference on [83] LUNG3-83.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (178, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (178, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-83.nii.gz\n",
            "ðŸ” Inference on [84] LUNG3-84.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (66, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (66, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-84.nii.gz\n",
            "ðŸ” Inference on [85] LUNG3-85.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (234, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (234, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-85.nii.gz\n",
            "ðŸ” Inference on [86] LUNG3-86.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (78, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (78, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-86.nii.gz\n",
            "ðŸ” Inference on [87] LUNG3-87.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (79, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (79, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-87.nii.gz\n",
            "ðŸ” Inference on [88] LUNG3-88.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (154, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (154, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-88.nii.gz\n",
            "ðŸ” Inference on [89] LUNG3-89.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (158, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (158, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-89.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "b54762e0-6093-45f5-86b6-48c278f39d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 38 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG1-001.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-001.nii.gz\n",
            "ðŸ” Inference on [2] LUNG1-025.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-025.nii.gz\n",
            "ðŸ” Inference on [3] LUNG1-027.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (108, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (108, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-027.nii.gz\n",
            "ðŸ” Inference on [4] LUNG1-034.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-034.nii.gz\n",
            "ðŸ” Inference on [5] LUNG1-039.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-039.nii.gz\n",
            "ðŸ” Inference on [6] LUNG1-066.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-066.nii.gz\n",
            "ðŸ” Inference on [7] LUNG1-078.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-078.nii.gz\n",
            "ðŸ” Inference on [8] LUNG1-088.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (123, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (123, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-088.nii.gz\n",
            "ðŸ” Inference on [9] LUNG1-107.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (116, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (116, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-107.nii.gz\n",
            "ðŸ” Inference on [10] LUNG1-132.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (114, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (114, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-132.nii.gz\n",
            "ðŸ” Inference on [11] LUNG1-133.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (184, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (184, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-133.nii.gz\n",
            "ðŸ” Inference on [12] LUNG1-143.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-143.nii.gz\n",
            "ðŸ” Inference on [13] LUNG1-149.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (118, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (118, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-149.nii.gz\n",
            "ðŸ” Inference on [14] LUNG1-151.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (118, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (118, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-151.nii.gz\n",
            "ðŸ” Inference on [15] LUNG1-158.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-158.nii.gz\n",
            "ðŸ” Inference on [16] LUNG1-168.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-168.nii.gz\n",
            "ðŸ” Inference on [17] LUNG1-175.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (112, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (112, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-175.nii.gz\n",
            "ðŸ” Inference on [18] LUNG1-176.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-176.nii.gz\n",
            "ðŸ” Inference on [19] LUNG1-201.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-201.nii.gz\n",
            "ðŸ” Inference on [20] LUNG1-224.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-224.nii.gz\n",
            "ðŸ” Inference on [21] LUNG1-225.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-225.nii.gz\n",
            "ðŸ” Inference on [22] LUNG1-235.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (129, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (129, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-235.nii.gz\n",
            "ðŸ” Inference on [23] LUNG1-239.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-239.nii.gz\n",
            "ðŸ” Inference on [24] LUNG1-246.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-246.nii.gz\n",
            "ðŸ” Inference on [25] LUNG1-263.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-263.nii.gz\n",
            "ðŸ” Inference on [26] LUNG1-266.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-266.nii.gz\n",
            "ðŸ” Inference on [27] LUNG1-281.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (101, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (101, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-281.nii.gz\n",
            "ðŸ” Inference on [28] LUNG1-286.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-286.nii.gz\n",
            "ðŸ” Inference on [29] LUNG1-312.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-312.nii.gz\n",
            "ðŸ” Inference on [30] LUNG1-338.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-338.nii.gz\n",
            "ðŸ” Inference on [31] LUNG1-352.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-352.nii.gz\n",
            "ðŸ” Inference on [32] LUNG1-353.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-353.nii.gz\n",
            "ðŸ” Inference on [33] LUNG1-365.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-365.nii.gz\n",
            "ðŸ” Inference on [34] LUNG1-374.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (130, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (130, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-374.nii.gz\n",
            "ðŸ” Inference on [35] LUNG1-383.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-383.nii.gz\n",
            "ðŸ” Inference on [36] LUNG1-405.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-405.nii.gz\n",
            "ðŸ” Inference on [37] LUNG1-408.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (107, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (107, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-408.nii.gz\n",
            "ðŸ” Inference on [38] LUNG1-410.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-410.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"ðŸŽ‰ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIi6GZ347x8",
        "outputId": "5b5fc90e-eeaf-4b07-d6a5-bf3197b8e4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "ðŸ” Found 43 NIfTI files for inference.\n",
            "ðŸ” Inference on [1] LUNG1-010.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (91, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (91, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-010.nii.gz\n",
            "ðŸ” Inference on [2] LUNG1-031.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (153, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (153, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-031.nii.gz\n",
            "ðŸ” Inference on [3] LUNG1-040.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (95, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (95, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-040.nii.gz\n",
            "ðŸ” Inference on [4] LUNG1-056.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-056.nii.gz\n",
            "ðŸ” Inference on [5] LUNG1-057.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (101, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (101, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-057.nii.gz\n",
            "ðŸ” Inference on [6] LUNG1-071.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (135, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (135, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-071.nii.gz\n",
            "ðŸ” Inference on [7] LUNG1-073.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (176, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (176, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-073.nii.gz\n",
            "ðŸ” Inference on [8] LUNG1-074.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (115, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (115, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-074.nii.gz\n",
            "ðŸ” Inference on [9] LUNG1-076.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-076.nii.gz\n",
            "ðŸ” Inference on [10] LUNG1-077.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (117, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (117, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-077.nii.gz\n",
            "ðŸ” Inference on [11] LUNG1-080.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-080.nii.gz\n",
            "ðŸ” Inference on [12] LUNG1-091.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (135, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (135, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-091.nii.gz\n",
            "ðŸ” Inference on [13] LUNG1-095.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (106, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (106, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-095.nii.gz\n",
            "ðŸ” Inference on [14] LUNG1-117.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (90, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (90, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-117.nii.gz\n",
            "ðŸ” Inference on [15] LUNG1-134.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (108, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (108, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-134.nii.gz\n",
            "ðŸ” Inference on [16] LUNG1-139.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (107, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (107, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-139.nii.gz\n",
            "ðŸ” Inference on [17] LUNG1-147.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (99, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (99, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-147.nii.gz\n",
            "ðŸ” Inference on [18] LUNG1-170.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (110, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (110, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-170.nii.gz\n",
            "ðŸ” Inference on [19] LUNG1-177.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-177.nii.gz\n",
            "ðŸ” Inference on [20] LUNG1-186.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-186.nii.gz\n",
            "ðŸ” Inference on [21] LUNG1-194.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (127, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (127, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-194.nii.gz\n",
            "ðŸ” Inference on [22] LUNG1-196.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-196.nii.gz\n",
            "ðŸ” Inference on [23] LUNG1-198.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (131, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (131, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-198.nii.gz\n",
            "ðŸ” Inference on [24] LUNG1-210.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (131, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (131, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-210.nii.gz\n",
            "ðŸ” Inference on [25] LUNG1-220.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (94, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (94, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-220.nii.gz\n",
            "ðŸ” Inference on [26] LUNG1-230.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-230.nii.gz\n",
            "ðŸ” Inference on [27] LUNG1-233.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-233.nii.gz\n",
            "ðŸ” Inference on [28] LUNG1-241.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-241.nii.gz\n",
            "ðŸ” Inference on [29] LUNG1-249.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-249.nii.gz\n",
            "ðŸ” Inference on [30] LUNG1-264.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (130, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (130, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-264.nii.gz\n",
            "ðŸ” Inference on [31] LUNG1-273.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (136, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (136, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-273.nii.gz\n",
            "ðŸ” Inference on [32] LUNG1-299.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (93, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (93, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-299.nii.gz\n",
            "ðŸ” Inference on [33] LUNG1-329.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-329.nii.gz\n",
            "ðŸ” Inference on [34] LUNG1-337.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-337.nii.gz\n",
            "ðŸ” Inference on [35] LUNG1-340.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (92, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (92, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-340.nii.gz\n",
            "ðŸ” Inference on [36] LUNG1-356.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-356.nii.gz\n",
            "ðŸ” Inference on [37] LUNG1-371.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (173, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (173, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-371.nii.gz\n",
            "ðŸ” Inference on [38] LUNG1-372.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-372.nii.gz\n",
            "ðŸ” Inference on [39] LUNG1-412.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-412.nii.gz\n",
            "ðŸ” Inference on [40] LUNG1-415.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (122, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (122, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-415.nii.gz\n",
            "ðŸ” Inference on [41] LUNG1-418.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (133, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (133, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-418.nii.gz\n",
            "ðŸ” Inference on [42] LUNG1-419.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-419.nii.gz\n",
            "ðŸ” Inference on [43] LUNG1-421.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "ðŸ” Original volume shape = (134, 512, 512)\n",
            "âœ… Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "âœ… Batch shape: torch.Size([1, 96, 96, 96])\n",
            "âœ… Inverted mask shape: (134, 512, 512)\n",
            "âœ… Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-421.nii.gz\n",
            "ðŸŽ‰ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"ðŸ“ Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOkW571pJjCQhuzBDTxpsn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}