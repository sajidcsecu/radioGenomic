{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/UnetinGPU_(Fifty_Fifty_TverskyLoss_And_Strong_Augmentation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 2D slices over GPU. The balanced sampler and the augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9OVdEeKXpMe",
        "outputId": "db329fb9-8579-489c-8bd3-7736fbaa0664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.1)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "from typing import List\n",
        "import torch.multiprocessing as mp\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torch.amp as amp\n",
        "import pickle\n",
        "from torch.utils.data import Sampler\n",
        "import torchvision.transforms.functional as TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "02245c13-aba8-4d54-f1e6-7589f6f8d8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4PdRsL8DChf"
      },
      "source": [
        "# (4) Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nTo3RxLmjW5r"
      },
      "outputs": [],
      "source": [
        "class StrongJointTransform:\n",
        "    def __init__(self, p_flip=0.5, p_rotate=0.5, p_gamma=0.5, p_noise=0.5):\n",
        "        self.p_flip = p_flip\n",
        "        self.p_rotate = p_rotate\n",
        "        self.p_gamma = p_gamma\n",
        "        self.p_noise = p_noise\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        if random.random() < self.p_flip:\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.hflip(image)\n",
        "                mask = TF.hflip(mask)\n",
        "            else:\n",
        "                image = TF.vflip(image)\n",
        "                mask = TF.vflip(mask)\n",
        "\n",
        "        if random.random() < self.p_rotate:\n",
        "            angle = random.choice([90, 180, 270])\n",
        "            image = TF.rotate(image, angle)\n",
        "            mask = TF.rotate(mask, angle)\n",
        "\n",
        "        if random.random() < self.p_gamma:\n",
        "            gamma = random.uniform(0.7, 1.5)\n",
        "            image = TF.adjust_gamma(image, gamma)\n",
        "\n",
        "        if random.random() < self.p_noise:\n",
        "            noise = torch.randn_like(image) * 0.05\n",
        "            image = torch.clamp(image + noise, 0, 1)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FvhtapeukPgt"
      },
      "outputs": [],
      "source": [
        "class BalancedTumorSampler(Sampler):\n",
        "    def __init__(self, dataset, tumor_ratio=0.5, shuffle=True, index_cache_path=None):\n",
        "        self.dataset = dataset\n",
        "        self.tumor_ratio = tumor_ratio\n",
        "        self.shuffle = shuffle\n",
        "        self.index_cache_path = index_cache_path\n",
        "\n",
        "        self.tumor_indices = []\n",
        "        self.non_tumor_indices = []\n",
        "\n",
        "        if index_cache_path and os.path.exists(index_cache_path):\n",
        "            print(f\"üìÇ Loading cached indices from {index_cache_path}\")\n",
        "            with open(index_cache_path, 'rb') as f:\n",
        "                cached = pickle.load(f)\n",
        "                self.tumor_indices = cached['tumor']\n",
        "                self.non_tumor_indices = cached['non_tumor']\n",
        "            print(f\"‚úÖ Loaded: {len(self.tumor_indices)} tumor, {len(self.non_tumor_indices)} non-tumor\")\n",
        "        else:\n",
        "            print(\"üõ†Ô∏è Computing tumor/non-tumor indices...\")\n",
        "            self._prepare_indices()\n",
        "            if index_cache_path:\n",
        "                print(f\"üíæ Saving indices to {index_cache_path}\")\n",
        "                with open(index_cache_path, 'wb') as f:\n",
        "                    pickle.dump({'tumor': self.tumor_indices, 'non_tumor': self.non_tumor_indices}, f)\n",
        "\n",
        "    def _prepare_indices(self):\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, mask = self.dataset[idx]\n",
        "            if mask.sum() > 0:\n",
        "                self.tumor_indices.append(idx)\n",
        "            else:\n",
        "                self.non_tumor_indices.append(idx)\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.tumor_indices)\n",
        "            random.shuffle(self.non_tumor_indices)\n",
        "\n",
        "        total_samples = min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n",
        "        num_tumor = int(self.tumor_ratio * total_samples)\n",
        "        num_non_tumor = total_samples - num_tumor\n",
        "\n",
        "        selected_tumor = self.tumor_indices[:num_tumor]\n",
        "        selected_non_tumor = self.non_tumor_indices[:num_non_tumor]\n",
        "\n",
        "        combined = selected_tumor + selected_non_tumor\n",
        "        if self.shuffle:\n",
        "            random.shuffle(combined)\n",
        "\n",
        "        return iter(combined)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.tumor_indices), len(self.non_tumor_indices)) * 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZoGkyWq93X-H"
      },
      "outputs": [],
      "source": [
        "class HDF5SegmentationDataset(Dataset):\n",
        "    def __init__(self, hdf5_path, transform=None):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.patient_ids = []\n",
        "\n",
        "        # Read only keys for indexing\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            self.patient_ids = list(f.keys())\n",
        "            self.slice_indices = [(pid, i) for pid in self.patient_ids for i in range(f[pid]['ct'].shape[0])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pid, slice_idx = self.slice_indices[idx]\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as f:\n",
        "            ct_slice = f[pid]['ct'][slice_idx]\n",
        "            mask_slice = f[pid]['mask'][slice_idx]\n",
        "\n",
        "        # Normalize CT to [0, 1]\n",
        "        ct_slice = (ct_slice - np.min(ct_slice)) / (np.max(ct_slice) - np.min(ct_slice) + 1e-5)\n",
        "\n",
        "        # Convert to torch tensors and add channel dim\n",
        "        ct_tensor = torch.tensor(ct_slice, dtype=torch.float32).unsqueeze(0)\n",
        "        mask_tensor = torch.tensor(mask_slice, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            ct_tensor, mask_tensor = self.transform(ct_tensor, mask_tensor)\n",
        "\n",
        "        return ct_tensor, mask_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2iHKHfcF3yP"
      },
      "source": [
        "# 2. Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PamAo5NoFsRv"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        p = self.pool(x)\n",
        "        return x, self.dropout(p)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.up = UpSample(in_channels, out_channels)\n",
        "        self.conv = DoubleConv(out_channels * 2, out_channels)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.e1 = EncoderBlock(in_channels, 64, dropout=dropout)\n",
        "        self.e2 = EncoderBlock(64, 128, dropout=dropout)\n",
        "        self.e3 = EncoderBlock(128, 256, dropout=dropout)\n",
        "        self.e4 = EncoderBlock(256, 512, dropout=dropout)\n",
        "\n",
        "        self.b = DoubleConv(512, 1024)\n",
        "        self.dropout_bottleneck = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.d1 = DecoderBlock(1024, 512, dropout=dropout)\n",
        "        self.d2 = DecoderBlock(512, 256, dropout=dropout)\n",
        "        self.d3 = DecoderBlock(256, 128, dropout=dropout)\n",
        "        self.d4 = DecoderBlock(128, 64, dropout=dropout)\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.e1(x)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        b = self.b(p4)\n",
        "        b = self.dropout_bottleneck(b)\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        return self.outputs(d4)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # double_conv = DoubleConv(256, 256)\n",
        "#     # print(double_conv)\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     input_image = torch.randn((1, 1, 512, 512), dtype=torch.float32)\n",
        "#     model = UNet(1, 1).to(device)\n",
        "#     input_image = input_image.to(device)\n",
        "#     out = model(input_image)\n",
        "#     print(out.shape)\n",
        "#     print(device)\n",
        "#     print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## 2. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, beta=0.5, smooth=1e-6):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        # Ensure sigmoid is applied\n",
        "        preds = torch.sigmoid(preds)\n",
        "\n",
        "        # Flatten\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        TP = (preds * targets).sum()\n",
        "        FP = ((1 - targets) * preds).sum()\n",
        "        FN = (targets * (1 - preds)).sum()\n",
        "\n",
        "        tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
        "        return 1 - tversky"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# 3. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str,metrics_csv, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.device = device\n",
        "        self.metrics_csv = metrics_csv\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Initialize CSV file with headers\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, mode='w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "        print(f\"Test results will be saved to: {self.test_result_path}\")\n",
        "        print(f\"Using device: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def calculate_metrics(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> List[float]:\n",
        "        # Apply sigmoid and threshold at 0.5\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        y_true_np = y_true.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy().astype(bool).reshape(-1)\n",
        "\n",
        "        # If ground truth is completely empty or prediction is empty, set zero_division=0 for clarity\n",
        "        return [\n",
        "            jaccard_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            f1_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            recall_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            precision_score(y_true_np, y_pred_np, zero_division=0),\n",
        "            accuracy_score(y_true_np, y_pred_np)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def save_result(self, image: torch.Tensor, org_mask: torch.Tensor, predicted_mask: torch.Tensor, sample_id: int) -> None:\n",
        "        predicted_mask = (predicted_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        org_mask = (org_mask.detach().cpu().numpy().squeeze() > 0.5).astype(np.uint8) * 255\n",
        "        image = (image.detach().cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "        h, w = image.shape\n",
        "        line = np.ones((h, 10), dtype=np.uint8) * 128\n",
        "        cat_images = np.concatenate([image, line, org_mask, line, predicted_mask], axis=1)\n",
        "\n",
        "        file_name = os.path.join(self.test_result_path, f\"sample_{sample_id}.png\")\n",
        "        success = cv2.imwrite(file_name, cat_images)\n",
        "\n",
        "        if success:\n",
        "            print(f\"‚úÖ Saved: {file_name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to save image: {file_name}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: int, metrics: List[float], elapsed_time: float) -> None:\n",
        "        with open(self.metrics_csv, mode='a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> None:\n",
        "        model.eval()\n",
        "        metrics_score = np.zeros(5)\n",
        "        time_taken = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pid, (x, y) in enumerate(test_loader):\n",
        "                # if (pid >=2):\n",
        "                #   break\n",
        "                x = x.to(self.device, dtype=torch.float32)\n",
        "                y = y.to(self.device, dtype=torch.float32)\n",
        "\n",
        "                start_time = time.time()\n",
        "                y_pred = torch.sigmoid(model(x))\n",
        "                elapsed_time = time.time() - start_time\n",
        "                time_taken.append(elapsed_time)\n",
        "\n",
        "                batch_metrics = self.calculate_metrics(y, y_pred)\n",
        "                metrics_score += np.array(batch_metrics)\n",
        "\n",
        "                for idx in range(x.size(0)):\n",
        "                    sample_id = pid * x.size(0) + idx\n",
        "                    self.save_result(x[idx], y[idx], y_pred[idx], sample_id)\n",
        "                    self.append_metrics_to_csv(sample_id, batch_metrics, elapsed_time)\n",
        "\n",
        "        num_batches = len(test_loader)\n",
        "        avg_metrics = metrics_score / num_batches\n",
        "\n",
        "        print(f\"\\nüß™ Total Batches in Test Set: {num_batches}\")\n",
        "        print(f\"üìä Jaccard: {avg_metrics[0]:.4f} | F1: {avg_metrics[1]:.4f} | Recall: {avg_metrics[2]:.4f} | \"\n",
        "              f\"Precision: {avg_metrics[3]:.4f} | Accuracy: {avg_metrics[4]:.4f}\")\n",
        "        print(f\"‚ö° FPS: {1 / np.mean(time_taken):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"‚è≥ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
        "            self.counter = 0\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, epoch, optimizer):\n",
        "        if self.verbose:\n",
        "            print(f\"‚úÖ Valid loss improved. Saving model...\")\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self,\n",
        "                 model_file: str,\n",
        "                 loss_result_path: str,\n",
        "                 lr: float,\n",
        "                 num_epochs: int,\n",
        "                 device: torch.device):\n",
        "\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "\n",
        "        # For reproducibility\n",
        "        self.seeding(42)\n",
        "\n",
        "        print(f\"üîß Training initialized: lr={self.lr}, epochs={self.num_epochs}\")\n",
        "        print(f\"üìÅ Model will be saved to: {self.model_file}\")\n",
        "        print(f\"üìÅ Loss log will be saved to: {self.loss_result_path}\")\n",
        "        print(f\"üíª Device in use: {self.device} (CUDA available: {torch.cuda.is_available()})\")\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "    def train(self, model, loader, optimizer, loss_fn, device):\n",
        "        scaler = amp.GradScaler()\n",
        "        epoch_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            # if (batch_idx >=10):\n",
        "            #       break\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast(device_type=self.device.type):\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn, device):\n",
        "        epoch_loss = 0.0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (x, y) in enumerate(loader):\n",
        "                # if (batch_idx >=2):\n",
        "                #     break\n",
        "                x = x.to(device, dtype=torch.float32)\n",
        "                y = y.to(device, dtype=torch.float32)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = UNet(in_channels=1, out_channels=1, dropout=0.3).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = TverskyLoss(alpha=0.7, beta=0.3)\n",
        "\n",
        "        early_stopping = EarlyStopping(patience=10, min_delta=0.001, path=self.model_file)\n",
        "        results = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        for epoch in tqdm(range(1, self.num_epochs + 1), desc=\"üèãÔ∏è Training\"):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train(model, train_loader, optimizer, loss_fn, self.device)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn, self.device)\n",
        "            scheduler.step()\n",
        "\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "            results[\"train_loss\"].append(train_loss)\n",
        "            results[\"valid_loss\"].append(valid_loss)\n",
        "\n",
        "            print(f\"üìÖ Epoch {epoch:03d} | ‚è±Ô∏è {epoch_mins}m {epoch_secs}s | üî• Train: {train_loss:.4f} | üéØ Val: {valid_loss:.4f}\")\n",
        "\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"üõë Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Save train/val loss history to CSV\n",
        "        with open(self.loss_result_path, \"w\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\"] + list(range(1, len(results[\"train_loss\"]) + 1)))\n",
        "            writer.writerow([\"Train Loss\"] + results[\"train_loss\"])\n",
        "            writer.writerow([\"Valid Loss\"] + results[\"valid_loss\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwcTHPshqu0O",
        "outputId": "3b6d0420-dcd7-4587-c3b8-d6d01c103907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "üì¶ Loading datasets...\n",
            "üìÇ Loading cached indices from ./datasets/Datasets_OriginalCT_With_Empty_NonEmpty_slices_In_Train/tumor_indices.pkl\n",
            "‚úÖ Loaded: 5858 tumor, 35476 non-tumor\n",
            "‚úÖ Dataset sizes ‚Äî Train: 41334, Valid: 5141, Test: 4653\n",
            "üîß Training initialized: lr=1e-05, epochs=100\n",
            "üìÅ Model will be saved to: ./results/Results_OriginalCT_Fifty_Fifty_TverskyLoss_And_Strong_Augmentation/model.pth\n",
            "üìÅ Loss log will be saved to: ./results/Results_OriginalCT_Fifty_Fifty_TverskyLoss_And_Strong_Augmentation/train_and_valid_loss_results.csv\n",
            "üíª Device in use: cuda (CUDA available: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 001 | ‚è±Ô∏è 34m 17s | üî• Train: 0.9908 | üéØ Val: 0.9970\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:   2%|‚ñè         | 2/100 [1:04:50<52:22:58, 1924.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 002 | ‚è±Ô∏è 30m 25s | üî• Train: 0.9884 | üéØ Val: 0.9967\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   3%|‚ñé         | 3/100 [1:35:12<50:34:47, 1877.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 003 | ‚è±Ô∏è 30m 21s | üî• Train: 0.9872 | üéØ Val: 0.9962\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "üìÖ Epoch 004 | ‚è±Ô∏è 30m 21s | üî• Train: 0.9859 | üéØ Val: 0.9956\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:   5%|‚ñå         | 5/100 [2:36:02<48:42:04, 1845.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 005 | ‚è±Ô∏è 30m 27s | üî• Train: 0.9847 | üéØ Val: 0.9952\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   6%|‚ñå         | 6/100 [3:06:23<47:58:13, 1837.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 006 | ‚è±Ô∏è 30m 20s | üî• Train: 0.9838 | üéØ Val: 0.9952\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   7%|‚ñã         | 7/100 [3:36:46<47:20:39, 1832.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 007 | ‚è±Ô∏è 30m 23s | üî• Train: 0.9830 | üéØ Val: 0.9948\n",
            "‚è≥ EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   8%|‚ñä         | 8/100 [4:07:09<46:45:22, 1829.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 008 | ‚è±Ô∏è 30m 22s | üî• Train: 0.9825 | üéØ Val: 0.9947\n",
            "‚è≥ EarlyStopping counter: 4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:   9%|‚ñâ         | 9/100 [4:37:31<46:11:26, 1827.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 009 | ‚è±Ô∏è 30m 22s | üî• Train: 0.9821 | üéØ Val: 0.9947\n",
            "‚è≥ EarlyStopping counter: 5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  10%|‚ñà         | 10/100 [5:07:55<45:39:18, 1826.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 010 | ‚è±Ô∏è 30m 23s | üî• Train: 0.9820 | üéØ Val: 0.9946\n",
            "‚è≥ EarlyStopping counter: 6 out of 10\n",
            "üìÖ Epoch 011 | ‚è±Ô∏è 30m 23s | üî• Train: 0.9814 | üéØ Val: 0.9941\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  11%|‚ñà         | 11/100 [5:38:19<45:07:59, 1825.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 012 | ‚è±Ô∏è 30m 30s | üî• Train: 0.9793 | üéØ Val: 0.9931\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  13%|‚ñà‚ñé        | 13/100 [6:39:21<44:11:02, 1828.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 013 | ‚è±Ô∏è 30m 30s | üî• Train: 0.9767 | üéØ Val: 0.9927\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 014 | ‚è±Ô∏è 30m 23s | üî• Train: 0.9737 | üéØ Val: 0.9919\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  15%|‚ñà‚ñå        | 15/100 [7:40:16<43:09:44, 1828.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 015 | ‚è±Ô∏è 30m 29s | üî• Train: 0.9705 | üéØ Val: 0.9915\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 016 | ‚è±Ô∏è 30m 24s | üî• Train: 0.9667 | üéØ Val: 0.9895\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  17%|‚ñà‚ñã        | 17/100 [8:41:14<42:09:50, 1828.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 017 | ‚è±Ô∏è 30m 32s | üî• Train: 0.9625 | üéØ Val: 0.9887\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 018 | ‚è±Ô∏è 30m 25s | üî• Train: 0.9583 | üéØ Val: 0.9869\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  19%|‚ñà‚ñâ        | 19/100 [9:42:14<41:10:16, 1829.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 019 | ‚è±Ô∏è 30m 33s | üî• Train: 0.9536 | üéØ Val: 0.9860\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 020 | ‚è±Ô∏è 30m 26s | üî• Train: 0.9492 | üéØ Val: 0.9848\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  20%|‚ñà‚ñà        | 20/100 [10:12:41<40:38:36, 1828.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 021 | ‚è±Ô∏è 30m 33s | üî• Train: 0.9447 | üéØ Val: 0.9835\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  21%|‚ñà‚ñà        | 21/100 [10:43:16<40:10:22, 1830.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 022 | ‚è±Ô∏è 30m 33s | üî• Train: 0.9405 | üéØ Val: 0.9821\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  23%|‚ñà‚ñà‚ñé       | 23/100 [11:44:25<39:11:58, 1832.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 023 | ‚è±Ô∏è 30m 34s | üî• Train: 0.9368 | üéØ Val: 0.9818\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 024 | ‚è±Ô∏è 30m 26s | üî• Train: 0.9338 | üéØ Val: 0.9807\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  25%|‚ñà‚ñà‚ñå       | 25/100 [12:45:27<38:10:17, 1832.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 025 | ‚è±Ô∏è 30m 34s | üî• Train: 0.9308 | üéØ Val: 0.9805\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 026 | ‚è±Ô∏è 30m 29s | üî• Train: 0.9289 | üéØ Val: 0.9796\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  27%|‚ñà‚ñà‚ñã       | 27/100 [13:46:31<37:09:05, 1832.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 027 | ‚è±Ô∏è 30m 33s | üî• Train: 0.9275 | üéØ Val: 0.9796\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  28%|‚ñà‚ñà‚ñä       | 28/100 [14:17:00<36:37:21, 1831.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 028 | ‚è±Ô∏è 30m 28s | üî• Train: 0.9265 | üéØ Val: 0.9789\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  29%|‚ñà‚ñà‚ñâ       | 29/100 [14:47:28<36:05:50, 1830.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 029 | ‚è±Ô∏è 30m 28s | üî• Train: 0.9262 | üéØ Val: 0.9790\n",
            "‚è≥ EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  30%|‚ñà‚ñà‚ñà       | 30/100 [15:17:58<35:35:14, 1830.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 030 | ‚è±Ô∏è 30m 29s | üî• Train: 0.9259 | üéØ Val: 0.9792\n",
            "‚è≥ EarlyStopping counter: 4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  31%|‚ñà‚ñà‚ñà       | 31/100 [15:48:28<35:04:47, 1830.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 031 | ‚è±Ô∏è 30m 30s | üî• Train: 0.9247 | üéØ Val: 0.9786\n",
            "‚è≥ EarlyStopping counter: 5 out of 10\n",
            "üìÖ Epoch 032 | ‚è±Ô∏è 30m 28s | üî• Train: 0.9147 | üéØ Val: 0.9752\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [16:18:58<34:33:59, 1829.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 033 | ‚è±Ô∏è 30m 38s | üî• Train: 0.9037 | üéØ Val: 0.9702\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [17:20:14<33:37:19, 1833.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 034 | ‚è±Ô∏è 30m 36s | üî• Train: 0.8892 | üéØ Val: 0.9702\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 035 | ‚è±Ô∏è 30m 27s | üî• Train: 0.8724 | üéØ Val: 0.9628\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [17:50:42<33:04:49, 1832.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 036 | ‚è±Ô∏è 30m 24s | üî• Train: 0.8547 | üéØ Val: 0.9593\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [18:21:07<32:32:05, 1830.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 037 | ‚è±Ô∏è 30m 22s | üî• Train: 0.8352 | üéØ Val: 0.9540\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [18:51:31<31:59:34, 1828.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 038 | ‚è±Ô∏è 30m 19s | üî• Train: 0.8111 | üéØ Val: 0.9492\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [19:21:51<31:26:40, 1825.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 039 | ‚è±Ô∏è 30m 11s | üî• Train: 0.7888 | üéØ Val: 0.9467\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [19:52:04<30:52:14, 1821.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 040 | ‚è±Ô∏è 30m 18s | üî• Train: 0.7671 | üéØ Val: 0.9404\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [20:22:23<30:21:00, 1821.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 041 | ‚è±Ô∏è 30m 12s | üî• Train: 0.7392 | üéØ Val: 0.9380\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [20:52:36<29:48:32, 1818.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 042 | ‚è±Ô∏è 30m 17s | üî• Train: 0.7138 | üéØ Val: 0.9328\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [21:22:55<29:18:08, 1818.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 043 | ‚è±Ô∏è 30m 18s | üî• Train: 0.6894 | üéØ Val: 0.9266\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [21:53:15<28:48:08, 1819.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 044 | ‚è±Ô∏è 30m 5s | üî• Train: 0.6644 | üéØ Val: 0.9218\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [22:23:22<28:14:22, 1815.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 045 | ‚è±Ô∏è 30m 4s | üî• Train: 0.6418 | üéØ Val: 0.9174\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üèãÔ∏è Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [23:23:29<27:08:23, 1809.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Epoch 046 | ‚è±Ô∏è 30m 2s | üî• Train: 0.6221 | üéØ Val: 0.9175\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "üìÖ Epoch 047 | ‚è±Ô∏è 29m 56s | üî• Train: 0.5964 | üéØ Val: 0.9152\n",
            "‚úÖ Valid loss improved. Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüèãÔ∏è Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [23:53:26<26:34:56, 1805.60s/it]"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Set working directory\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    print(\"üìÅ Current Directory:\", os.getcwd())\n",
        "\n",
        "    # Training configuration\n",
        "    batch_size = 16\n",
        "    num_epochs = 100\n",
        "    lr = 1e-5\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transformation = \"OriginalCT_With_Empty_NonEmpty_slices_In_Train\"\n",
        "\n",
        "    # Define paths\n",
        "    output_dir = os.path.join(\".\",\"results\",f\"Results_OriginalCT_Fifty_Fifty_TverskyLoss_And_Strong_Augmentation\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    loss_result_file = os.path.join(output_dir, \"train_and_valid_loss_results.csv\")\n",
        "    model_file = os.path.join(output_dir, \"model.pth\")\n",
        "    test_metrics_file = os.path.join(output_dir, \"test_metrics.csv\")\n",
        "    test_result_path = os.path.join(output_dir, \"test_outputs\")\n",
        "    os.makedirs(test_result_path, exist_ok=True)\n",
        "\n",
        "    DATASET_DIR = f\"./datasets/Datasets_{transformation}\"\n",
        "    train_path = os.path.join(DATASET_DIR, \"train_dataset.hdf5\")\n",
        "    valid_path = os.path.join(DATASET_DIR, \"valid_dataset.hdf5\")\n",
        "    test_path = os.path.join(DATASET_DIR, \"test_dataset.hdf5\")\n",
        "\n",
        "    train_transform=StrongJointTransform()\n",
        "\n",
        "    print(\"üì¶ Loading datasets...\")\n",
        "    train_dataset = HDF5SegmentationDataset(train_path,transform=train_transform)\n",
        "    valid_dataset = HDF5SegmentationDataset(valid_path,transform=None)\n",
        "    test_dataset = HDF5SegmentationDataset(test_path,transform=None)\n",
        "\n",
        "    sampler = BalancedTumorSampler(train_dataset,\n",
        "                               tumor_ratio=0.5,\n",
        "                               shuffle=True,\n",
        "                               index_cache_path=f'{DATASET_DIR}/tumor_indices.pkl')\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,num_workers=0, pin_memory=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    print(f\"‚úÖ Dataset sizes ‚Äî Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize and run training\n",
        "    trainer = UnetTrain(\n",
        "        model_file=model_file,\n",
        "        loss_result_path=loss_result_file,\n",
        "        lr=lr,\n",
        "        num_epochs=num_epochs,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    trainer.execute(train_loader, valid_loader)\n",
        "\n",
        "    # Load best model for testing\n",
        "    model = UNet(in_channels=1, out_channels=1).to(device)\n",
        "    checkpoint = torch.load(model_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Test and save metrics\n",
        "    tester = UnetTest(test_result_path,test_metrics_file,device)\n",
        "    tester.test(model, test_loader)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')  # Required for some multiprocessing backends\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df.transpose()  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_OriginalCT_With_Balanced_Empty_NonEmpty_slices_In_Train_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyM9aPz/82b5NuB6+k00uT5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}