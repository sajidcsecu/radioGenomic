{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3dunetingpu__nifti_monai6_1_3_balanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. This is the improved of Model 5\n",
        "1. the architecture is 3DUNet\n",
        "2. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the\n",
        "3. strong augmentation is used in the code...\n",
        "4. Dice Loss is 1 and Binary classification Entropy is 1\n",
        "5. Number of positive pixels is for all patients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c0d4c1-fc01-4db3-a878-acf87c23c67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (1.26.4)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import AsDiscrete\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    ResizeWithPadOrCropd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandFlipd,\n",
        "    RandAffined,\n",
        "    RandGaussianNoised,\n",
        "    RandScaleIntensityd,\n",
        "    ToTensord,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstD,\n",
        "    SpatialPadd,\n",
        "    Rand3DElasticd,\n",
        "    NormalizeIntensityd,\n",
        "    RandGaussianSmoothd,\n",
        "    RandAdjustContrastd,\n",
        "    AsDiscreted,\n",
        "    Lambdad,\n",
        "    CenterSpatialCropd\n",
        "\n",
        ")\n",
        "from monai.transforms import MapTransform\n",
        "from monai.utils import ensure_tuple_rep\n",
        "import json\n",
        "from monai.data import CacheDataset\n",
        "from monai.transforms import Transform\n",
        "from monai.data import CacheDataset\n",
        "import torch.nn.functional as F\n",
        "from monai.data import Dataset, DataLoader, CacheDataset, pad_list_data_collate\n",
        "from monai.networks.layers import Norm\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from monai.transforms import EnsureTyped\n",
        "from monai.transforms import SaveImaged\n",
        "from monai.utils import set_determinism\n",
        "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Num foregrounds 0, Num backgrounds.*unable to generate class balanced samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "7fb6262e-7ee2-41d2-cdca-6a1a79bebf01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Safe Unet"
      ],
      "metadata": {
        "id": "Z0WDdyUd12ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SafeUNet(torch.nn.Module):\n",
        "    def __init__(self, base_unet):\n",
        "        super().__init__()\n",
        "        self.unet = base_unet\n",
        "\n",
        "    def forward(self, x):\n",
        "        try:\n",
        "            # Try normal forward pass\n",
        "            return self.unet(x)\n",
        "        except RuntimeError as e:\n",
        "            if \"Sizes of tensors must match\" in str(e):\n",
        "                print(f\"‚ö†Ô∏è Size mismatch detected! Input: {x.shape}\")\n",
        "                print(\"üîÑ Attempting automatic resize...\")\n",
        "\n",
        "                # Emergency resize to compatible size\n",
        "                compatible_size = self.find_compatible_size(x.shape[2:])\n",
        "                x_resized = F.interpolate(\n",
        "                    x,\n",
        "                    size=compatible_size,\n",
        "                    mode='trilinear',\n",
        "                    align_corners=False\n",
        "                )\n",
        "\n",
        "                # Forward pass with resized input\n",
        "                output = self.unet(x_resized)\n",
        "\n",
        "                # Resize output back to original size\n",
        "                output = F.interpolate(\n",
        "                    output,\n",
        "                    size=x.shape[2:],\n",
        "                    mode='trilinear',\n",
        "                    align_corners=False\n",
        "                )\n",
        "                print(f\"‚úÖ Resize successful: {x.shape[2:]} ‚Üí {compatible_size} ‚Üí {x.shape[2:]}\")\n",
        "                return output\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    def find_compatible_size(self, original_size):\n",
        "        \"\"\"Find a size compatible with UNet architecture (divisible by 16)\"\"\"\n",
        "        # UNet needs sizes divisible by 2^num_downsampling (16 for 4 downsamples)\n",
        "        compatible_size = tuple((s // 16) * 16 for s in original_size)\n",
        "\n",
        "        # Ensure minimum size\n",
        "        compatible_size = tuple(max(16, s) for s in compatible_size)\n",
        "\n",
        "        print(f\"üéØ Original: {original_size}, Compatible: {compatible_size}\")\n",
        "        return compatible_size"
      ],
      "metadata": {
        "id": "cGu3zWdW3jje"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class ImprovedDiceFocalLoss(nn.Module):\n",
        "    # Definition stub for runnable code (replace with your actual definition)\n",
        "    def __init__(self, smooth=1e-6, dice_weight=0.7, focal_weight=0.3, gamma=2.0, alpha=0.25, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.dice_weight = dice_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "\n",
        "        # Dice Loss\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth\n",
        "        )\n",
        "\n",
        "        # Focal Loss with pos_weight\n",
        "        # NOTE: F.binary_cross_entropy_with_logits handles pos_weight internally\n",
        "        if self.pos_weight is not None:\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(\n",
        "                preds, targets,\n",
        "                reduction='none',\n",
        "                pos_weight=self.pos_weight\n",
        "            )\n",
        "        else:\n",
        "            bce_loss = F.binary_cross_entropy_with_logits(preds, targets, reduction='none')\n",
        "\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
        "\n",
        "        return self.dice_weight * dice_loss + self.focal_weight * focal_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        # Remove super().__init__() since there's no parent class\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "        self.hd95_metric = HausdorffDistanceMetric(include_background=False, percentile=95, reduction=\"mean\")\n",
        "        self.asd_metric = SurfaceDistanceMetric(include_background=False, reduction=\"mean\")\n",
        "\n",
        "        # Create test output directory\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        # Update CSV headers to include new metrics\n",
        "        self._init_enhanced_metrics_csv()\n",
        "\n",
        "    def _init_enhanced_metrics_csv(self):\n",
        "        \"\"\"Initialize CSV with additional metric columns\"\"\"\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\n",
        "                    \"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\",\n",
        "                    \"Dice\", \"HD95\", \"ASD\", \"Time\"\n",
        "                ])\n",
        "\n",
        "    def calculate_basic_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate basic segmentation metrics (replacement for missing parent class)\"\"\"\n",
        "        # If you had a parent class with calculate_metrics, implement it here\n",
        "        eps = 1e-8\n",
        "\n",
        "        tp = np.sum(y_true * y_pred)\n",
        "        fp = np.sum((1 - y_true) * y_pred)\n",
        "        fn = np.sum(y_true * (1 - y_pred))\n",
        "        tn = np.sum((1 - y_true) * (1 - y_pred))\n",
        "\n",
        "        jaccard = tp / (tp + fp + fn + eps)\n",
        "        f1 = 2 * tp / (2 * tp + fp + fn + eps)\n",
        "        recall = tp / (tp + fn + eps)\n",
        "        precision = tp / (tp + fp + eps)\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn + eps)\n",
        "\n",
        "        return [jaccard, f1, recall, precision, accuracy]\n",
        "\n",
        "    def calculate_comprehensive_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        \"\"\"Calculate both basic and medical image metrics\"\"\"\n",
        "        # Use the new basic metrics method\n",
        "        basic_metrics = self.calculate_basic_metrics(y_true, y_pred)\n",
        "\n",
        "        # Convert to torch tensors for MONAI metrics\n",
        "        y_true_t = torch.from_numpy(y_true.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "        y_pred_t = torch.from_numpy(y_pred.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Calculate MONAI metrics\n",
        "        dice_value = self.dice_metric(y_pred_t, y_true_t)\n",
        "        hd95_value = self.hd95_metric(y_pred_t, y_true_t)\n",
        "        asd_value = self.asd_metric(y_pred_t, y_true_t)\n",
        "\n",
        "        # Reset metrics for next calculation\n",
        "        self.dice_metric.reset()\n",
        "        self.hd95_metric.reset()\n",
        "        self.asd_metric.reset()\n",
        "\n",
        "        return basic_metrics + [\n",
        "            dice_value.item() if not dice_value.isnan() else 0.0,\n",
        "            hd95_value.item() if not hd95_value.isnan() else 0.0,\n",
        "            asd_value.item() if not asd_value.isnan() else 0.0\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image_np: np.ndarray, pred_np: np.ndarray, label_np: np.ndarray, sample_id: str):\n",
        "        \"\"\"Save sample slices for visualization\"\"\"\n",
        "        try:\n",
        "            # Find slices with predictions for better visualization\n",
        "            pred_slices = np.where(np.any(pred_np, axis=(0, 1)))[0]\n",
        "            label_slices = np.where(np.any(label_np, axis=(0, 1)))[0]\n",
        "\n",
        "            # Combine and get unique slices of interest\n",
        "            slices_of_interest = np.unique(np.concatenate([pred_slices, label_slices]))\n",
        "\n",
        "            # If no positive slices, use center slices\n",
        "            if len(slices_of_interest) == 0:\n",
        "                slices_of_interest = [pred_np.shape[2] // 2 - 1, pred_np.shape[2] // 2, pred_np.shape[2] // 2 + 1]\n",
        "\n",
        "            # Save a few representative slices\n",
        "            for i, slice_idx in enumerate(slices_of_interest[:3]):  # Save max 3 slices\n",
        "                if 0 <= slice_idx < pred_np.shape[2]:\n",
        "                    # Create a simple visualization\n",
        "                    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "                    axes[0].imshow(image_np[:, :, slice_idx], cmap='gray')\n",
        "                    axes[0].set_title(f'Image - Slice {slice_idx}')\n",
        "                    axes[0].axis('off')\n",
        "\n",
        "                    axes[1].imshow(label_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[1].set_title('Ground Truth')\n",
        "                    axes[1].axis('off')\n",
        "\n",
        "                    axes[2].imshow(pred_np[:, :, slice_idx], cmap='jet', alpha=0.7)\n",
        "                    axes[2].set_title('Prediction')\n",
        "                    axes[2].axis('off')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    save_path = os.path.join(self.test_result_path, f\"{sample_id}_slice_{slice_idx}.png\")\n",
        "                    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not save slices for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        \"\"\"Override to handle extended metrics\"\"\"\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            # Now metrics should have: [jaccard, f1, recall, precision, accuracy, dice, hd95, asd]\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(8)  # Now 8 metrics total\n",
        "        total_times = []\n",
        "\n",
        "        # Count samples with actual predictions\n",
        "        samples_with_predictions = 0\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                # Skip if no predictions AND no ground truth (empty case)\n",
        "                if pred_np.sum() == 0 and label_np.sum() == 0:\n",
        "                    print(f\"üìù Sample {batch_idx}: No predictions and no ground truth - skipping\")\n",
        "                    continue\n",
        "\n",
        "                # Enhanced metrics calculation\n",
        "                metrics = self.calculate_comprehensive_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "                samples_with_predictions += 1\n",
        "\n",
        "                sample_id = f\"sample_{batch_idx:03d}\"\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "                # Print sample-level results\n",
        "                print(f\"üìä Sample {batch_idx}: Dice={metrics[5]:.4f}, HD95={metrics[6]:.2f}mm, Time={elapsed:.2f}s\")\n",
        "\n",
        "        # Print enhanced summary (only for samples with meaningful data)\n",
        "        if samples_with_predictions > 0:\n",
        "            num_samples = samples_with_predictions\n",
        "            metric_names = [\"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Dice\", \"HD95\", \"ASD\"]\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üìä ENHANCED TEST METRICS SUMMARY:\")\n",
        "            print(\"=\"*60)\n",
        "            for i, name in enumerate(metric_names):\n",
        "                print(f\"{name:<12}: {total_metrics[i]/num_samples:.4f}\")\n",
        "            print(f\"üìà Samples evaluated: {num_samples}/{len(test_loader)}\")\n",
        "            print(f\"‚ö° Average FPS: {1 / np.mean(total_times):.2f}\")\n",
        "            print(f\"‚è±Ô∏è  Average time per sample: {np.mean(total_times):.2f}s\")\n",
        "        else:\n",
        "            print(\"‚ùå No samples with meaningful predictions to evaluate!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) Early Stopping"
      ],
      "metadata": {
        "id": "3JLRqnw5L7xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"‚úÖ Validation loss improved ({self.val_loss_min:.6f}). Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"‚è≥ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # Always save a full checkpoint\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter,\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "        if self.verbose:\n",
        "            print(f\"üíæ Checkpoint saved.\")"
      ],
      "metadata": {
        "id": "LA4lGL-xL6st"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (7). Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------- Trainer ----------\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        # Initialize pos_weight_file: This is the dedicated JSON path.\n",
        "        self.pos_weight_file = model_file.replace('.pth', '_pos_weight.json')\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, accumulation_steps, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        # Uses mixed-precision training (amp) for efficiency\n",
        "        scaler = torch.amp.GradScaler()\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        positive_patches = 0\n",
        "        total_patches = 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # FIX: Calculate the total number of iterations (patches) for accurate reporting\n",
        "        # Assuming loader yields 8 patches per original volume (num_samples=8)\n",
        "        total_iterations = len(loader) * 8\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            # 1. Load data to device\n",
        "            inputs, labels = batch[\"vol\"].to(self.device, non_blocking=True), batch[\"seg\"].to(self.device, non_blocking=True)\n",
        "\n",
        "            # 2. Monitor patch quality (checking if the current batch contains a positive lesion)\n",
        "            batch_positives = labels.sum().item()\n",
        "            if batch_positives > 0:\n",
        "                positive_patches += 1\n",
        "            total_patches += 1 # Total number of batches processed\n",
        "\n",
        "            # 3. Forward Pass and Loss Calculation (using automatic mixed precision)\n",
        "            with torch.amp.autocast(device_type=device_type, enabled=True):\n",
        "                outputs = model(inputs)\n",
        "                # Loss is scaled down by accumulation_steps for averaging\n",
        "                loss = loss_fn(outputs, labels) / accumulation_steps\n",
        "\n",
        "            # 4. Backward Pass (Gradient calculation)\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # 5. Gradient Accumulation Check (Updates weights only every N steps)\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                scaler.step(optimizer) # Apply accumulated gradients\n",
        "                scaler.update()        # Update the scaler for mixed precision\n",
        "                optimizer.zero_grad()  # Clear gradients for the next cycle\n",
        "\n",
        "            # 6. Accumulate loss for reporting (rescale loss back up)\n",
        "            epoch_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            # 7. Progress reporting (using the corrected total_iterations)\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"  Batch {i+1}/{total_iterations}, Loss: {loss.item() * accumulation_steps:.4f}\")\n",
        "\n",
        "        # Final print statement for Patch Quality\n",
        "        print(f\"  Patch Quality: {positive_patches}/{total_patches} ({positive_patches/total_patches*100:.1f}%) with positives\")\n",
        "\n",
        "        # Return the final averaged loss over the true number of iterations\n",
        "        return epoch_loss / total_iterations\n",
        "\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                inputs, labels = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def save_pos_weight(self, pos_weight):\n",
        "        \"\"\"Save pos_weight to JSON file\"\"\"\n",
        "        with open(self.pos_weight_file, 'w') as f:\n",
        "            json.dump({'pos_weight': pos_weight, 'timestamp': time.time()}, f)\n",
        "        print(f\"üíæ Saved pos_weight: {pos_weight:.4f}\")\n",
        "\n",
        "    def load_pos_weight(self):\n",
        "        \"\"\"Load pos_weight from JSON file\"\"\"\n",
        "        # Condition 1 & 2: Check if file exists and read it\n",
        "        if os.path.exists(self.pos_weight_file):\n",
        "            try:\n",
        "                with open(self.pos_weight_file, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    pos_weight = data['pos_weight']\n",
        "                    print(f\"üìÇ Loaded pos_weight: {pos_weight:.4f}\")\n",
        "                    return pos_weight\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading pos_weight: {e}\")\n",
        "        return None\n",
        "\n",
        "    def get_pos_weight(self, train_loader, force_recompute=False):\n",
        "        \"\"\"Get pos_weight - load if exists, otherwise compute and save\"\"\"\n",
        "        if not force_recompute:\n",
        "            pos_weight = self.load_pos_weight()\n",
        "            if pos_weight is not None:\n",
        "                return pos_weight\n",
        "\n",
        "        # Condition 3: Compute new pos_weight and save it\n",
        "        pos_weight = self.compute_pos_weight(train_loader, max_batches=None)\n",
        "        self.save_pos_weight(pos_weight)\n",
        "        return pos_weight\n",
        "\n",
        "    def compute_pos_weight(self, train_loader, max_batches=None):\n",
        "        \"\"\"Compute pos_weight with better diagnostics\"\"\"\n",
        "        pos, neg = 0, 0\n",
        "        total_samples = 0\n",
        "        total_batch_pos = 0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            seg = batch[\"seg\"].to(self.device)\n",
        "            batch_pos = seg.sum().item()\n",
        "            batch_neg = seg.numel() - batch_pos\n",
        "\n",
        "            pos += batch_pos\n",
        "            neg += batch_neg\n",
        "            total_samples += 1\n",
        "\n",
        "            print(f\"Batch {i}: pos={batch_pos}, neg={batch_neg}, pos_ratio={batch_pos/seg.numel():.6f}\")\n",
        "\n",
        "            if(batch_pos > 0):\n",
        "                total_batch_pos += 1\n",
        "\n",
        "            if max_batches and (i + 1) >= max_batches:\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "        pos_ratio = pos / (pos + neg) if (pos + neg) > 0 else 0\n",
        "        pos_weight = neg / (pos + 1e-8)\n",
        "\n",
        "        print(f\"üìä Final Stats:\")\n",
        "        print(f\"  Total pos voxels: {pos}\")\n",
        "        print(f\"  Total neg voxels: {neg}\")\n",
        "        print(f\"  Positive ratio: {pos_ratio:.6f} ({pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Computed pos_weight: {pos_weight:.4f}\")\n",
        "        print(f\"  Total batches with positives: {total_batch_pos}\")\n",
        "        return pos_weight\n",
        "\n",
        "    def execute(self, model, train_loader, valid_loader):\n",
        "        # ... (Optimizer and Scheduler remain unchanged)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=10,\n",
        "            min_lr=1e-6,\n",
        "            threshold=0.0001\n",
        "        )\n",
        "\n",
        "        # üîπ LINK: Auto-compute/load pos_weight before training (Handles all 3 file conditions)\n",
        "        pos_weight = self.get_pos_weight(train_loader)\n",
        "        # Cap pos_weight to reasonable value\n",
        "        reasonable_pos_weight = min(pos_weight, 100.0)\n",
        "        print(f\"üìä Using reasonable pos_weight: {reasonable_pos_weight:.2f} (capped from {pos_weight:.2f})\")\n",
        "\n",
        "        # ‚úÖ Initialize loss function using the final fixed weight\n",
        "        loss_fn = ImprovedDiceFocalLoss(\n",
        "            dice_weight=0.9,\n",
        "            focal_weight=0.1,\n",
        "            gamma=2.0,\n",
        "            alpha=0.5,\n",
        "            pos_weight=torch.tensor([reasonable_pos_weight], device=self.device)\n",
        "        )\n",
        "\n",
        "        accumulation_steps = 4\n",
        "\n",
        "        # ---- Resume training state ----\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "            # NOTE: Removed all checkpoint pos_weight loading logic, relying on self.get_pos_weight() above.\n",
        "\n",
        "        # üéØ Initialize EarlyStopping (pos_weight parameter is no longer required)\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=20,\n",
        "            min_delta=0.0002,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter,\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # ---- Training loop ----\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(\n",
        "                model, train_loader, optimizer, accumulation_steps, loss_fn\n",
        "            )\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step(metrics=valid_loss)\n",
        "            mins, secs = self.epoch_time(start_time, time.time())\n",
        "            print(f\"Epoch {epoch:03d} | Time: {mins}m {secs}s | \"\n",
        "                  f\"Train: {train_loss:.6f} | Val: {valid_loss:.6f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            # üéØ Call EarlyStopping without pos_weight argument\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"üõë Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinarizeSegd(MapTransform):\n",
        "    \"\"\"\n",
        "    Custom MapTransform to explicitly binarize the segmentation label map.\n",
        "    This replaces the unpicklable lambda function and the unavailable Thresholdd.\n",
        "    \"\"\"\n",
        "    def __init__(self, keys, threshold=0.5, allow_missing_keys: bool = False):\n",
        "        super().__init__(keys, allow_missing_keys)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            # Ensure the segmentation tensor is float before comparison\n",
        "            seg_tensor = d[key].to(torch.float32)\n",
        "\n",
        "            # Binarize: x > threshold results in a boolean tensor (True/False)\n",
        "            # .float() converts True to 1.0 and False to 0.0\n",
        "            d[key] = (seg_tensor > self.threshold).float()\n",
        "\n",
        "            # Crucial: Ensure the resulting segmentation is still 0 or 1 integers\n",
        "            # if subsequent transforms or the UNet expect integer types for labels.\n",
        "            # However, for loss calculation (BCELogits/Dice), float is usually fine.\n",
        "            # Let's keep it float for compatibility with the UNet output and loss calculation,\n",
        "            # but ensure the values are exactly 0.0 or 1.0.\n",
        "\n",
        "        return d"
      ],
      "metadata": {
        "id": "dXTWolptPylX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# GLOBAL HELPER FUNCTION (MUST be defined outside the UnetPipeline class)\n",
        "# ----------------------------------------------------------------------\n",
        "def binarize_segmentation_logic(data):\n",
        "    \"\"\"Binarizes the input tensor/array using a 0.5 threshold (Picklable).\"\"\"\n",
        "    # This is the logic, and it MUST remain outside the class method.\n",
        "    return (data > 0.5).float()"
      ],
      "metadata": {
        "id": "NjiK8pPtAMVw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (8). Pipeline"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CwcTHPshqu0O",
        "outputId": "803926be-3e5b-40c7-92c6-ff4713b8df6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Current Directory: /content/drive/MyDrive/PhDwork/Segmentation\n",
            "üì¶ Preparing datasets and transforms...\n",
            "üîÑ Loading training dataset...\n",
            "üìä Filtered 340 -> 340 non-empty samples\n",
            "üìÅ train: Loaded 340 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [03:51<00:00,  6.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading validation dataset...\n",
            "üìÅ valid: Loaded 43 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:07<00:00,  8.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading test dataset...\n",
            "üìÅ test: Loaded 38 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:52<00:00,  7.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Filtered 340 -> 340 non-empty samples\n",
            "üìÅ train: Loaded 340 samples\n",
            "‚úÖ Dataset sizes ‚Äî Train: 340, Valid: 43, Test: 38\n",
            "üöÄ Starting pipeline with:\n",
            "   - Train samples: 340\n",
            "   - Valid samples: 43\n",
            "   - Test samples: 38\n",
            "   - Device: cuda\n",
            "   - Output directory: ./results/Results_Nifti_MONAI6_1_3Original\n",
            "‚ö†Ô∏è DynamicUNet not available or import failed. Using SafeUNet wrapper.\n",
            "üéØ GPU Memory allocated: 0.07 GB\n",
            "üéØ GPU Memory cached: 0.08 GB\n",
            "Batch 0: pos=97992.0, neg=1073643832.0, pos_ratio=0.000091\n",
            "Batch 1: pos=206760.0, neg=1073535064.0, pos_ratio=0.000193\n",
            "Batch 2: pos=145848.0, neg=1073595976.0, pos_ratio=0.000136\n",
            "Batch 3: pos=29880.0, neg=1073711944.0, pos_ratio=0.000028\n",
            "Batch 4: pos=40968.0, neg=1073700856.0, pos_ratio=0.000038\n",
            "Batch 5: pos=265080.0, neg=1073476744.0, pos_ratio=0.000247\n",
            "Batch 6: pos=1733768.0, neg=1072008056.0, pos_ratio=0.001615\n",
            "Batch 7: pos=91992.0, neg=1073649832.0, pos_ratio=0.000086\n",
            "Batch 8: pos=1619512.0, neg=1072122312.0, pos_ratio=0.001508\n",
            "Batch 9: pos=20664.0, neg=1073721160.0, pos_ratio=0.000019\n",
            "Batch 10: pos=39120.0, neg=1073702704.0, pos_ratio=0.000036\n",
            "Batch 11: pos=260632.0, neg=1073481192.0, pos_ratio=0.000243\n",
            "Batch 12: pos=1008048.0, neg=1072733776.0, pos_ratio=0.000939\n",
            "Batch 13: pos=103736.0, neg=1073638088.0, pos_ratio=0.000097\n",
            "Batch 14: pos=170976.0, neg=1073570848.0, pos_ratio=0.000159\n",
            "Batch 15: pos=38808.0, neg=1073703016.0, pos_ratio=0.000036\n",
            "Batch 16: pos=613464.0, neg=1073128360.0, pos_ratio=0.000571\n",
            "Batch 17: pos=307416.0, neg=1073434408.0, pos_ratio=0.000286\n",
            "Batch 18: pos=71904.0, neg=1073669920.0, pos_ratio=0.000067\n",
            "Batch 19: pos=870088.0, neg=1072871736.0, pos_ratio=0.000810\n",
            "Batch 20: pos=326040.0, neg=1073415784.0, pos_ratio=0.000304\n",
            "Batch 21: pos=1400.0, neg=1073740424.0, pos_ratio=0.000001\n",
            "Batch 22: pos=93352.0, neg=1073648472.0, pos_ratio=0.000087\n",
            "Batch 23: pos=1157064.0, neg=1072584760.0, pos_ratio=0.001078\n",
            "Batch 24: pos=421920.0, neg=1073319904.0, pos_ratio=0.000393\n",
            "Batch 25: pos=630600.0, neg=1073111224.0, pos_ratio=0.000587\n",
            "Batch 26: pos=7920.0, neg=1073733904.0, pos_ratio=0.000007\n",
            "Batch 27: pos=466120.0, neg=1073275704.0, pos_ratio=0.000434\n",
            "Batch 28: pos=776.0, neg=1073741048.0, pos_ratio=0.000001\n",
            "Batch 29: pos=4688.0, neg=1073737136.0, pos_ratio=0.000004\n",
            "Batch 30: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 31: pos=926272.0, neg=1072815552.0, pos_ratio=0.000863\n",
            "Batch 32: pos=640.0, neg=1073741184.0, pos_ratio=0.000001\n",
            "Batch 33: pos=227752.0, neg=1073514072.0, pos_ratio=0.000212\n",
            "Batch 34: pos=265472.0, neg=1073476352.0, pos_ratio=0.000247\n",
            "Batch 35: pos=1183032.0, neg=1072558792.0, pos_ratio=0.001102\n",
            "Batch 36: pos=168448.0, neg=1073573376.0, pos_ratio=0.000157\n",
            "Batch 37: pos=3904.0, neg=1073737920.0, pos_ratio=0.000004\n",
            "Batch 38: pos=717720.0, neg=1073024104.0, pos_ratio=0.000668\n",
            "Batch 39: pos=53088.0, neg=1073688736.0, pos_ratio=0.000049\n",
            "Batch 40: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 41: pos=80.0, neg=1073741744.0, pos_ratio=0.000000\n",
            "Batch 42: pos=249696.0, neg=1073492128.0, pos_ratio=0.000233\n",
            "Batch 43: pos=1906488.0, neg=1071835336.0, pos_ratio=0.001776\n",
            "Batch 44: pos=1781304.0, neg=1071960520.0, pos_ratio=0.001659\n",
            "Batch 45: pos=34672.0, neg=1073707152.0, pos_ratio=0.000032\n",
            "Batch 46: pos=428344.0, neg=1073313480.0, pos_ratio=0.000399\n",
            "Batch 47: pos=500160.0, neg=1073241664.0, pos_ratio=0.000466\n",
            "Batch 48: pos=519704.0, neg=1073222120.0, pos_ratio=0.000484\n",
            "Batch 49: pos=9888.0, neg=1073731936.0, pos_ratio=0.000009\n",
            "Batch 50: pos=210472.0, neg=1073531352.0, pos_ratio=0.000196\n",
            "Batch 51: pos=2873864.0, neg=1070867960.0, pos_ratio=0.002676\n",
            "Batch 52: pos=784528.0, neg=1072957296.0, pos_ratio=0.000731\n",
            "Batch 53: pos=16888.0, neg=1073724936.0, pos_ratio=0.000016\n",
            "Batch 54: pos=98272.0, neg=1073643552.0, pos_ratio=0.000092\n",
            "Batch 55: pos=48000.0, neg=1073693824.0, pos_ratio=0.000045\n",
            "Batch 56: pos=1321320.0, neg=1072420504.0, pos_ratio=0.001231\n",
            "Batch 57: pos=66984.0, neg=1073674840.0, pos_ratio=0.000062\n",
            "Batch 58: pos=135816.0, neg=1073606008.0, pos_ratio=0.000126\n",
            "Batch 59: pos=60048.0, neg=1073681776.0, pos_ratio=0.000056\n",
            "Batch 60: pos=39768.0, neg=1073702056.0, pos_ratio=0.000037\n",
            "Batch 61: pos=137400.0, neg=1073604424.0, pos_ratio=0.000128\n",
            "Batch 62: pos=8016.0, neg=1073733808.0, pos_ratio=0.000007\n",
            "Batch 63: pos=740400.0, neg=1073001424.0, pos_ratio=0.000690\n",
            "Batch 64: pos=4904.0, neg=1073736920.0, pos_ratio=0.000005\n",
            "Batch 65: pos=22280.0, neg=1073719544.0, pos_ratio=0.000021\n",
            "Batch 66: pos=49344.0, neg=1073692480.0, pos_ratio=0.000046\n",
            "Batch 67: pos=5496.0, neg=1073736328.0, pos_ratio=0.000005\n",
            "Batch 68: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 69: pos=53120.0, neg=1073688704.0, pos_ratio=0.000049\n",
            "Batch 70: pos=95088.0, neg=1073646736.0, pos_ratio=0.000089\n",
            "Batch 71: pos=953776.0, neg=1072788048.0, pos_ratio=0.000888\n",
            "Batch 72: pos=63848.0, neg=1073677976.0, pos_ratio=0.000059\n",
            "Batch 73: pos=77792.0, neg=1073664032.0, pos_ratio=0.000072\n",
            "Batch 74: pos=18032.0, neg=1073723792.0, pos_ratio=0.000017\n",
            "Batch 75: pos=83688.0, neg=1073658136.0, pos_ratio=0.000078\n",
            "Batch 76: pos=93528.0, neg=1073648296.0, pos_ratio=0.000087\n",
            "Batch 77: pos=383128.0, neg=1073358696.0, pos_ratio=0.000357\n",
            "Batch 78: pos=48664.0, neg=1073693160.0, pos_ratio=0.000045\n",
            "Batch 79: pos=286656.0, neg=1073455168.0, pos_ratio=0.000267\n",
            "Batch 80: pos=1842072.0, neg=1071899752.0, pos_ratio=0.001716\n",
            "Batch 81: pos=206280.0, neg=1073535544.0, pos_ratio=0.000192\n",
            "Batch 82: pos=400512.0, neg=1073341312.0, pos_ratio=0.000373\n",
            "Batch 83: pos=145392.0, neg=1073596432.0, pos_ratio=0.000135\n",
            "Batch 84: pos=11112.0, neg=1073730712.0, pos_ratio=0.000010\n",
            "Batch 85: pos=1245800.0, neg=1072496024.0, pos_ratio=0.001160\n",
            "Batch 86: pos=781296.0, neg=1072960528.0, pos_ratio=0.000728\n",
            "Batch 87: pos=969880.0, neg=1072771944.0, pos_ratio=0.000903\n",
            "Batch 88: pos=379944.0, neg=1073361880.0, pos_ratio=0.000354\n",
            "Batch 89: pos=458880.0, neg=1073282944.0, pos_ratio=0.000427\n",
            "Batch 90: pos=75208.0, neg=1073666616.0, pos_ratio=0.000070\n",
            "Batch 91: pos=1698616.0, neg=1072043208.0, pos_ratio=0.001582\n",
            "Batch 92: pos=657984.0, neg=1073083840.0, pos_ratio=0.000613\n",
            "Batch 93: pos=41616.0, neg=1073700208.0, pos_ratio=0.000039\n",
            "Batch 94: pos=1656592.0, neg=1072085232.0, pos_ratio=0.001543\n",
            "Batch 95: pos=28296.0, neg=1073713528.0, pos_ratio=0.000026\n",
            "Batch 96: pos=488392.0, neg=1073253432.0, pos_ratio=0.000455\n",
            "Batch 97: pos=1219776.0, neg=1072522048.0, pos_ratio=0.001136\n",
            "Batch 98: pos=71832.0, neg=1073669992.0, pos_ratio=0.000067\n",
            "Batch 99: pos=94520.0, neg=1073647304.0, pos_ratio=0.000088\n",
            "Batch 100: pos=243440.0, neg=1073498384.0, pos_ratio=0.000227\n",
            "Batch 101: pos=314392.0, neg=1073427432.0, pos_ratio=0.000293\n",
            "Batch 102: pos=166416.0, neg=1073575408.0, pos_ratio=0.000155\n",
            "Batch 103: pos=38736.0, neg=1073703088.0, pos_ratio=0.000036\n",
            "Batch 104: pos=902568.0, neg=1072839256.0, pos_ratio=0.000841\n",
            "Batch 105: pos=6240.0, neg=1073735584.0, pos_ratio=0.000006\n",
            "Batch 106: pos=45888.0, neg=1073695936.0, pos_ratio=0.000043\n",
            "Batch 107: pos=378920.0, neg=1073362904.0, pos_ratio=0.000353\n",
            "Batch 108: pos=950544.0, neg=1072791280.0, pos_ratio=0.000885\n",
            "Batch 109: pos=336856.0, neg=1073404968.0, pos_ratio=0.000314\n",
            "Batch 110: pos=415464.0, neg=1073326360.0, pos_ratio=0.000387\n",
            "Batch 111: pos=2435544.0, neg=1071306280.0, pos_ratio=0.002268\n",
            "Batch 112: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 113: pos=444264.0, neg=1073297560.0, pos_ratio=0.000414\n",
            "Batch 114: pos=1092792.0, neg=1072649032.0, pos_ratio=0.001018\n",
            "Batch 115: pos=192600.0, neg=1073549224.0, pos_ratio=0.000179\n",
            "Batch 116: pos=244968.0, neg=1073496856.0, pos_ratio=0.000228\n",
            "Batch 117: pos=11344.0, neg=1073730480.0, pos_ratio=0.000011\n",
            "Batch 118: pos=1461144.0, neg=1072280680.0, pos_ratio=0.001361\n",
            "Batch 119: pos=674784.0, neg=1073067040.0, pos_ratio=0.000628\n",
            "Batch 120: pos=410640.0, neg=1073331184.0, pos_ratio=0.000382\n",
            "Batch 121: pos=2030312.0, neg=1071711512.0, pos_ratio=0.001891\n",
            "Batch 122: pos=207240.0, neg=1073534584.0, pos_ratio=0.000193\n",
            "Batch 123: pos=480.0, neg=1073741344.0, pos_ratio=0.000000\n",
            "Batch 124: pos=2171968.0, neg=1071569856.0, pos_ratio=0.002023\n",
            "Batch 125: pos=287488.0, neg=1073454336.0, pos_ratio=0.000268\n",
            "Batch 126: pos=1152544.0, neg=1072589280.0, pos_ratio=0.001073\n",
            "Batch 127: pos=254088.0, neg=1073487736.0, pos_ratio=0.000237\n",
            "Batch 128: pos=2868120.0, neg=1070873704.0, pos_ratio=0.002671\n",
            "Batch 129: pos=12024.0, neg=1073729800.0, pos_ratio=0.000011\n",
            "Batch 130: pos=115264.0, neg=1073626560.0, pos_ratio=0.000107\n",
            "Batch 131: pos=189128.0, neg=1073552696.0, pos_ratio=0.000176\n",
            "Batch 132: pos=530872.0, neg=1073210952.0, pos_ratio=0.000494\n",
            "Batch 133: pos=85248.0, neg=1073656576.0, pos_ratio=0.000079\n",
            "Batch 134: pos=123168.0, neg=1073618656.0, pos_ratio=0.000115\n",
            "Batch 135: pos=1219072.0, neg=1072522752.0, pos_ratio=0.001135\n",
            "Batch 136: pos=1194816.0, neg=1072547008.0, pos_ratio=0.001113\n",
            "Batch 137: pos=534432.0, neg=1073207392.0, pos_ratio=0.000498\n",
            "Batch 138: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 139: pos=520920.0, neg=1073220904.0, pos_ratio=0.000485\n",
            "Batch 140: pos=617280.0, neg=1073124544.0, pos_ratio=0.000575\n",
            "Batch 141: pos=1382216.0, neg=1072359608.0, pos_ratio=0.001287\n",
            "Batch 142: pos=24624.0, neg=1073717200.0, pos_ratio=0.000023\n",
            "Batch 143: pos=2688680.0, neg=1071053144.0, pos_ratio=0.002504\n",
            "Batch 144: pos=4200.0, neg=1073737624.0, pos_ratio=0.000004\n",
            "Batch 145: pos=1205144.0, neg=1072536680.0, pos_ratio=0.001122\n",
            "Batch 146: pos=281688.0, neg=1073460136.0, pos_ratio=0.000262\n",
            "Batch 147: pos=5032.0, neg=1073736792.0, pos_ratio=0.000005\n",
            "Batch 148: pos=17880.0, neg=1073723944.0, pos_ratio=0.000017\n",
            "Batch 149: pos=16056.0, neg=1073725768.0, pos_ratio=0.000015\n",
            "Batch 150: pos=322344.0, neg=1073419480.0, pos_ratio=0.000300\n",
            "Batch 151: pos=247056.0, neg=1073494768.0, pos_ratio=0.000230\n",
            "Batch 152: pos=6648.0, neg=1073735176.0, pos_ratio=0.000006\n",
            "Batch 153: pos=331104.0, neg=1073410720.0, pos_ratio=0.000308\n",
            "Batch 154: pos=1507720.0, neg=1072234104.0, pos_ratio=0.001404\n",
            "Batch 155: pos=917584.0, neg=1072824240.0, pos_ratio=0.000855\n",
            "Batch 156: pos=52896.0, neg=1073688928.0, pos_ratio=0.000049\n",
            "Batch 157: pos=749472.0, neg=1072992352.0, pos_ratio=0.000698\n",
            "Batch 158: pos=147224.0, neg=1073594600.0, pos_ratio=0.000137\n",
            "Batch 159: pos=200928.0, neg=1073540896.0, pos_ratio=0.000187\n",
            "Batch 160: pos=1638120.0, neg=1072103704.0, pos_ratio=0.001526\n",
            "Batch 161: pos=478920.0, neg=1073262904.0, pos_ratio=0.000446\n",
            "Batch 162: pos=570792.0, neg=1073171032.0, pos_ratio=0.000532\n",
            "Batch 163: pos=298992.0, neg=1073442832.0, pos_ratio=0.000278\n",
            "Batch 164: pos=159056.0, neg=1073582768.0, pos_ratio=0.000148\n",
            "Batch 165: pos=749856.0, neg=1072991968.0, pos_ratio=0.000698\n",
            "Batch 166: pos=106392.0, neg=1073635432.0, pos_ratio=0.000099\n",
            "Batch 167: pos=619632.0, neg=1073122192.0, pos_ratio=0.000577\n",
            "Batch 168: pos=66600.0, neg=1073675224.0, pos_ratio=0.000062\n",
            "Batch 169: pos=109016.0, neg=1073632808.0, pos_ratio=0.000102\n",
            "Batch 170: pos=1569760.0, neg=1072172064.0, pos_ratio=0.001462\n",
            "Batch 171: pos=4112.0, neg=1073737712.0, pos_ratio=0.000004\n",
            "Batch 172: pos=27480.0, neg=1073714344.0, pos_ratio=0.000026\n",
            "Batch 173: pos=45144.0, neg=1073696680.0, pos_ratio=0.000042\n",
            "Batch 174: pos=9296.0, neg=1073732528.0, pos_ratio=0.000009\n",
            "Batch 175: pos=415224.0, neg=1073326600.0, pos_ratio=0.000387\n",
            "Batch 176: pos=142152.0, neg=1073599672.0, pos_ratio=0.000132\n",
            "Batch 177: pos=230664.0, neg=1073511160.0, pos_ratio=0.000215\n",
            "Batch 178: pos=144096.0, neg=1073597728.0, pos_ratio=0.000134\n",
            "Batch 179: pos=429648.0, neg=1073312176.0, pos_ratio=0.000400\n",
            "Batch 180: pos=548104.0, neg=1073193720.0, pos_ratio=0.000510\n",
            "Batch 181: pos=92568.0, neg=1073649256.0, pos_ratio=0.000086\n",
            "Batch 182: pos=176688.0, neg=1073565136.0, pos_ratio=0.000165\n",
            "Batch 183: pos=104808.0, neg=1073637016.0, pos_ratio=0.000098\n",
            "Batch 184: pos=92808.0, neg=1073649016.0, pos_ratio=0.000086\n",
            "Batch 185: pos=672624.0, neg=1073069200.0, pos_ratio=0.000626\n",
            "Batch 186: pos=4080.0, neg=1073737744.0, pos_ratio=0.000004\n",
            "Batch 187: pos=2130888.0, neg=1071610936.0, pos_ratio=0.001985\n",
            "Batch 188: pos=13800.0, neg=1073728024.0, pos_ratio=0.000013\n",
            "Batch 189: pos=586728.0, neg=1073155096.0, pos_ratio=0.000546\n",
            "Batch 190: pos=350784.0, neg=1073391040.0, pos_ratio=0.000327\n",
            "Batch 191: pos=341424.0, neg=1073400400.0, pos_ratio=0.000318\n",
            "Batch 192: pos=25032.0, neg=1073716792.0, pos_ratio=0.000023\n",
            "Batch 193: pos=84432.0, neg=1073657392.0, pos_ratio=0.000079\n",
            "Batch 194: pos=305256.0, neg=1073436568.0, pos_ratio=0.000284\n",
            "Batch 195: pos=255192.0, neg=1073486632.0, pos_ratio=0.000238\n",
            "Batch 196: pos=272136.0, neg=1073469688.0, pos_ratio=0.000253\n",
            "Batch 197: pos=3104.0, neg=1073738720.0, pos_ratio=0.000003\n",
            "Batch 198: pos=870864.0, neg=1072870960.0, pos_ratio=0.000811\n",
            "Batch 199: pos=66264.0, neg=1073675560.0, pos_ratio=0.000062\n",
            "Batch 200: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 201: pos=1107904.0, neg=1072633920.0, pos_ratio=0.001032\n",
            "Batch 202: pos=24312.0, neg=1073717512.0, pos_ratio=0.000023\n",
            "Batch 203: pos=27960.0, neg=1073713864.0, pos_ratio=0.000026\n",
            "Batch 204: pos=713856.0, neg=1073027968.0, pos_ratio=0.000665\n",
            "Batch 205: pos=19464.0, neg=1073722360.0, pos_ratio=0.000018\n",
            "Batch 206: pos=2328.0, neg=1073739496.0, pos_ratio=0.000002\n",
            "Batch 207: pos=471408.0, neg=1073270416.0, pos_ratio=0.000439\n",
            "Batch 208: pos=20624.0, neg=1073721200.0, pos_ratio=0.000019\n",
            "Batch 209: pos=191048.0, neg=1073550776.0, pos_ratio=0.000178\n",
            "Batch 210: pos=118272.0, neg=1073623552.0, pos_ratio=0.000110\n",
            "Batch 211: pos=697624.0, neg=1073044200.0, pos_ratio=0.000650\n",
            "Batch 212: pos=665808.0, neg=1073076016.0, pos_ratio=0.000620\n",
            "Batch 213: pos=123216.0, neg=1073618608.0, pos_ratio=0.000115\n",
            "Batch 214: pos=258272.0, neg=1073483552.0, pos_ratio=0.000241\n",
            "Batch 215: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 216: pos=62064.0, neg=1073679760.0, pos_ratio=0.000058\n",
            "Batch 217: pos=620184.0, neg=1073121640.0, pos_ratio=0.000578\n",
            "Batch 218: pos=11136.0, neg=1073730688.0, pos_ratio=0.000010\n",
            "Batch 219: pos=591904.0, neg=1073149920.0, pos_ratio=0.000551\n",
            "Batch 220: pos=699984.0, neg=1073041840.0, pos_ratio=0.000652\n",
            "Batch 221: pos=144648.0, neg=1073597176.0, pos_ratio=0.000135\n",
            "Batch 222: pos=409048.0, neg=1073332776.0, pos_ratio=0.000381\n",
            "Batch 223: pos=131496.0, neg=1073610328.0, pos_ratio=0.000122\n",
            "Batch 224: pos=82992.0, neg=1073658832.0, pos_ratio=0.000077\n",
            "Batch 225: pos=414552.0, neg=1073327272.0, pos_ratio=0.000386\n",
            "Batch 226: pos=436968.0, neg=1073304856.0, pos_ratio=0.000407\n",
            "Batch 227: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 228: pos=101168.0, neg=1073640656.0, pos_ratio=0.000094\n",
            "Batch 229: pos=664.0, neg=1073741160.0, pos_ratio=0.000001\n",
            "Batch 230: pos=30552.0, neg=1073711272.0, pos_ratio=0.000028\n",
            "Batch 231: pos=1414176.0, neg=1072327648.0, pos_ratio=0.001317\n",
            "Batch 232: pos=383856.0, neg=1073357968.0, pos_ratio=0.000357\n",
            "Batch 233: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 234: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 235: pos=909000.0, neg=1072832824.0, pos_ratio=0.000847\n",
            "Batch 236: pos=1302296.0, neg=1072439528.0, pos_ratio=0.001213\n",
            "Batch 237: pos=456040.0, neg=1073285784.0, pos_ratio=0.000425\n",
            "Batch 238: pos=20040.0, neg=1073721784.0, pos_ratio=0.000019\n",
            "Batch 239: pos=1274688.0, neg=1072467136.0, pos_ratio=0.001187\n",
            "Batch 240: pos=664072.0, neg=1073077752.0, pos_ratio=0.000618\n",
            "Batch 241: pos=183440.0, neg=1073558384.0, pos_ratio=0.000171\n",
            "Batch 242: pos=2390400.0, neg=1071351424.0, pos_ratio=0.002226\n",
            "Batch 243: pos=776040.0, neg=1072965784.0, pos_ratio=0.000723\n",
            "Batch 244: pos=122640.0, neg=1073619184.0, pos_ratio=0.000114\n",
            "Batch 245: pos=763248.0, neg=1072978576.0, pos_ratio=0.000711\n",
            "Batch 246: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 247: pos=689808.0, neg=1073052016.0, pos_ratio=0.000642\n",
            "Batch 248: pos=7800.0, neg=1073734024.0, pos_ratio=0.000007\n",
            "Batch 249: pos=14984.0, neg=1073726840.0, pos_ratio=0.000014\n",
            "Batch 250: pos=435912.0, neg=1073305912.0, pos_ratio=0.000406\n",
            "Batch 251: pos=39864.0, neg=1073701960.0, pos_ratio=0.000037\n",
            "Batch 252: pos=646728.0, neg=1073095096.0, pos_ratio=0.000602\n",
            "Batch 253: pos=98112.0, neg=1073643712.0, pos_ratio=0.000091\n",
            "Batch 254: pos=609912.0, neg=1073131912.0, pos_ratio=0.000568\n",
            "Batch 255: pos=24600.0, neg=1073717224.0, pos_ratio=0.000023\n",
            "Batch 256: pos=663216.0, neg=1073078608.0, pos_ratio=0.000618\n",
            "Batch 257: pos=22248.0, neg=1073719576.0, pos_ratio=0.000021\n",
            "Batch 258: pos=1041672.0, neg=1072700152.0, pos_ratio=0.000970\n",
            "Batch 259: pos=880112.0, neg=1072861712.0, pos_ratio=0.000820\n",
            "Batch 260: pos=320808.0, neg=1073421016.0, pos_ratio=0.000299\n",
            "Batch 261: pos=147464.0, neg=1073594360.0, pos_ratio=0.000137\n",
            "Batch 262: pos=777976.0, neg=1072963848.0, pos_ratio=0.000725\n",
            "Batch 263: pos=34152.0, neg=1073707672.0, pos_ratio=0.000032\n",
            "Batch 264: pos=3462000.0, neg=1070279824.0, pos_ratio=0.003224\n",
            "Batch 265: pos=22224.0, neg=1073719600.0, pos_ratio=0.000021\n",
            "Batch 266: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 267: pos=35520.0, neg=1073706304.0, pos_ratio=0.000033\n",
            "Batch 268: pos=127352.0, neg=1073614472.0, pos_ratio=0.000119\n",
            "Batch 269: pos=913512.0, neg=1072828312.0, pos_ratio=0.000851\n",
            "Batch 270: pos=261456.0, neg=1073480368.0, pos_ratio=0.000243\n",
            "Batch 271: pos=242440.0, neg=1073499384.0, pos_ratio=0.000226\n",
            "Batch 272: pos=76760.0, neg=1073665064.0, pos_ratio=0.000071\n",
            "Batch 273: pos=12984.0, neg=1073728840.0, pos_ratio=0.000012\n",
            "Batch 274: pos=74616.0, neg=1073667208.0, pos_ratio=0.000069\n",
            "Batch 275: pos=115800.0, neg=1073626024.0, pos_ratio=0.000108\n",
            "Batch 276: pos=558968.0, neg=1073182856.0, pos_ratio=0.000521\n",
            "Batch 277: pos=428616.0, neg=1073313208.0, pos_ratio=0.000399\n",
            "Batch 278: pos=1223112.0, neg=1072518712.0, pos_ratio=0.001139\n",
            "Batch 279: pos=59544.0, neg=1073682280.0, pos_ratio=0.000055\n",
            "Batch 280: pos=509688.0, neg=1073232136.0, pos_ratio=0.000475\n",
            "Batch 281: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 282: pos=118416.0, neg=1073623408.0, pos_ratio=0.000110\n",
            "Batch 283: pos=507288.0, neg=1073234536.0, pos_ratio=0.000472\n",
            "Batch 284: pos=46384.0, neg=1073695440.0, pos_ratio=0.000043\n",
            "Batch 285: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 286: pos=832192.0, neg=1072909632.0, pos_ratio=0.000775\n",
            "Batch 287: pos=1372968.0, neg=1072368856.0, pos_ratio=0.001279\n",
            "Batch 288: pos=654568.0, neg=1073087256.0, pos_ratio=0.000610\n",
            "Batch 289: pos=47592.0, neg=1073694232.0, pos_ratio=0.000044\n",
            "Batch 290: pos=1543832.0, neg=1072197992.0, pos_ratio=0.001438\n",
            "Batch 291: pos=1362024.0, neg=1072379800.0, pos_ratio=0.001268\n",
            "Batch 292: pos=1087216.0, neg=1072654608.0, pos_ratio=0.001013\n",
            "Batch 293: pos=118784.0, neg=1073623040.0, pos_ratio=0.000111\n",
            "Batch 294: pos=22968.0, neg=1073718856.0, pos_ratio=0.000021\n",
            "Batch 295: pos=412320.0, neg=1073329504.0, pos_ratio=0.000384\n",
            "Batch 296: pos=2043384.0, neg=1071698440.0, pos_ratio=0.001903\n",
            "Batch 297: pos=56520.0, neg=1073685304.0, pos_ratio=0.000053\n",
            "Batch 298: pos=1532360.0, neg=1072209464.0, pos_ratio=0.001427\n",
            "Batch 299: pos=956792.0, neg=1072785032.0, pos_ratio=0.000891\n",
            "Batch 300: pos=901584.0, neg=1072840240.0, pos_ratio=0.000840\n",
            "Batch 301: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 302: pos=1383144.0, neg=1072358680.0, pos_ratio=0.001288\n",
            "Batch 303: pos=26248.0, neg=1073715576.0, pos_ratio=0.000024\n",
            "Batch 304: pos=11760.0, neg=1073730064.0, pos_ratio=0.000011\n",
            "Batch 305: pos=8.0, neg=1073741816.0, pos_ratio=0.000000\n",
            "Batch 306: pos=357312.0, neg=1073384512.0, pos_ratio=0.000333\n",
            "Batch 307: pos=296760.0, neg=1073445064.0, pos_ratio=0.000276\n",
            "Batch 308: pos=88208.0, neg=1073653616.0, pos_ratio=0.000082\n",
            "Batch 309: pos=977080.0, neg=1072764744.0, pos_ratio=0.000910\n",
            "Batch 310: pos=0.0, neg=1073741824.0, pos_ratio=0.000000\n",
            "Batch 311: pos=187968.0, neg=1073553856.0, pos_ratio=0.000175\n",
            "Batch 312: pos=3667600.0, neg=1070074224.0, pos_ratio=0.003416\n",
            "Batch 313: pos=1565376.0, neg=1072176448.0, pos_ratio=0.001458\n",
            "Batch 314: pos=214128.0, neg=1073527696.0, pos_ratio=0.000199\n",
            "Batch 315: pos=335680.0, neg=1073406144.0, pos_ratio=0.000313\n",
            "Batch 316: pos=630728.0, neg=1073111096.0, pos_ratio=0.000587\n",
            "Batch 317: pos=12304.0, neg=1073729520.0, pos_ratio=0.000011\n",
            "Batch 318: pos=68632.0, neg=1073673192.0, pos_ratio=0.000064\n",
            "Batch 319: pos=210192.0, neg=1073531632.0, pos_ratio=0.000196\n",
            "Batch 320: pos=1101176.0, neg=1072640648.0, pos_ratio=0.001026\n",
            "Batch 321: pos=1214376.0, neg=1072527448.0, pos_ratio=0.001131\n",
            "Batch 322: pos=14696.0, neg=1073727128.0, pos_ratio=0.000014\n",
            "Batch 323: pos=41552.0, neg=1073700272.0, pos_ratio=0.000039\n",
            "Batch 324: pos=362040.0, neg=1073379784.0, pos_ratio=0.000337\n",
            "Batch 325: pos=633080.0, neg=1073108744.0, pos_ratio=0.000590\n",
            "Batch 326: pos=454720.0, neg=1073287104.0, pos_ratio=0.000423\n",
            "Batch 327: pos=305280.0, neg=1073436544.0, pos_ratio=0.000284\n",
            "Batch 328: pos=61920.0, neg=1073679904.0, pos_ratio=0.000058\n",
            "Batch 329: pos=3647352.0, neg=1070094472.0, pos_ratio=0.003397\n",
            "Batch 330: pos=79728.0, neg=1073662096.0, pos_ratio=0.000074\n",
            "Batch 331: pos=2210272.0, neg=1071531552.0, pos_ratio=0.002058\n",
            "Batch 332: pos=139752.0, neg=1073602072.0, pos_ratio=0.000130\n",
            "Batch 333: pos=227760.0, neg=1073514064.0, pos_ratio=0.000212\n",
            "Batch 334: pos=21408.0, neg=1073720416.0, pos_ratio=0.000020\n",
            "Batch 335: pos=69744.0, neg=1073672080.0, pos_ratio=0.000065\n",
            "Batch 336: pos=320560.0, neg=1073421264.0, pos_ratio=0.000299\n",
            "Batch 337: pos=161232.0, neg=1073580592.0, pos_ratio=0.000150\n",
            "Batch 338: pos=108456.0, neg=1073633368.0, pos_ratio=0.000101\n",
            "Batch 339: pos=5048.0, neg=1073736776.0, pos_ratio=0.000005\n",
            "üìä Final Stats:\n",
            "  Total pos voxels: 159131184.0\n",
            "  Total neg voxels: 364913088976.0\n",
            "  Positive ratio: 0.000436 (0.0436%)\n",
            "  Computed pos_weight: 2293.1589\n",
            "  Total batches with positives: 324\n",
            "üíæ Saved pos_weight: 2293.1589\n",
            "üìä Using reasonable pos_weight: 100.00 (capped from 2293.16)\n",
            "‚ùå Pipeline failed: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.32 GiB of which 727.88 MiB is free. Process 24588 has 78.57 GiB memory in use. Of the allocated memory 76.07 GiB is allocated by PyTorch, and 2.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.32 GiB of which 727.88 MiB is free. Process 24588 has 78.57 GiB memory in use. Of the allocated memory 76.07 GiB is allocated by PyTorch, and 2.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1502324180.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1502324180.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnetPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1502324180.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1502324180.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         )\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1081170447.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, model, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             train_loss = self.train_one_epoch(\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-1081170447.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, model, loader, optimizer, accumulation_steps, loss_fn)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# 3. Forward Pass and Loss Calculation (using automatic mixed precision)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# Loss is scaled down by accumulation_steps for averaging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3752073683.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_compatible_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3752073683.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# Try normal forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Sizes of tensors must match\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/networks/nets/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/networks/blocks/convolutions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create the additive residual from x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# apply x to sequence of operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres\u001b[0m  \u001b[0;31m# add the residual to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/monai/data/meta_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;31m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# if \"out\" in kwargs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.32 GiB of which 727.88 MiB is free. Process 24588 has 78.57 GiB memory in use. Of the allocated memory 76.07 GiB is allocated by PyTorch, and 2.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        set_determinism(seed=42)\n",
        "\n",
        "        # Setup paths\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
        "\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "        # Prepare loaders\n",
        "        print(\"üì¶ Preparing datasets and transforms...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader, self.full_train_loader = self.prepare_loaders()\n",
        "        # self.debug_model_shapes()\n",
        "        # Dataset quality analysis\n",
        "        # print(\"\\n\" + \"=\"*60)\n",
        "        # print(\"üîç RUNNING DATASET QUALITY ANALYSIS...\")\n",
        "        # print(\"=\"*60)\n",
        "        # self.analyze_dataset_quality()\n",
        "\n",
        "        # # üî• ADD COMPREHENSIVE SANITY CHECKS\n",
        "        # print(\"\\n\" + \"=\"*60)\n",
        "        # print(\"‚úÖ RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        # print(\"=\"*60)\n",
        "        # self.check_data_sanity(max_batches=2)\n",
        "        # self.check_data_distributions()\n",
        "        # self.check_spatial_consistency()\n",
        "\n",
        "\n",
        "    def create_unet_model(self, device):\n",
        "        \"\"\"Create a robust UNet model that handles size variations.\"\"\"\n",
        "\n",
        "        # FIX: Only try to import UNet and Norm, which are typically present.\n",
        "        try:\n",
        "            from monai.networks.nets import UNet  # <--- ONLY import UNet\n",
        "            from monai.networks.layers import Norm\n",
        "        except ImportError as e:\n",
        "            # Handle cases where MONAI is not correctly installed\n",
        "            print(f\"FATAL ERROR: Could not import MONAI base components. Check installation. Error: {e}\")\n",
        "            raise e\n",
        "\n",
        "        # 1. Attempt DynamicUNet logic (now removed or commented out)\n",
        "\n",
        "        print(\"‚ö†Ô∏è DynamicUNet not available or import failed. Using SafeUNet wrapper.\")\n",
        "\n",
        "        # 2. Use standard UNet wrapped by SafeUNet\n",
        "        base_model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            # This configuration is based on standard UNet depth (5 layers, 4 strides)\n",
        "            # It is the necessary minimum feature complexity, but extremely VRAM-intensive at 512^3.\n",
        "            channels=(32, 64, 128, 256, 512),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.INSTANCE,\n",
        "            dropout=0.1,\n",
        "            act='PRELU'\n",
        "        )\n",
        "        # SafeUNet acts as the wrapper to catch runtime errors\n",
        "        return SafeUNet(base_model).to(device)\n",
        "\n",
        "\n",
        "    def analyze_dataset_quality(self):\n",
        "        \"\"\"Comprehensive dataset quality analysis\"\"\"\n",
        "        print(\"üìä Analyzing dataset quality...\")\n",
        "\n",
        "        # Analyze full volumes (before patch sampling)\n",
        "        self._analyze_loader_quality(self.full_train_loader, \"TRAIN (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.valid_loader, \"VALID (Full Volumes)\")\n",
        "        self._analyze_loader_quality(self.test_loader, \"TEST (Full Volumes)\")\n",
        "\n",
        "        # Analyze training patches (after patch sampling)\n",
        "        print(\"\\n\" + \"üîç Analyzing Training Patches (After Sampling):\")\n",
        "        self._analyze_patch_quality(self.train_loader, \"TRAIN PATCHES\")\n",
        "\n",
        "    def debug_model_shapes(self):\n",
        "        \"\"\"Debug method to identify shape mismatches between model and data\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üîç DEBUGGING MODEL SHAPES\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Get a sample batch\n",
        "        sample_batch = next(iter(self.train_loader))\n",
        "        images, segs = sample_batch[\"vol\"], sample_batch[\"seg\"]\n",
        "\n",
        "        # üî• FIX: Move data to the same device as model\n",
        "        images = images.to(self.device)\n",
        "        segs = segs.to(self.device)\n",
        "\n",
        "        print(f\"üìê Input data shape: {images.shape}\")\n",
        "        print(f\"üéØ Target segmentation shape: {segs.shape}\")\n",
        "        print(f\"üíª Input device: {images.device}\")\n",
        "\n",
        "        # NEW FIX: Clear cache before model creation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"‚ö°Ô∏è Cleared CUDA cache before model instantiation.\")\n",
        "\n",
        "        # Test current model configuration\n",
        "\n",
        "\n",
        "        current_model = self.create_unet_model(self.device)\n",
        "\n",
        "        print(f\"ü§ñ Model device: {next(current_model.parameters()).device}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = current_model(images)\n",
        "            print(f\"ü§ñ Current model output shape: {output.shape}\")\n",
        "\n",
        "            # Check for mismatch\n",
        "            if output.shape[2:] != segs.shape[2:]:\n",
        "                print(f\"‚ùå SHAPE MISMATCH DETECTED!\")\n",
        "                print(f\"   Model output: {output.shape[2:]}\")\n",
        "                print(f\"   Target: {segs.shape[2:]}\")\n",
        "                print(f\"   Difference: {tuple(o-t for o,t in zip(output.shape[2:], segs.shape[2:]))}\")\n",
        "\n",
        "                # üî• Calculate what the input size should be\n",
        "                print(f\"\\nüí° SOLUTION: Your input size {images.shape[2:]} needs to be divisible by 16\")\n",
        "                print(f\"   Try using: (96, 96, 96) ‚Üí divisible by 16? {all(s % 16 == 0 for s in images.shape[2:])}\")\n",
        "            else:\n",
        "                print(\"‚úÖ Shapes match perfectly!\")\n",
        "\n",
        "        return output.shape, segs.shape\n",
        "\n",
        "\n",
        "    def _analyze_loader_quality(self, loader, name: str):\n",
        "        \"\"\"Analyze a specific data loader\"\"\"\n",
        "        print(f\"\\nüìä {name} Dataset Analysis:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        total_volumes = 0\n",
        "        volumes_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each volume in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                volume_seg = seg[i]\n",
        "                total_volumes += 1\n",
        "                volume_positives = volume_seg.sum().item()\n",
        "                volume_voxels = volume_seg.numel()\n",
        "\n",
        "                if volume_positives > 0:\n",
        "                    volumes_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += volume_positives\n",
        "                total_voxels += volume_voxels\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"  Total volumes: {total_volumes}\")\n",
        "        print(f\"  Volumes with positives: {volumes_with_positives} ({volumes_with_positives/total_volumes*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "        print(f\"  Total positive voxels: {total_pos_voxels:,}\")\n",
        "        print(f\"  Total voxels: {total_voxels:,}\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def _analyze_patch_quality(self, loader, name: str, max_batches: int = 20):\n",
        "        \"\"\"Analyze patch distribution in training loader\"\"\"\n",
        "        print(f\"\\nüìä {name} Patch Analysis (first {max_batches} batches):\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        total_patches = 0\n",
        "        patches_with_positives = 0\n",
        "        total_pos_voxels = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(loader):\n",
        "            if batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            # Check each patch in batch\n",
        "            for i in range(seg.shape[0]):\n",
        "                patch_seg = seg[i]\n",
        "                total_patches += 1\n",
        "                patch_positives = patch_seg.sum().item()\n",
        "                patch_voxels = patch_seg.numel()\n",
        "\n",
        "                if patch_positives > 0:\n",
        "                    patches_with_positives += 1\n",
        "\n",
        "                total_pos_voxels += patch_positives\n",
        "                total_voxels += patch_voxels\n",
        "\n",
        "                pos_ratio = patch_positives / patch_voxels if patch_voxels > 0 else 0\n",
        "                if patch_positives > 0:  # Only print patches with positives for clarity\n",
        "                    print(f\"  Batch {batch_idx}, Patch {i}: {patch_positives}/{patch_voxels} \"\n",
        "                          f\"({pos_ratio*100:.3f}% positive)\")\n",
        "\n",
        "        overall_pos_ratio = total_pos_voxels / total_voxels if total_voxels > 0 else 0\n",
        "\n",
        "        print(f\"\\nüìà {name} Patch Summary:\")\n",
        "        print(f\"  Total patches analyzed: {total_patches}\")\n",
        "        print(f\"  Patches with positives: {patches_with_positives} ({patches_with_positives/total_patches*100:.1f}%)\")\n",
        "        print(f\"  Overall positive ratio: {overall_pos_ratio:.6f} ({overall_pos_ratio*100:.4f}%)\")\n",
        "\n",
        "        return overall_pos_ratio\n",
        "\n",
        "    def check_data_sanity(self, max_batches: int = 3):\n",
        "        \"\"\"Comprehensive data sanity checks for all loaders\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üîç RUNNING COMPREHENSIVE DATA SANITY CHECKS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check training data\n",
        "        print(\"\\nüìä TRAINING DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.train_loader, \"train\", max_batches)\n",
        "\n",
        "        # Check validation data\n",
        "        print(\"\\nüìä VALIDATION DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.valid_loader, \"valid\", max_batches)\n",
        "\n",
        "        # Check test data\n",
        "        print(\"\\nüìä TEST DATA SANITY CHECK:\")\n",
        "        self._check_loader_sanity(self.test_loader, \"test\", max_batches)\n",
        "\n",
        "        # Check full volumes (before patch sampling)\n",
        "        print(\"\\nüìä FULL VOLUME SANITY CHECK (Before Patch Sampling):\")\n",
        "        self._check_loader_sanity(self.full_train_loader, \"full_train\", max_batches)\n",
        "\n",
        "    def _check_loader_sanity(self, loader, name: str, max_batches: int):\n",
        "        \"\"\"Check a specific loader for data sanity\"\"\"\n",
        "        print(f\"üîç Checking {name} loader...\")\n",
        "\n",
        "        batch_count = 0\n",
        "        total_positives = 0\n",
        "        total_voxels = 0\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "\n",
        "            vol = batch[\"vol\"]\n",
        "            seg = batch[\"seg\"]\n",
        "\n",
        "            print(f\"\\n  Batch {i}:\")\n",
        "            print(f\"    Volume shape: {vol.shape}\")\n",
        "            print(f\"    Volume range: [{vol.min():.4f}, {vol.max():.4f}]\")\n",
        "            print(f\"    Volume mean: {vol.mean():.4f} ¬± {vol.std():.4f}\")\n",
        "            print(f\"    Segmentation shape: {seg.shape}\")\n",
        "            print(f\"    Segmentation unique values: {torch.unique(seg)}\")\n",
        "\n",
        "            # Check for NaNs or Infs\n",
        "            if torch.isnan(vol).any():\n",
        "                print(\"    ‚ö†Ô∏è WARNING: Volume contains NaN values!\")\n",
        "            if torch.isinf(vol).any():\n",
        "                print(\"    ‚ö†Ô∏è WARNING: Volume contains Inf values!\")\n",
        "\n",
        "            # Check segmentation values are binary\n",
        "            unique_vals = torch.unique(seg)\n",
        "            if not all(val in [0, 1] for val in unique_vals):\n",
        "                print(f\"    ‚ö†Ô∏è WARNING: Segmentation has non-binary values: {unique_vals}\")\n",
        "\n",
        "            # Calculate positives\n",
        "            batch_positives = seg.sum().item()\n",
        "            batch_voxels = seg.numel()\n",
        "            pos_ratio = batch_positives / batch_voxels if batch_voxels > 0 else 0\n",
        "\n",
        "            print(f\"    Positives: {batch_positives:,}/{batch_voxels:,} ({pos_ratio*100:.4f}%)\")\n",
        "\n",
        "            total_positives += batch_positives\n",
        "            total_voxels += batch_voxels\n",
        "            batch_count += 1\n",
        "\n",
        "        # Summary for this loader\n",
        "        if batch_count > 0:\n",
        "            overall_ratio = total_positives / total_voxels if total_voxels > 0 else 0\n",
        "            print(f\"\\n  üìà {name} Summary ({batch_count} batches):\")\n",
        "            print(f\"    Total positives: {total_positives:,}\")\n",
        "            print(f\"    Total voxels: {total_voxels:,}\")\n",
        "            print(f\"    Overall positive ratio: {overall_ratio:.6f} ({overall_ratio*100:.4f}%)\")\n",
        "\n",
        "    def check_data_distributions(self):\n",
        "        \"\"\"Check intensity distributions and data consistency\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üìä CHECKING DATA DISTRIBUTIONS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Check intensity distributions\n",
        "        self._check_intensity_distribution(self.train_loader, \"Training\")\n",
        "        self._check_intensity_distribution(self.valid_loader, \"Validation\")\n",
        "        self._check_intensity_distribution(self.test_loader, \"Test\")\n",
        "\n",
        "    def _check_intensity_distribution(self, loader, name: str):\n",
        "        \"\"\"Check intensity distribution for a loader\"\"\"\n",
        "        print(f\"\\nüìà {name} Intensity Distribution:\")\n",
        "\n",
        "        all_values = []\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= 5:  # Check first 5 batches for speed\n",
        "                break\n",
        "            vol = batch[\"vol\"]\n",
        "            all_values.extend(vol.flatten().cpu().numpy())\n",
        "\n",
        "        if all_values:\n",
        "            all_values = np.array(all_values)\n",
        "            print(f\"  Range: [{np.min(all_values):.4f}, {np.max(all_values):.4f}]\")\n",
        "            print(f\"  Mean: {np.mean(all_values):.4f} ¬± {np.std(all_values):.4f}\")\n",
        "            print(f\"  Median: {np.median(all_values):.4f}\")\n",
        "            print(f\"  Non-zero values: {np.sum(all_values != 0):,}/{len(all_values):,} \"\n",
        "                  f\"({np.sum(all_values != 0)/len(all_values)*100:.2f}%)\")\n",
        "\n",
        "    def check_spatial_consistency(self):\n",
        "        \"\"\"Check that all volumes have consistent spatial properties\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üìè CHECKING SPATIAL CONSISTENCY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        loaders = {\n",
        "            \"Training\": self.train_loader,\n",
        "            \"Validation\": self.valid_loader,\n",
        "            \"Test\": self.test_loader\n",
        "        }\n",
        "\n",
        "        for name, loader in loaders.items():\n",
        "            print(f\"\\nüìê {name} Spatial Properties:\")\n",
        "            shapes = []\n",
        "            for i, batch in enumerate(loader):\n",
        "                if i >= 3:  # Check first 3 batches\n",
        "                    break\n",
        "                vol = batch[\"vol\"]\n",
        "                shapes.append(vol.shape[2:])  # Get spatial dimensions (D, H, W)\n",
        "                print(f\"  Batch {i} shape: {vol.shape}\")\n",
        "\n",
        "            # Check consistency\n",
        "            if len(shapes) > 1:\n",
        "                if all(shape == shapes[0] for shape in shapes):\n",
        "                    print(f\"  ‚úÖ All batches have consistent shape: {shapes[0]}\")\n",
        "                else:\n",
        "                    print(f\"  ‚ö†Ô∏è Shape inconsistency: {shapes}\")\n",
        "\n",
        "    def filter_empty_samples(self, file_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Remove samples that have no positive segmentation labels\"\"\"\n",
        "        filtered_files = []\n",
        "\n",
        "        for file_pair in file_list:\n",
        "            # Load just the segmentation to check if it's empty\n",
        "            seg_loader = Compose([\n",
        "                LoadImaged(keys=[\"seg\"]),\n",
        "                EnsureChannelFirstd(keys=[\"seg\"]),\n",
        "            ])\n",
        "\n",
        "            try:\n",
        "                seg_data = seg_loader(file_pair)[\"seg\"]\n",
        "                if seg_data.sum() > 0:  # Only keep if has positive voxels\n",
        "                    filtered_files.append(file_pair)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading {file_pair['seg']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"üìä Filtered {len(file_list)} -> {len(filtered_files)} non-empty samples\")\n",
        "        return filtered_files\n",
        "\n",
        "    def prepare_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader]:\n",
        "        \"\"\"Prepare data loaders for training, validation, and testing\"\"\"\n",
        "        # --- Constants ---\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        patch_size = (512, 512, 512) # Target training patch size\n",
        "\n",
        "        # NOTE: compatible_spatial_size is now redundant since we are targeting patch_size directly,\n",
        "        # but we keep the name for validation/test sets which must be divisible by 16.\n",
        "        compatible_spatial_size = (512, 512, 512)\n",
        "        # -----------------\n",
        "\n",
        "        def get_files(split: str) -> List[Dict]:\n",
        "            \"\"\"Get file paths for a specific split with validation (original helper, unchanged)\"\"\"\n",
        "            ct_dir = os.path.join(self.dataset_dir, split, \"ct\")\n",
        "            seg_dir = os.path.join(self.dataset_dir, split, \"segment\")\n",
        "\n",
        "            # (File loading and error checks remain here)\n",
        "\n",
        "            ct_files = sorted(glob(os.path.join(ct_dir, \"*.nii.gz\")))\n",
        "            seg_files = sorted(glob(os.path.join(seg_dir, \"*.nii.gz\")))\n",
        "\n",
        "            # (Error checks remain here)\n",
        "\n",
        "            files = []\n",
        "            for ct_file, seg_file in zip(ct_files, seg_files):\n",
        "                ct_id = os.path.basename(ct_file).replace('.nii.gz', '')\n",
        "                seg_id = os.path.basename(seg_file).replace('.nii.gz', '')\n",
        "                if ct_id != seg_id:\n",
        "                    print(f\"‚ö†Ô∏è Warning: File name mismatch - CT: {ct_id}, SEG: {seg_id}\")\n",
        "                files.append({\"vol\": ct_file, \"seg\": seg_file})\n",
        "\n",
        "            # Filter out empty samples for training\n",
        "            if split == \"train\":\n",
        "                files = self.filter_empty_samples(files)\n",
        "\n",
        "            print(f\"üìÅ {split}: Loaded {len(files)} samples\")\n",
        "            return files\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "        # Training transforms: Resize volume directly to 96x96x96\n",
        "        # ----------------------------------------------------------------------\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "            # FIX 1: Spacingd Interpolation (This is the one safe place for bilinear/nearest)\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "\n",
        "            # FIX 2: Resize Interpolation/Padding (MUST be 'constant' to avoid crash)\n",
        "            ResizeWithPadOrCropd(keys=[\"vol\", \"seg\"],\n",
        "                                spatial_size=patch_size,\n",
        "                                # CRITICAL CHANGE: Use crash-proof CONSTANT for BOTH\n",
        "                                mode=(\"constant\", \"constant\"),\n",
        "                                constant_values=(0.0, 0.0)),\n",
        "\n",
        "            # Binarization\n",
        "            Lambdad(keys=\"seg\", func=binarize_segmentation_logic),\n",
        "\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=[0, 1, 2]),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.05),\n",
        "\n",
        "            # Sampler (RandCropByPosNegLabeld must be here, NOT ResizeWithPadOrCropd)\n",
        "            RandCropByPosNegLabeld(\n",
        "                keys=[\"vol\", \"seg\"],\n",
        "                label_key=\"seg\",\n",
        "                spatial_size=patch_size,\n",
        "                pos=0.9, neg=0.1, num_samples=8,\n",
        "                image_key=\"vol\", image_threshold=0, allow_smaller=False,\n",
        "            ),\n",
        "\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\", \"seg\"]),\n",
        "        ])\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "        # Base transforms: Use compatible_spatial_size (128^3) for evaluation/test\n",
        "        # ----------------------------------------------------------------------\n",
        "        base_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "            # FIX 1: Spacingd Interpolation (This is the one safe place for bilinear/nearest)\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\", labels=None),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            NormalizeIntensityd(keys=[\"vol\"], subtrahend=0.5, divisor=0.5),\n",
        "\n",
        "            # FIX 2: Resize Interpolation/Padding (MUST be 'constant' to avoid crash)\n",
        "            ResizeWithPadOrCropd(keys=[\"vol\", \"seg\"],\n",
        "                                spatial_size=patch_size,\n",
        "                                # CRITICAL CHANGE: Use crash-proof CONSTANT for BOTH\n",
        "                                mode=(\"constant\", \"constant\"),\n",
        "                                constant_values=(0.0, 0.0)),\n",
        "\n",
        "            # CRITICAL FIX: Apply Lambdad with the global function (for picklability)\n",
        "            Lambdad(keys=\"seg\", func=binarize_segmentation_logic),\n",
        "\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\",\"seg\"], track_meta=True),\n",
        "        ])\n",
        "\n",
        "        # Create datasets\n",
        "        print(\"üîÑ Loading training dataset...\")\n",
        "        train_ds = CacheDataset(\n",
        "            data=get_files(\"train\"),\n",
        "            transform=train_transforms,\n",
        "            cache_rate=0.1,\n",
        "            num_workers=2 # <-- SPEED FIX: Re-enable multiprocessing for caching\n",
        "        )\n",
        "\n",
        "        print(\"üîÑ Loading validation dataset...\")\n",
        "        valid_ds = CacheDataset(\n",
        "            data=get_files(\"valid\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,\n",
        "            num_workers=2 # <-- SPEED FIX\n",
        "        )\n",
        "\n",
        "        print(\"üîÑ Loading test dataset...\")\n",
        "        test_ds = CacheDataset(\n",
        "            data=get_files(\"test\"),\n",
        "            transform=base_transforms,\n",
        "            cache_rate=0.2,\n",
        "            num_workers=2 # <-- SPEED FIX\n",
        "        )\n",
        "\n",
        "        # Create data loaders with optimized settings\n",
        "        train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=True,\n",
        "            num_workers=0, # <-- CRITICAL TEMPORARY FIX: Disable workers for training stability\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            persistent_workers=False,\n",
        "            # REMOVED prefetch_factor=2, # MUST be removed if num_workers=0\n",
        "            collate_fn=pad_list_data_collate,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        valid_loader = DataLoader(\n",
        "            valid_ds,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=0,  # Synchronous evaluation/analysis\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            # Removed persistent_workers=False,\n",
        "            # Removed prefetch_factor=1,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=0,  # Synchronous evaluation/analysis\n",
        "            pin_memory=False,\n",
        "            # Removed persistent_workers=False,\n",
        "            # Removed prefetch_factor=None,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        # Full volume train loader for sanity checks (no patching)\n",
        "        full_train_ds = Dataset(get_files(\"train\"), base_transforms)\n",
        "        full_train_loader = DataLoader(\n",
        "            full_train_ds,\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=0,  # Synchronous evaluation/analysis\n",
        "            pin_memory=False,\n",
        "            collate_fn=pad_list_data_collate\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Dataset sizes ‚Äî Train: {len(train_ds)}, Valid: {len(valid_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "        return train_loader, valid_loader, test_loader, full_train_loader\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Execute training with resource monitoring\"\"\"\n",
        "        model = self.create_unet_model(self.device)\n",
        "        # Monitor resources\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"üéØ GPU Memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "            print(f\"üéØ GPU Memory cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n",
        "        # print(\"\\nüîç Final shape check before training...\")\n",
        "        # self.debug_model_shapes()\n",
        "        # Validate we have data\n",
        "\n",
        "        if len(self.train_loader.dataset) == 0:\n",
        "            raise ValueError(\"No training data available!\")\n",
        "        if len(self.valid_loader.dataset) == 0:\n",
        "            raise ValueError(\"No validation data available!\")\n",
        "\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(model,self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Execute testing with checkpoint validation\"\"\"\n",
        "        # Use consistent architecture with training\n",
        "        model = self.create_unet_model(self.device)\n",
        "\n",
        "        if os.path.exists(self.model_file):\n",
        "            print(\"üìÇ Loading checkpoint...\")\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "\n",
        "            # Validate checkpoint\n",
        "            if 'model_state_dict' not in checkpoint:\n",
        "                raise ValueError(\"Invalid checkpoint: missing 'model_state_dict'\")\n",
        "\n",
        "            try:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                print(\"‚úÖ Checkpoint loaded successfully\")\n",
        "\n",
        "                # Print training info if available\n",
        "                if 'epoch' in checkpoint:\n",
        "                    print(f\"üìÖ Checkpoint from epoch: {checkpoint['epoch']}\")\n",
        "                if 'val_loss' in checkpoint:\n",
        "                    print(f\"üìâ Checkpoint validation loss: {checkpoint['val_loss']:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Checkpoint loading failed: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Model file not found: {self.model_file}\")\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Execute full pipeline with validation\"\"\"\n",
        "        print(\"üöÄ Starting pipeline with:\")\n",
        "        print(f\"   - Train samples: {len(self.train_loader.dataset)}\")\n",
        "        print(f\"   - Valid samples: {len(self.valid_loader.dataset)}\")\n",
        "        print(f\"   - Test samples: {len(self.test_loader.dataset)}\")\n",
        "        print(f\"   - Device: {self.device}\")\n",
        "        print(f\"   - Output directory: {self.output_dir}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            self.train()\n",
        "            self.test()\n",
        "\n",
        "            total_time = time.time() - start_time\n",
        "            print(f\"‚úÖ Pipeline completed in {total_time/60:.2f} minutes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Pipeline failed: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "# ---------- Run ----------\n",
        "def main():\n",
        "    import multiprocessing as mp\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_Nifti_MONAI6_1_3Original\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 1,   # Effective patches per step = num_samples * batch_size\n",
        "        'num_epochs': 200,\n",
        "        'learning_rate': 1e-5,\n",
        "    }\n",
        "\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    Resized,\n",
        "    CopyItemsd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    SaveImaged,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "# from monai.transforms.utils import SaveTransform\n",
        "\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_ct_dir, input_seg_dir, output_dir, device=\"cuda:0\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_ct_dir = input_ct_dir\n",
        "        self.input_seg_dir = input_seg_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.ct_out_dir = os.path.join(output_dir, \"ct\")\n",
        "        self.seg_out_dir = os.path.join(output_dir, \"segment\")\n",
        "        os.makedirs(self.ct_out_dir, exist_ok=True)\n",
        "        os.makedirs(self.seg_out_dir, exist_ok=True)\n",
        "        self.model_path = model_path\n",
        "        self.model = self._load_model()\n",
        "        set_determinism(seed=42)\n",
        "        self.forward_transforms = self._get_forward_transforms()\n",
        "        self.inverse_transforms = None\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        model.load_state_dict(state_dict.get('model_state_dict', state_dict))\n",
        "\n",
        "        print(f\"‚úÖ Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_forward_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            CopyItemsd(keys=[\"vol\"], names=[\"vol_meta_dict\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\"], spatial_size=(96, 96, 96)),\n",
        "            EnsureTyped(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _get_inverse_transforms(self):\n",
        "        return Compose([\n",
        "            Invertd(\n",
        "                keys=[\"seg\"],\n",
        "                transform=self.forward_transforms,\n",
        "                orig_keys=[\"vol\"],\n",
        "                meta_keys=[\"vol_meta_dict\"],\n",
        "                nearest_interp=True,\n",
        "                to_tensor=False,\n",
        "            ),\n",
        "            EnsureTyped(keys=[\"seg\"])\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        data = []\n",
        "        for f in os.listdir(self.input_ct_dir):\n",
        "            if f.endswith(('.nii', '.nii.gz')):\n",
        "                ct_path = os.path.join(self.input_ct_dir, f)\n",
        "                data.append({\"vol\": ct_path})\n",
        "        print(f\"üîç Found {len(data)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data, transform=self.forward_transforms), batch_size=1, num_workers=0)\n",
        "\n",
        "    def infer(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                batch = decollate_batch(batch)[0]\n",
        "                vol_meta = batch[\"vol_meta_dict\"]\n",
        "                ct = batch[\"vol\"]\n",
        "\n",
        "                if ct.dim() == 4:\n",
        "                    ct = ct.unsqueeze(0)\n",
        "                ct = ct.to(self.device)\n",
        "\n",
        "                filename = os.path.basename(vol_meta.meta[\"filename_or_obj\"])\n",
        "                orig_vol = nib.load(vol_meta.meta[\"filename_or_obj\"]).get_fdata()\n",
        "                print(f\"üîç Inference on [{i+1}] {filename} | shape = {ct.shape}\")\n",
        "                print(f\"üîç Original volume shape = {orig_vol.shape}\")\n",
        "                pred = self.model(ct)\n",
        "                pred = (torch.sigmoid(pred) > 0.5).float()\n",
        "\n",
        "                print(f\"‚úÖ Predicted mask shape: {pred.shape}\")\n",
        "\n",
        "                batch[\"seg\"] = pred.cpu().squeeze(0)\n",
        "                print(f\"‚úÖ Batch shape: {batch['seg'].shape}\")\n",
        "\n",
        "                if self.inverse_transforms is None:\n",
        "                    self.inverse_transforms = self._get_inverse_transforms()\n",
        "\n",
        "                inverted = self.inverse_transforms(batch)\n",
        "                inv_seg = inverted[\"seg\"].squeeze(0).numpy()\n",
        "                inv_seg = (inv_seg > 0.5).astype(np.uint8)\n",
        "                print(f\"‚úÖ Inverted mask shape: {inv_seg.shape}\")\n",
        "\n",
        "                self._save_nifti(inv_seg, vol_meta, self.seg_out_dir, filename, is_segmentation=True)\n",
        "\n",
        "\n",
        "    def _save_nifti(self, array, meta_tensor, out_dir, filename, is_segmentation=False):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        affine = meta_tensor.meta.get(\"original_affine\", meta_tensor.meta.get(\"affine\", np.eye(4)))\n",
        "        dtype = np.uint8 if is_segmentation else np.float32\n",
        "        nib_img = nib.Nifti1Image(array.astype(dtype), affine)\n",
        "        nib.save(nib_img, os.path.join(out_dir, filename))\n",
        "        print(f\"‚úÖ Saved: {os.path.join(out_dir, filename)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"üéâ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "z6a0G1DXTIV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a85b9f-c61a-4fd8-b379-3bd00e32c605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "üîç Found 89 NIfTI files for inference.\n",
            "üîç Inference on [1] LUNG3-01.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (59, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (59, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-01.nii.gz\n",
            "üîç Inference on [2] LUNG3-02.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (57, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (57, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-02.nii.gz\n",
            "üîç Inference on [3] LUNG3-03.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (61, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (61, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-03.nii.gz\n",
            "üîç Inference on [4] LUNG3-04.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (61, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (61, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-04.nii.gz\n",
            "üîç Inference on [5] LUNG3-05.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (229, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (229, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-05.nii.gz\n",
            "üîç Inference on [6] LUNG3-06.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (61, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (61, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-06.nii.gz\n",
            "üîç Inference on [7] LUNG3-07.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (86, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (86, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-07.nii.gz\n",
            "üîç Inference on [8] LUNG3-08.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (158, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (158, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-08.nii.gz\n",
            "üîç Inference on [9] LUNG3-09.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (140, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (140, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-09.nii.gz\n",
            "üîç Inference on [10] LUNG3-10.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (95, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (95, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-10.nii.gz\n",
            "üîç Inference on [11] LUNG3-11.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (252, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (252, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-11.nii.gz\n",
            "üîç Inference on [12] LUNG3-12.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (206, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (206, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-12.nii.gz\n",
            "üîç Inference on [13] LUNG3-13.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (71, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (71, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-13.nii.gz\n",
            "üîç Inference on [14] LUNG3-14.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (325, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (325, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-14.nii.gz\n",
            "üîç Inference on [15] LUNG3-15.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (234, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (234, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-15.nii.gz\n",
            "üîç Inference on [16] LUNG3-16.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (192, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (192, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-16.nii.gz\n",
            "üîç Inference on [17] LUNG3-17.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (226, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (226, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-17.nii.gz\n",
            "üîç Inference on [18] LUNG3-18.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-18.nii.gz\n",
            "üîç Inference on [19] LUNG3-19.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-19.nii.gz\n",
            "üîç Inference on [20] LUNG3-20.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (176, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (176, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-20.nii.gz\n",
            "üîç Inference on [21] LUNG3-21.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (74, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (74, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-21.nii.gz\n",
            "üîç Inference on [22] LUNG3-22.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (236, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (236, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-22.nii.gz\n",
            "üîç Inference on [23] LUNG3-23.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (52, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (52, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-23.nii.gz\n",
            "üîç Inference on [24] LUNG3-24.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-24.nii.gz\n",
            "üîç Inference on [25] LUNG3-25.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (202, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (202, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-25.nii.gz\n",
            "üîç Inference on [26] LUNG3-26.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (83, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (83, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-26.nii.gz\n",
            "üîç Inference on [27] LUNG3-27.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (149, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (149, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-27.nii.gz\n",
            "üîç Inference on [28] LUNG3-28.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (86, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (86, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-28.nii.gz\n",
            "üîç Inference on [29] LUNG3-29.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (173, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (173, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-29.nii.gz\n",
            "üîç Inference on [30] LUNG3-30.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (72, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (72, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-30.nii.gz\n",
            "üîç Inference on [31] LUNG3-31.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (242, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (242, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-31.nii.gz\n",
            "üîç Inference on [32] LUNG3-32.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (58, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (58, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-32.nii.gz\n",
            "üîç Inference on [33] LUNG3-33.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (276, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (276, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-33.nii.gz\n",
            "üîç Inference on [34] LUNG3-34.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (255, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (255, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-34.nii.gz\n",
            "üîç Inference on [35] LUNG3-35.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (253, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (253, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-35.nii.gz\n",
            "üîç Inference on [36] LUNG3-36.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (356, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (356, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-36.nii.gz\n",
            "üîç Inference on [37] LUNG3-37.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (97, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (97, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-37.nii.gz\n",
            "üîç Inference on [38] LUNG3-38.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (223, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (223, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-38.nii.gz\n",
            "üîç Inference on [39] LUNG3-39.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (82, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (82, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-39.nii.gz\n",
            "üîç Inference on [40] LUNG3-40.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (239, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (239, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-40.nii.gz\n",
            "üîç Inference on [41] LUNG3-41.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (110, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (110, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-41.nii.gz\n",
            "üîç Inference on [42] LUNG3-42.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (255, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (255, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-42.nii.gz\n",
            "üîç Inference on [43] LUNG3-43.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (68, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (68, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-43.nii.gz\n",
            "üîç Inference on [44] LUNG3-44.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (227, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (227, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-44.nii.gz\n",
            "üîç Inference on [45] LUNG3-45.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-45.nii.gz\n",
            "üîç Inference on [46] LUNG3-46.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (184, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (184, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-46.nii.gz\n",
            "üîç Inference on [47] LUNG3-47.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (275, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (275, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-47.nii.gz\n",
            "üîç Inference on [48] LUNG3-48.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (157, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (157, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-48.nii.gz\n",
            "üîç Inference on [49] LUNG3-49.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (89, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (89, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-49.nii.gz\n",
            "üîç Inference on [50] LUNG3-50.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (255, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (255, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-50.nii.gz\n",
            "üîç Inference on [51] LUNG3-51.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (76, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (76, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-51.nii.gz\n",
            "üîç Inference on [52] LUNG3-52.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (50, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (50, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-52.nii.gz\n",
            "üîç Inference on [53] LUNG3-53.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (255, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (255, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-53.nii.gz\n",
            "üîç Inference on [54] LUNG3-54.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (175, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (175, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-54.nii.gz\n",
            "üîç Inference on [55] LUNG3-55.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (72, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (72, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-55.nii.gz\n",
            "üîç Inference on [56] LUNG3-56.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-56.nii.gz\n",
            "üîç Inference on [57] LUNG3-57.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-57.nii.gz\n",
            "üîç Inference on [58] LUNG3-58.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (64, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (64, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-58.nii.gz\n",
            "üîç Inference on [59] LUNG3-59.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (62, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (62, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-59.nii.gz\n",
            "üîç Inference on [60] LUNG3-60.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (92, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (92, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-60.nii.gz\n",
            "üîç Inference on [61] LUNG3-61.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (203, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (203, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-61.nii.gz\n",
            "üîç Inference on [62] LUNG3-62.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (66, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (66, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-62.nii.gz\n",
            "üîç Inference on [63] LUNG3-63.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (57, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (57, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-63.nii.gz\n",
            "üîç Inference on [64] LUNG3-64.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (172, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (172, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-64.nii.gz\n",
            "üîç Inference on [65] LUNG3-65.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (175, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (175, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-65.nii.gz\n",
            "üîç Inference on [66] LUNG3-66.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (69, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (69, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-66.nii.gz\n",
            "üîç Inference on [67] LUNG3-67.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (74, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (74, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-67.nii.gz\n",
            "üîç Inference on [68] LUNG3-68.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (60, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (60, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-68.nii.gz\n",
            "üîç Inference on [69] LUNG3-69.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (158, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (158, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-69.nii.gz\n",
            "üîç Inference on [70] LUNG3-70.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (258, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (258, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-70.nii.gz\n",
            "üîç Inference on [71] LUNG3-71.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (287, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (287, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-71.nii.gz\n",
            "üîç Inference on [72] LUNG3-72.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (84, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (84, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-72.nii.gz\n",
            "üîç Inference on [73] LUNG3-73.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (218, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (218, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-73.nii.gz\n",
            "üîç Inference on [74] LUNG3-74.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (67, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (67, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-74.nii.gz\n",
            "üîç Inference on [75] LUNG3-75.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (88, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (88, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-75.nii.gz\n",
            "üîç Inference on [76] LUNG3-76.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (74, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (74, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-76.nii.gz\n",
            "üîç Inference on [77] LUNG3-77.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (99, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (99, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-77.nii.gz\n",
            "üîç Inference on [78] LUNG3-78.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (255, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (255, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-78.nii.gz\n",
            "üîç Inference on [79] LUNG3-79.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (240, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (240, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-79.nii.gz\n",
            "üîç Inference on [80] LUNG3-80.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (59, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (59, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-80.nii.gz\n",
            "üîç Inference on [81] LUNG3-81.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (307, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (307, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-81.nii.gz\n",
            "üîç Inference on [82] LUNG3-82.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (78, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (78, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-82.nii.gz\n",
            "üîç Inference on [83] LUNG3-83.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (178, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (178, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-83.nii.gz\n",
            "üîç Inference on [84] LUNG3-84.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (66, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (66, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-84.nii.gz\n",
            "üîç Inference on [85] LUNG3-85.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (234, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (234, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-85.nii.gz\n",
            "üîç Inference on [86] LUNG3-86.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (78, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (78, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-86.nii.gz\n",
            "üîç Inference on [87] LUNG3-87.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (79, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (79, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-87.nii.gz\n",
            "üîç Inference on [88] LUNG3-88.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (154, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (154, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-88.nii.gz\n",
            "üîç Inference on [89] LUNG3-89.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (158, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (158, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3_Predicted/segment/LUNG3-89.nii.gz\n",
            "üéâ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"test_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"üéâ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "b54762e0-6093-45f5-86b6-48c278f39d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "üîç Found 38 NIfTI files for inference.\n",
            "üîç Inference on [1] LUNG1-001.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-001.nii.gz\n",
            "üîç Inference on [2] LUNG1-025.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (106, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (106, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-025.nii.gz\n",
            "üîç Inference on [3] LUNG1-027.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (108, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (108, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-027.nii.gz\n",
            "üîç Inference on [4] LUNG1-034.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (95, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (95, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-034.nii.gz\n",
            "üîç Inference on [5] LUNG1-039.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (95, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (95, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-039.nii.gz\n",
            "üîç Inference on [6] LUNG1-066.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (92, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (92, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-066.nii.gz\n",
            "üîç Inference on [7] LUNG1-078.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (136, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (136, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-078.nii.gz\n",
            "üîç Inference on [8] LUNG1-088.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (123, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (123, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-088.nii.gz\n",
            "üîç Inference on [9] LUNG1-107.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (116, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (116, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-107.nii.gz\n",
            "üîç Inference on [10] LUNG1-132.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (114, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (114, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-132.nii.gz\n",
            "üîç Inference on [11] LUNG1-133.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (184, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (184, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-133.nii.gz\n",
            "üîç Inference on [12] LUNG1-143.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-143.nii.gz\n",
            "üîç Inference on [13] LUNG1-149.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (118, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (118, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-149.nii.gz\n",
            "üîç Inference on [14] LUNG1-151.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (118, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (118, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-151.nii.gz\n",
            "üîç Inference on [15] LUNG1-158.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (115, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (115, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-158.nii.gz\n",
            "üîç Inference on [16] LUNG1-168.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-168.nii.gz\n",
            "üîç Inference on [17] LUNG1-175.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (112, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (112, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-175.nii.gz\n",
            "üîç Inference on [18] LUNG1-176.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (106, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (106, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-176.nii.gz\n",
            "üîç Inference on [19] LUNG1-201.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-201.nii.gz\n",
            "üîç Inference on [20] LUNG1-224.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (93, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (93, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-224.nii.gz\n",
            "üîç Inference on [21] LUNG1-225.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-225.nii.gz\n",
            "üîç Inference on [22] LUNG1-235.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (129, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (129, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-235.nii.gz\n",
            "üîç Inference on [23] LUNG1-239.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-239.nii.gz\n",
            "üîç Inference on [24] LUNG1-246.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (115, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (115, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-246.nii.gz\n",
            "üîç Inference on [25] LUNG1-263.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-263.nii.gz\n",
            "üîç Inference on [26] LUNG1-266.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (94, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (94, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-266.nii.gz\n",
            "üîç Inference on [27] LUNG1-281.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (101, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (101, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-281.nii.gz\n",
            "üîç Inference on [28] LUNG1-286.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (136, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (136, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-286.nii.gz\n",
            "üîç Inference on [29] LUNG1-312.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-312.nii.gz\n",
            "üîç Inference on [30] LUNG1-338.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-338.nii.gz\n",
            "üîç Inference on [31] LUNG1-352.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-352.nii.gz\n",
            "üîç Inference on [32] LUNG1-353.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-353.nii.gz\n",
            "üîç Inference on [33] LUNG1-365.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-365.nii.gz\n",
            "üîç Inference on [34] LUNG1-374.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (130, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (130, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-374.nii.gz\n",
            "üîç Inference on [35] LUNG1-383.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-383.nii.gz\n",
            "üîç Inference on [36] LUNG1-405.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-405.nii.gz\n",
            "üîç Inference on [37] LUNG1-408.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (107, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (107, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-408.nii.gz\n",
            "üîç Inference on [38] LUNG1-410.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/test_Predicted/segment/LUNG1-410.nii.gz\n",
            "üéâ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_CT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"ct\")\n",
        "    INPUT_SEG_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid\", \"segment\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"valid_Predicted\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_CT_FOLDER, INPUT_SEG_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"üéâ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIi6GZ347x8",
        "outputId": "5b5fc90e-eeaf-4b07-d6a5-bf3197b8e4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "üîç Found 43 NIfTI files for inference.\n",
            "üîç Inference on [1] LUNG1-010.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (91, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (91, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-010.nii.gz\n",
            "üîç Inference on [2] LUNG1-031.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (153, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (153, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-031.nii.gz\n",
            "üîç Inference on [3] LUNG1-040.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (95, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (95, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-040.nii.gz\n",
            "üîç Inference on [4] LUNG1-056.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-056.nii.gz\n",
            "üîç Inference on [5] LUNG1-057.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (101, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (101, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-057.nii.gz\n",
            "üîç Inference on [6] LUNG1-071.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (135, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (135, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-071.nii.gz\n",
            "üîç Inference on [7] LUNG1-073.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (176, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (176, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-073.nii.gz\n",
            "üîç Inference on [8] LUNG1-074.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (115, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (115, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-074.nii.gz\n",
            "üîç Inference on [9] LUNG1-076.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (92, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (92, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-076.nii.gz\n",
            "üîç Inference on [10] LUNG1-077.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (117, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (117, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-077.nii.gz\n",
            "üîç Inference on [11] LUNG1-080.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (99, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (99, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-080.nii.gz\n",
            "üîç Inference on [12] LUNG1-091.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (135, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (135, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-091.nii.gz\n",
            "üîç Inference on [13] LUNG1-095.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (106, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (106, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-095.nii.gz\n",
            "üîç Inference on [14] LUNG1-117.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (90, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (90, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-117.nii.gz\n",
            "üîç Inference on [15] LUNG1-134.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (108, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (108, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-134.nii.gz\n",
            "üîç Inference on [16] LUNG1-139.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (107, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (107, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-139.nii.gz\n",
            "üîç Inference on [17] LUNG1-147.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (99, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (99, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-147.nii.gz\n",
            "üîç Inference on [18] LUNG1-170.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (110, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (110, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-170.nii.gz\n",
            "üîç Inference on [19] LUNG1-177.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (94, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (94, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-177.nii.gz\n",
            "üîç Inference on [20] LUNG1-186.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-186.nii.gz\n",
            "üîç Inference on [21] LUNG1-194.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (127, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (127, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-194.nii.gz\n",
            "üîç Inference on [22] LUNG1-196.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (94, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (94, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-196.nii.gz\n",
            "üîç Inference on [23] LUNG1-198.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (131, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (131, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-198.nii.gz\n",
            "üîç Inference on [24] LUNG1-210.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (131, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (131, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-210.nii.gz\n",
            "üîç Inference on [25] LUNG1-220.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (94, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (94, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-220.nii.gz\n",
            "üîç Inference on [26] LUNG1-230.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (93, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (93, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-230.nii.gz\n",
            "üîç Inference on [27] LUNG1-233.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-233.nii.gz\n",
            "üîç Inference on [28] LUNG1-241.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (136, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (136, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-241.nii.gz\n",
            "üîç Inference on [29] LUNG1-249.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (93, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (93, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-249.nii.gz\n",
            "üîç Inference on [30] LUNG1-264.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (130, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (130, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-264.nii.gz\n",
            "üîç Inference on [31] LUNG1-273.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (136, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (136, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-273.nii.gz\n",
            "üîç Inference on [32] LUNG1-299.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (93, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (93, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-299.nii.gz\n",
            "üîç Inference on [33] LUNG1-329.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-329.nii.gz\n",
            "üîç Inference on [34] LUNG1-337.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-337.nii.gz\n",
            "üîç Inference on [35] LUNG1-340.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (92, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (92, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-340.nii.gz\n",
            "üîç Inference on [36] LUNG1-356.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-356.nii.gz\n",
            "üîç Inference on [37] LUNG1-371.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (173, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (173, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-371.nii.gz\n",
            "üîç Inference on [38] LUNG1-372.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-372.nii.gz\n",
            "üîç Inference on [39] LUNG1-412.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-412.nii.gz\n",
            "üîç Inference on [40] LUNG1-415.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (122, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (122, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-415.nii.gz\n",
            "üîç Inference on [41] LUNG1-418.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (133, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (133, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-418.nii.gz\n",
            "üîç Inference on [42] LUNG1-419.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-419.nii.gz\n",
            "üîç Inference on [43] LUNG1-421.nii.gz | shape = torch.Size([1, 1, 96, 96, 96])\n",
            "üîç Original volume shape = (134, 512, 512)\n",
            "‚úÖ Predicted mask shape: torch.Size([1, 1, 96, 96, 96])\n",
            "‚úÖ Batch shape: torch.Size([1, 96, 96, 96])\n",
            "‚úÖ Inverted mask shape: (134, 512, 512)\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/valid_Predicted/segment/LUNG1-421.nii.gz\n",
            "üéâ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPE0vOI8tVZoFOv5R9SeOas",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}