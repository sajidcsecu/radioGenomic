{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+b0zIm1eSg9Ckk5bUsJPt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/Data_Preparation_(final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) Mount Google Drive"
      ],
      "metadata": {
        "id": "ikPOT8l5eXax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYQhOOWMdfu5",
        "outputId": "1c827a22-3058-4417-f26b-a2eef4965d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) Import Required Libraries"
      ],
      "metadata": {
        "id": "Eq97t6sueacq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "S9EC6i1nfcRB",
        "outputId": "3c848436-92cc-4ba0-c9dd-0a0a84f14465"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.1\n",
            "Collecting pydicom===2.4.3\n",
            "  Downloading pydicom-2.4.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.3\n",
            "Collecting pydicom-seg\n",
            "  Downloading pydicom_seg-0.4.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.1)\n",
            "Collecting jsonschema<4.0.0,>=3.2.0 (from pydicom-seg)\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting numpy<2.0.0,>=1.18.0 (from pydicom-seg)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Collecting pyrsistent>=0.14.0 (from jsonschema<4.0.0,>=3.2.0->pydicom-seg)\n",
            "  Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.1.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Downloading pydicom_seg-0.4.1-py3-none-any.whl (27 kB)\n",
            "Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyrsistent, numpy, jsonschema, pydicom-seg\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "Successfully installed jsonschema-3.2.0 numpy-1.26.4 pydicom-seg-0.4.1 pyrsistent-0.20.0\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.41.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3552a55d3c614a77892d1b923760ad9b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import SimpleITK as sitk\n",
        "import pydicom\n",
        "import pydicom_seg\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "D1njhVn-edBG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Paths"
      ],
      "metadata": {
        "id": "Il1FABEtehB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dir = \"/content/drive/MyDrive/PhDwork\"\n",
        "save_dir = \"/content/drive/MyDrive/PhDwork/datasets\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "YyJPyaZven3A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) Define Dataset Class with Optimized Mask Storage"
      ],
      "metadata": {
        "id": "VV3wNxCyeogU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatientDataset2DUNet(Dataset):\n",
        "    def __init__(self, patients, metadata, train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patients (list): List of patient IDs.\n",
        "            metadata (DataFrame): Metadata containing patient information.\n",
        "            train (bool): If True, filters out empty slices.\n",
        "        \"\"\"\n",
        "        self.patients = patients\n",
        "        self.metadata = metadata\n",
        "        self.train = train\n",
        "        self.slices = self._extract_slices()  # Store (img_path, mask_path, slice_idx) tuples\n",
        "\n",
        "    def get_path(self, subject, modality):\n",
        "        subject_filtered = subject[subject['Modality'] == modality]\n",
        "        return subject_filtered['File Location'].iloc[0] if not subject_filtered.empty else None\n",
        "\n",
        "    def _extract_slices(self):\n",
        "        slices = []\n",
        "        patient_paths = {p: self.metadata[self.metadata['Subject ID'] == p] for p in self.patients}\n",
        "\n",
        "        for patient, subject in patient_paths.items():\n",
        "            img_path = self.get_path(subject, \"CT\")\n",
        "            msk_path = self.get_path(subject, \"SEG\")\n",
        "\n",
        "            if img_path and msk_path:\n",
        "                min_slices = min(self.get_num_slices(img_path), self.get_num_slices(msk_path))\n",
        "                slice_indices = np.arange(min_slices) if not self.train else np.where(self.has_tumor(msk_path))[0]\n",
        "                slices.extend(zip([img_path] * len(slice_indices), [msk_path] * len(slice_indices), slice_indices))\n",
        "        return slices\n",
        "\n",
        "    def read_ct_array(self, path, slice_idx):\n",
        "        reader = sitk.ImageSeriesReader()\n",
        "        reader.SetImageIO(\"GDCMImageIO\")\n",
        "        path = os.path.normpath(path)\n",
        "        path = path.replace(\"\\\\\", \"/\")\n",
        "        dicom_names = reader.GetGDCMSeriesFileNames(path)\n",
        "        reader.SetFileNames(dicom_names)\n",
        "        image = reader.Execute()\n",
        "        return sitk.GetArrayFromImage(image)[slice_idx].astype(np.float32)\n",
        "\n",
        "    def read_seg_array(self, path, slice_idx, seg_type=\"GTV-1\"):\n",
        "        path = os.path.normpath(path)\n",
        "        path = path.replace(\"\\\\\", \"/\")\n",
        "        try:\n",
        "            segmentation = pydicom.dcmread(os.path.join(path, '1-1.dcm'))\n",
        "            seg_df = pd.DataFrame({f: [s[f].value for s in segmentation.SegmentSequence] for f in ['SegmentNumber', 'SegmentDescription']})\n",
        "            seg_number = seg_df.loc[seg_df['SegmentDescription'] == seg_type, 'SegmentNumber'].iloc[0]\n",
        "            mask = pydicom_seg.SegmentReader().read(segmentation).segment_image(seg_number)\n",
        "            return sitk.GetArrayFromImage(mask)[slice_idx].astype(np.uint8)  # Use uint8 to save space\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading segmentation from {path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path, slice_idx = self.slices[idx]\n",
        "\n",
        "        # Read one slice at a time\n",
        "        img = self.read_ct_array(img_path, slice_idx)\n",
        "        msk = self.read_seg_array(mask_path, slice_idx, \"GTV-1\")\n",
        "\n",
        "        if img is None or msk is None:\n",
        "            return torch.zeros(1, 512, 512), torch.zeros(1, 512, 512)\n",
        "\n",
        "        # Normalize image\n",
        "        img = (img - img.min()) / max(img.max(), 1e-6)  # Avoid divide-by-zero\n",
        "\n",
        "        # Convert to tensors\n",
        "        img = torch.tensor(img, dtype=torch.float16).unsqueeze(0)  # Convert to float16\n",
        "        msk = torch.tensor(msk, dtype=torch.uint8).unsqueeze(0)  # Use uint8 for masks\n",
        "\n",
        "        return img, msk\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSsfQa0EeqhM",
        "outputId": "0e5ad132-d47e-41ac-a509-42fc8162ae08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PhDwork\n",
            "Patients: Train=1, Valid=1, Test=1\n",
            "Loading Training Data...\n",
            "Processing Patient: LUNG1-002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) PROCESS & SAVE TRAIN DATASET (.npz)"
      ],
      "metadata": {
        "id": "OJ575YgJFV7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset_npz(dataset, filename):\n",
        "    save_path = os.path.join(DATASET_DIR, filename)\n",
        "    images, masks = [], []\n",
        "\n",
        "    for img, mask in dataset:\n",
        "        images.append(img.numpy())  # Already float16\n",
        "        masks.append(mask.numpy())  # Already uint8\n",
        "\n",
        "    np.savez_compressed(save_path, images=np.stack(images), masks=np.stack(masks))\n",
        "    print(f\"✅ Saved {filename} at {save_path}\")"
      ],
      "metadata": {
        "id": "Mt_owGxsFU-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (5) Load and Save Train Dataset"
      ],
      "metadata": {
        "id": "bGpwmn6Ee7-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_lung1 = pd.read_csv(\"/content/drive/MyDrive/PhDwork/metadata/metadata_lung1.csv\")\n",
        "\n",
        "patient_list_lung1 = metadata_lung1[\"Subject ID\"].unique().tolist()\n",
        "train_patient, valid_patient = train_test_split(patient_list_lung1, test_size=0.1, random_state=42)\n",
        "train_patient, test_patient = train_test_split(train_patient, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Patients: Train={len(train_patient)}, Valid={len(valid_patient)}, Test={len(test_patient)}\")\n",
        "\n",
        "# Create Train Dataset\n",
        "print(\"Loading Training Data...\")\n",
        "train_dataset = PatientDataset2DUNet(train_patient, metadata_lung1, train=True)\n",
        "\n",
        "# Save Train Dataset as .npz\n",
        "save_dataset_npz(train_dataset, \"train_dataset.npz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "9HGPqKMle-Ip",
        "outputId": "4b468aa2-32b4-4c32-beb6-b98d862e9e7e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Training Data...\n",
            "Processing Patient: LUNG1-002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float8'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4c71931ff74c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-e1c9ed4eccec>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Return empty tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    312\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float8'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (6) Display Sample Slices"
      ],
      "metadata": {
        "id": "DRpQFTMhfAmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample_shape(dataset):\n",
        "    idx = np.random.randint(0, len(dataset))\n",
        "    img, mask = dataset[idx]\n",
        "\n",
        "    print(f\"Image Shape: {img.shape}\")  # Should be (1, H, W)\n",
        "    print(f\"Mask Shape: {mask.shape}\")  # Should be (1, H, W)\n",
        "\n",
        "display_sample_shape(train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1uQ7-4PfCRx",
        "outputId": "c38c5130-5713-44d6-f124-3899abb49e86"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Shape: torch.Size([1, 512, 512])\n",
            "Mask Shape: torch.Size([1, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ua_HRykvedQ6"
      }
    }
  ]
}