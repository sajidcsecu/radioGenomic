{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajidcsecu/radioGenomic/blob/main/3DUnetinGPU_(Nifti_MONAI).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2QqHlZ8GZB"
      },
      "source": [
        "# This is the Code for the Segmentation on Rider Dataset (LUNG1). The Code is worked on the 3D volume over GPU. The balanced sampler, preprocessed data (uniform volume spacing and clipping [-1000, 700]) and the strong augmentation is used in the code..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Zo7tkcI1CX"
      },
      "source": [
        "# (1) Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OVdEeKXpMe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88c16b3f-d088-42c5-de21-57378b29662b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pydicom===2.4.3 in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pydicom-seg in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.5.2)\n",
            "Requirement already satisfied: jsonschema<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (1.23.5)\n",
            "Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from pydicom-seg) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (25.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (75.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom-seg) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Collecting monai\n",
            "  Using cached monai-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy<3.0,>=1.24 (from monai)\n",
            "  Using cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\n",
            "Using cached monai-1.5.0-py3-none-any.whl (2.7 MB)\n",
            "Using cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, monai\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydicom-seg 0.4.1 requires numpy<2.0.0,>=1.18.0, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed monai-1.5.0 numpy-2.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b2a035c9b7c74915a0bf9e91b52bd7a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.1\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (4.14.1)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n",
            "Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl (887.4 MB)\n",
            "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.1/317.1 MB\u001b[0m \u001b[31m227.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pydicom===2.4.3\n",
        "!pip install pydicom-seg\n",
        "!pip install numpy==1.23.5\n",
        "!pip install monai\n",
        "!pip install torch==1.13.1\n",
        "!pip install nibabel>=5.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadHvjQcJ-qU"
      },
      "source": [
        "\n",
        "# (2) Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmtDNjxMbfB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import lr_scheduler\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import AsDiscrete\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
        "    Orientationd, ScaleIntensityRanged, CropForegroundd, Resized,\n",
        "    RandFlipd, RandFlipd, RandAffined, RandGaussianNoised, RandScaleIntensityd,EnsureTyped, ToTensord\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, CacheDataset, pad_list_data_collate\n",
        "from monai.networks.layers import Norm\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import jaccard_score, f1_score, recall_score, precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "from monai.transforms import EnsureTyped\n",
        "from monai.transforms import SaveImaged\n",
        "from monai.utils import set_determinism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzguRDWI9bM"
      },
      "source": [
        "# (3) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6jVaaMXZz5",
        "outputId": "b509532a-6713-4c78-9059-4b6c7779aa26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFrRJqgG7wxo"
      },
      "source": [
        "## (4). Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944_4uJbmPPx"
      },
      "outputs": [],
      "source": [
        "class DiceBCELoss3D(nn.Module):\n",
        "    def __init__(self, smooth=1e-6, epsilon=1e-8):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.epsilon = epsilon\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        preds = preds.flatten()\n",
        "        targets = targets.flatten()\n",
        "        preds_sigmoid = torch.sigmoid(preds)\n",
        "        intersection = (preds_sigmoid * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (\n",
        "            preds_sigmoid.sum() + targets.sum() + self.smooth + self.epsilon)\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "        return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZ3Gu-DD88X"
      },
      "source": [
        "# (5). Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4VsKIzmFGLP"
      },
      "outputs": [],
      "source": [
        "class UnetTest:\n",
        "    def __init__(self, test_result_path: str, metrics_csv: str, device: torch.device):\n",
        "        self.test_result_path = test_result_path\n",
        "        self.metrics_csv = metrics_csv\n",
        "        self.device = device\n",
        "\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "        self._init_metrics_csv()\n",
        "\n",
        "    def _init_metrics_csv(self):\n",
        "        if not os.path.exists(self.metrics_csv):\n",
        "            with open(self.metrics_csv, 'w', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"SampleID\", \"Jaccard\", \"F1\", \"Recall\", \"Precision\", \"Accuracy\", \"Time\"])\n",
        "\n",
        "    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        y_true = y_true.astype(bool).flatten()\n",
        "        y_pred = y_pred.astype(bool).flatten()\n",
        "\n",
        "        return [\n",
        "            jaccard_score(y_true, y_pred, zero_division=0),\n",
        "            f1_score(y_true, y_pred, zero_division=0),\n",
        "            recall_score(y_true, y_pred, zero_division=0),\n",
        "            precision_score(y_true, y_pred, zero_division=0),\n",
        "            accuracy_score(y_true, y_pred)\n",
        "        ]\n",
        "\n",
        "    def save_result_slices(self, image: np.ndarray, pred_mask: np.ndarray, true_mask: np.ndarray, sample_id: str):\n",
        "        sample_dir = os.path.join(self.test_result_path, sample_id)\n",
        "        os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "        for i in range(image.shape[0]):\n",
        "            try:\n",
        "                fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "                ax[0].imshow(image[i], cmap='gray')\n",
        "                ax[0].set_title('Image')\n",
        "\n",
        "                ax[1].imshow(true_mask[i], cmap='gray')\n",
        "                ax[1].set_title('Ground Truth')\n",
        "\n",
        "                ax[2].imshow(pred_mask[i], cmap='gray')\n",
        "                ax[2].set_title('Prediction')\n",
        "\n",
        "                for a in ax:\n",
        "                    a.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(sample_dir, f'slice_{i:03d}.png'))\n",
        "                plt.close()\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Could not save slice {i} for {sample_id}: {e}\")\n",
        "\n",
        "    def append_metrics_to_csv(self, sample_id: str, metrics: list, elapsed_time: float):\n",
        "        with open(self.metrics_csv, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([sample_id] + [f\"{m:.4f}\" for m in metrics] + [f\"{elapsed_time:.4f}\"])\n",
        "\n",
        "    def test(self, model: nn.Module, test_loader: DataLoader):\n",
        "        model.eval()\n",
        "        total_metrics = np.zeros(5)\n",
        "        total_times = []\n",
        "\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_loader):\n",
        "                image, label = batch[\"vol\"].to(self.device), batch[\"seg\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "\n",
        "                pred = sliding_window_inference(\n",
        "                    inputs=image,\n",
        "                    roi_size=roi_size,\n",
        "                    sw_batch_size=sw_batch_size,\n",
        "                    predictor=model\n",
        "                )\n",
        "                pred = torch.sigmoid(pred) > 0.5  # Binary thresholding\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                total_times.append(elapsed)\n",
        "\n",
        "                # Convert to NumPy\n",
        "                image_np = image[0, 0].cpu().numpy()\n",
        "                label_np = label[0, 0].cpu().numpy()\n",
        "                pred_np = pred[0, 0].cpu().numpy()\n",
        "\n",
        "                # Metrics\n",
        "                metrics = self.calculate_metrics(label_np, pred_np)\n",
        "                total_metrics += np.array(metrics)\n",
        "\n",
        "                # Identify sample name\n",
        "                sample_id = os.path.basename(batch[\"vol_meta_dict\"][\"filename_or_obj\"][0]).replace(\".nii.gz\", \"\")\n",
        "                self.save_result_slices(image_np, pred_np, label_np, sample_id)\n",
        "                self.append_metrics_to_csv(sample_id, metrics, elapsed)\n",
        "\n",
        "        # Print summary\n",
        "        num_samples = len(test_loader)\n",
        "        print(\"\\nüìä Average Test Metrics:\")\n",
        "        print(f\"Jaccard:  {total_metrics[0]/num_samples:.4f}\")\n",
        "        print(f\"F1:       {total_metrics[1]/num_samples:.4f}\")\n",
        "        print(f\"Recall:   {total_metrics[2]/num_samples:.4f}\")\n",
        "        print(f\"Precision:{total_metrics[3]/num_samples:.4f}\")\n",
        "        print(f\"Accuracy: {total_metrics[4]/num_samples:.4f}\")\n",
        "        print(f\"‚ö° FPS:    {1 / np.mean(total_times):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8L5nD2EVP_"
      },
      "source": [
        "# (6). Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "281KQS_iEIDX"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True, min_delta=0, path='checkpoint.pt',\n",
        "                 start_val_loss_min=None, start_patience_counter=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.val_loss_min = start_val_loss_min if start_val_loss_min is not None else np.inf\n",
        "        self.counter = start_patience_counter\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch=None, optimizer=None):\n",
        "        improved = False\n",
        "        if val_loss < self.val_loss_min - self.min_delta:\n",
        "            self.val_loss_min = val_loss\n",
        "            self.counter = 0\n",
        "            improved = True\n",
        "            if self.verbose:\n",
        "                print(f\"‚úÖ Validation loss improved. Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"‚è≥ EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "\n",
        "        # ‚úÖ Always save full checkpoint (model + optimizer + val_loss + patience_counter)\n",
        "        self.save_checkpoint(model, epoch, optimizer)\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, model, epoch=None, optimizer=None):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
        "            'val_loss': self.val_loss_min,\n",
        "            'patience_counter': self.counter\n",
        "        }\n",
        "        torch.save(checkpoint, self.path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class UnetTrain:\n",
        "    def __init__(self, model_file, loss_result_path, lr, num_epochs, device):\n",
        "        self.model_file = model_file\n",
        "        self.loss_result_path = loss_result_path\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = device\n",
        "        self.seeding(42)\n",
        "\n",
        "    def seeding(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed = end_time - start_time\n",
        "        return int(elapsed / 60), int(elapsed % 60)\n",
        "\n",
        "    def train_one_epoch(self, model, loader, optimizer, loss_fn):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        scaler = torch.amp.GradScaler()  # no device_type here\n",
        "\n",
        "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
        "\n",
        "        for x in loader:\n",
        "            inputs, labels = x[\"vol\"].to(self.device), x[\"seg\"].to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast(device_type=device_type):\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def evaluate(self, model, loader, loss_fn):\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x in loader:\n",
        "                inputs, labels = x[\"vol\"].to(self.device), x[\"seg\"].to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                epoch_loss += loss.item()\n",
        "        return epoch_loss / len(loader)\n",
        "\n",
        "    def execute(self, train_loader, valid_loader):\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        loss_fn = DiceBCELoss3D()\n",
        "\n",
        "        # Initialize state\n",
        "        start_epoch = 1\n",
        "        start_val_loss_min = None\n",
        "        start_patience_counter = 0\n",
        "        history = {\"train_loss\": [], \"valid_loss\": []}\n",
        "\n",
        "        # üì¶ Restore from model checkpoint if exists\n",
        "        if os.path.exists(self.model_file):\n",
        "            checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            if checkpoint.get('optimizer_state_dict'):\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "            start_val_loss_min = checkpoint.get('val_loss', None)\n",
        "            start_patience_counter = checkpoint.get('patience_counter', 0)\n",
        "\n",
        "        # üìä Restore training history from loss CSV\n",
        "        if os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, 'r') as f:\n",
        "                reader = csv.reader(f)\n",
        "                next(reader)\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    last_epoch = int(rows[-1][0])\n",
        "                    start_epoch = last_epoch + 1\n",
        "                    history['train_loss'] = [float(r[1]) for r in rows]\n",
        "                    history['valid_loss'] = [float(r[2]) for r in rows]\n",
        "                    if start_val_loss_min is None:\n",
        "                        start_val_loss_min = min(history['valid_loss'])\n",
        "\n",
        "            # üíæ Make a backup copy\n",
        "            backup_path = self.loss_result_path.replace(\".csv\", \"_backup.csv\")\n",
        "            shutil.copy(self.loss_result_path, backup_path)\n",
        "\n",
        "        # üõë Initialize EarlyStopping\n",
        "        early_stopping = EarlyStopping(\n",
        "            patience=10,\n",
        "            min_delta=0.0005,\n",
        "            path=self.model_file,\n",
        "            start_val_loss_min=start_val_loss_min,\n",
        "            start_patience_counter=start_patience_counter\n",
        "        )\n",
        "\n",
        "        # üìÅ If loss file not present, create CSV header\n",
        "        if not os.path.exists(self.loss_result_path):\n",
        "            with open(self.loss_result_path, \"w\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\"Epoch\", \"Train Loss\", \"Valid Loss\"])\n",
        "\n",
        "        # üöÇ Training Loop\n",
        "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = self.train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            valid_loss = self.evaluate(model, valid_loader, loss_fn)\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, time.time())\n",
        "            print(f\"Epoch {epoch:03d} | Time: {epoch_mins}m {epoch_secs}s | \"\n",
        "                  f\"Train: {train_loss:.6f} | Val: {valid_loss:.6f}\")\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['valid_loss'].append(valid_loss)\n",
        "\n",
        "            with open(self.loss_result_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([epoch, train_loss, valid_loss])\n",
        "\n",
        "            # üõë Early stopping check\n",
        "            if early_stopping(valid_loss, model, epoch, optimizer):\n",
        "                print(\"üõë Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (7). Pipeline"
      ],
      "metadata": {
        "id": "BZrW1cHg4OlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwcTHPshqu0O",
        "outputId": "826b5d3e-af03-4738-e8e2-cfeead5a08c6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Loading datasets...\n",
            "Epoch 071 | Time: 71m 35s | Train: 0.674845 | Val: 0.805939\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "Epoch 072 | Time: 68m 22s | Train: 0.711546 | Val: 0.810964\n",
            "‚è≥ EarlyStopping counter: 3 out of 10\n",
            "Epoch 073 | Time: 68m 42s | Train: 0.706732 | Val: 0.791821\n",
            "‚è≥ EarlyStopping counter: 4 out of 10\n",
            "Epoch 074 | Time: 68m 55s | Train: 0.681764 | Val: 0.789887\n",
            "‚è≥ EarlyStopping counter: 5 out of 10\n",
            "Epoch 075 | Time: 69m 1s | Train: 0.665208 | Val: 0.781649\n",
            "‚úÖ Validation loss improved. Saving model...\n",
            "Epoch 076 | Time: 69m 7s | Train: 0.641370 | Val: 0.784236\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "Epoch 077 | Time: 69m 18s | Train: 0.660566 | Val: 0.789251\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "Epoch 078 | Time: 69m 23s | Train: 0.639254 | Val: 0.780697\n",
            "‚úÖ Validation loss improved. Saving model...\n",
            "Epoch 079 | Time: 69m 26s | Train: 0.631953 | Val: 0.774602\n",
            "‚úÖ Validation loss improved. Saving model...\n",
            "Epoch 080 | Time: 69m 35s | Train: 0.628322 | Val: 0.770767\n",
            "‚úÖ Validation loss improved. Saving model...\n",
            "Epoch 081 | Time: 69m 34s | Train: 0.663994 | Val: 0.798359\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "Epoch 082 | Time: 69m 34s | Train: 0.663142 | Val: 0.796649\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "Epoch 083 | Time: 69m 40s | Train: 0.670170 | Val: 0.752426\n",
            "‚úÖ Validation loss improved. Saving model...\n",
            "Epoch 084 | Time: 69m 44s | Train: 0.654404 | Val: 0.807204\n",
            "‚è≥ EarlyStopping counter: 1 out of 10\n",
            "Epoch 085 | Time: 69m 44s | Train: 0.641575 | Val: 0.787742\n",
            "‚è≥ EarlyStopping counter: 2 out of 10\n",
            "Epoch 086 | Time: 69m 49s | Train: 0.657449 | Val: 0.757477\n",
            "‚è≥ EarlyStopping counter: 3 out of 10\n",
            "Epoch 087 | Time: 69m 48s | Train: 0.638449 | Val: 0.815259\n",
            "‚è≥ EarlyStopping counter: 4 out of 10\n",
            "Epoch 088 | Time: 69m 50s | Train: 0.643433 | Val: 0.777593\n",
            "‚è≥ EarlyStopping counter: 5 out of 10\n",
            "Epoch 089 | Time: 69m 47s | Train: 0.637775 | Val: 0.783900\n",
            "‚è≥ EarlyStopping counter: 6 out of 10\n",
            "Epoch 090 | Time: 69m 48s | Train: 0.624687 | Val: 0.788911\n",
            "‚è≥ EarlyStopping counter: 7 out of 10\n"
          ]
        }
      ],
      "source": [
        "class UnetPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.setup_paths()\n",
        "        print(\"üì¶ Loading datasets...\")\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self.prepare_loaders()\n",
        "\n",
        "    def setup_paths(self):\n",
        "        os.chdir(self.config['target_dir'])\n",
        "        self.output_dir = os.path.join(\".\", \"results\", self.config['output_folder_name'])\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.loss_result_file = os.path.join(self.output_dir, \"train_and_valid_loss_results.csv\")\n",
        "        self.model_file = os.path.join(self.output_dir, \"model.pth\")\n",
        "        self.test_metrics_file = os.path.join(self.output_dir, \"test_metrics.csv\")\n",
        "        self.test_result_path = os.path.join(self.output_dir, \"test_outputs\")\n",
        "        os.makedirs(self.test_result_path, exist_ok=True)\n",
        "\n",
        "        self.dataset_dir = os.path.join(\"./datasets\", f\"Datasets_{self.config['transformation']}\")\n",
        "\n",
        "    def prepare_loaders(self):\n",
        "        from glob import glob\n",
        "        from monai.transforms import (\n",
        "            Compose, LoadImaged, EnsureChannelFirstD, Spacingd, Orientationd,\n",
        "            ScaleIntensityRanged, CropForegroundd, Resized, ToTensord,\n",
        "            RandFlipd, RandAffined, RandGaussianNoised, RandScaleIntensityd\n",
        "        )\n",
        "        from monai.data import Dataset, DataLoader\n",
        "\n",
        "        pixdim = (1, 1, 1)\n",
        "        a_min, a_max = -1000, 700\n",
        "        spatial_size = (96, 96, 96)\n",
        "\n",
        "        def get_files(split):\n",
        "            ct = sorted(glob(os.path.join(self.dataset_dir, split, \"ct\", \"*.nii.gz\")))\n",
        "            seg = sorted(glob(os.path.join(self.dataset_dir, split, \"segment\", \"*.nii.gz\")))\n",
        "            return [{\"vol\": c, \"seg\": s} for c, s in zip(ct, seg)]\n",
        "\n",
        "        # Training transforms with augmentation\n",
        "        train_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "\n",
        "            # ‚ûï Augmentations\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=0),\n",
        "            RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=1),\n",
        "            RandAffined(\n",
        "                keys=[\"vol\", \"seg\"],\n",
        "                prob=0.3,\n",
        "                rotate_range=(0.1, 0.1, 0.1),\n",
        "                scale_range=(0.1, 0.1, 0.1),\n",
        "                mode=(\"bilinear\", \"nearest\")\n",
        "            ),\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.2, mean=0.0, std=0.1),\n",
        "            RandScaleIntensityd(keys=[\"vol\"], factors=0.1, prob=0.5),\n",
        "\n",
        "            ToTensord(keys=[\"vol\", \"seg\"])\n",
        "        ])\n",
        "\n",
        "        # Validation/test transforms without augmentation\n",
        "        base_transforms = Compose([\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"])\n",
        "        ])\n",
        "\n",
        "        train_loader = DataLoader(Dataset(get_files(\"train\"), train_transforms), batch_size=self.config['batch_size'], shuffle=True)\n",
        "        valid_loader = DataLoader(Dataset(get_files(\"valid\"), base_transforms), batch_size=self.config['batch_size'])\n",
        "        test_loader = DataLoader(Dataset(get_files(\"test\"), base_transforms), batch_size=1)\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    def train(self):\n",
        "        trainer = UnetTrain(\n",
        "            model_file=self.model_file,\n",
        "            loss_result_path=self.loss_result_file,\n",
        "            lr=self.config['learning_rate'],\n",
        "            num_epochs=self.config['num_epochs'],\n",
        "            device=self.device\n",
        "        )\n",
        "        trainer.execute(self.train_loader, self.valid_loader)\n",
        "\n",
        "    def test(self):\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "        checkpoint = torch.load(self.model_file, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        tester = UnetTest(self.test_result_path, self.test_metrics_file, self.device)\n",
        "        tester.test(model, self.test_loader)\n",
        "\n",
        "    def run(self):\n",
        "        self.train()\n",
        "        self.test()\n",
        "\n",
        "\n",
        "def main():\n",
        "    config = {\n",
        "        'target_dir': \"/content/drive/MyDrive/PhDwork/Segmentation\",\n",
        "        'output_folder_name': \"Results_MONAI_Augmented\",\n",
        "        'transformation': \"OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\",\n",
        "        'batch_size': 2,\n",
        "        'num_epochs': 100,\n",
        "        'learning_rate': 1e-4,\n",
        "    }\n",
        "    pipeline = UnetPipeline(config)\n",
        "    pipeline.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mp.set_start_method('spawn')\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) Mask Generation"
      ],
      "metadata": {
        "id": "hSP35kUBOaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.layers import Norm\n",
        "\n",
        "\n",
        "class UNetInferencePipeline:\n",
        "    def __init__(self, model_path, input_folder, output_folder, device=\"cuda:0\"):\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model_path = model_path\n",
        "        self.input_folder = input_folder\n",
        "        self.output_folder = output_folder\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        set_determinism(seed=42)\n",
        "\n",
        "        self.model = self._load_model()\n",
        "        self.transform = self._prepare_transforms()\n",
        "        self.dataloader = self._prepare_dataloader()\n",
        "\n",
        "    def _load_model(self):\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
        "\n",
        "        model = UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            norm=Norm.BATCH\n",
        "        ).to(self.device)\n",
        "\n",
        "        state_dict = torch.load(self.model_path, map_location=self.device)\n",
        "        if 'model_state_dict' in state_dict:\n",
        "            model.load_state_dict(state_dict['model_state_dict'])\n",
        "        else:\n",
        "            model.load_state_dict(state_dict)\n",
        "\n",
        "        model.eval()\n",
        "        print(f\"‚úÖ Model loaded successfully from {self.model_path}\")\n",
        "        return model\n",
        "\n",
        "    def _prepare_transforms(self):\n",
        "        return Compose([\n",
        "            LoadImaged(keys=[\"vol\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\"]),\n",
        "            Spacingd(keys=[\"vol\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "            Orientationd(keys=[\"vol\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-1000, a_max=700, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\"], source_key=\"vol\"),\n",
        "            EnsureTyped(keys=[\"vol\"], track_meta=True),\n",
        "            ToTensord(keys=[\"vol\"]),\n",
        "        ])\n",
        "\n",
        "    def _prepare_dataloader(self):\n",
        "        nifti_files = sorted(Path(self.input_folder).glob(\"*.nii.gz\"))\n",
        "        if not nifti_files:\n",
        "            raise FileNotFoundError(f\"No NIfTI files found in input folder: {self.input_folder}\")\n",
        "\n",
        "        data_dicts = [{\"vol\": str(f)} for f in nifti_files]\n",
        "        print(f\"üîç Found {len(data_dicts)} NIfTI files for inference.\")\n",
        "        return DataLoader(Dataset(data=data_dicts, transform=self.transform),\n",
        "                          batch_size=1, num_workers=0, collate_fn=list_data_collate)\n",
        "\n",
        "    def infer(self, roi_size=(96, 96, 96), sw_batch_size=1, overlap=0.5):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.dataloader):\n",
        "                try:\n",
        "                    meta = batch[\"vol\"].meta if hasattr(batch[\"vol\"], \"meta\") else {}\n",
        "                    input_path = meta.get(\"filename_or_obj\", [f\"case_{i}\"])[0]\n",
        "                    input_filename = Path(input_path).stem\n",
        "\n",
        "                    images = batch[\"vol\"].to(self.device)\n",
        "                    print(f\"üîç Inference on [{i+1}] {input_filename} | shape = {images.shape}\")\n",
        "\n",
        "                    # Sliding window inference\n",
        "                    preds = sliding_window_inference(\n",
        "                        images, roi_size=roi_size,\n",
        "                        sw_batch_size=sw_batch_size,\n",
        "                        predictor=self.model,\n",
        "                        overlap=overlap\n",
        "                    )\n",
        "\n",
        "                    # Apply sigmoid and threshold\n",
        "                    probs = torch.sigmoid(preds)\n",
        "                    pred_label = (probs > 0.5).float()\n",
        "\n",
        "                    # Save output\n",
        "                    self._save_prediction(\n",
        "                        pred=pred_label,\n",
        "                        meta=meta,\n",
        "                        input_filename=input_filename\n",
        "                    )\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error during inference on batch {i}: {e}\")\n",
        "\n",
        "\n",
        "    def _save_prediction(self, pred, meta, input_filename):\n",
        "        # Remove batch and channel dimensions: [1, 1, D, H, W] ‚Üí [D, H, W]\n",
        "        pred_np = pred.squeeze().cpu().numpy()\n",
        "\n",
        "        # --- Robust affine extraction ---\n",
        "        affine = meta.get(\"affine\")\n",
        "        if isinstance(affine, list):\n",
        "            affine = affine[0]\n",
        "        affine = np.asarray(affine)\n",
        "        if affine.shape != (4, 4):\n",
        "            print(f\"‚ö†Ô∏è Invalid affine shape: {affine.shape}, using identity affine.\")\n",
        "            affine = np.eye(4)\n",
        "\n",
        "        # Save with nibabel\n",
        "        out_path = Path(self.output_folder) / f\"{input_filename}_seg.nii.gz\"\n",
        "        nib_img = nib.Nifti1Image(pred_np.astype(np.uint8), affine)\n",
        "        nib.save(nib_img, str(out_path))\n",
        "        print(f\"‚úÖ Saved: {out_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ROOT_DIR = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    MODEL_PATH = os.path.join(ROOT_DIR, \"results\", \"Results_MONAI_Augmented\", \"model.pth\")\n",
        "    INPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"ct\")\n",
        "    OUTPUT_FOLDER = os.path.join(ROOT_DIR, \"datasets\", \"Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train\", \"Lung3\", \"segment\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    os.chdir(ROOT_DIR)\n",
        "\n",
        "    try:\n",
        "        pipeline = UNetInferencePipeline(MODEL_PATH, INPUT_FOLDER, OUTPUT_FOLDER)\n",
        "        pipeline.infer()\n",
        "        print(\"üéâ Inference completed successfully for all patients!\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "Ckpn4rjZJ9fn",
        "outputId": "d08a9b8b-e7c1-4f65-abd6-48492bd2c4a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully from /content/drive/MyDrive/PhDwork/Segmentation/results/Results_MONAI_Augmented/model.pth\n",
            "üîç Found 89 NIfTI files for inference.\n",
            "üîç Inference on [1] LUNG3-01.nii | shape = torch.Size([1, 1, 58, 499, 2553])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-01.nii_seg.nii.gz\n",
            "üîç Inference on [2] LUNG3-02.nii | shape = torch.Size([1, 1, 40, 360, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-02.nii_seg.nii.gz\n",
            "üîç Inference on [3] LUNG3-03.nii | shape = torch.Size([1, 1, 44, 364, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-03.nii_seg.nii.gz\n",
            "üîç Inference on [4] LUNG3-04.nii | shape = torch.Size([1, 1, 60, 499, 2553])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-04.nii_seg.nii.gz\n",
            "üîç Inference on [5] LUNG3-05.nii | shape = torch.Size([1, 1, 192, 430, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-05.nii_seg.nii.gz\n",
            "üîç Inference on [6] LUNG3-06.nii | shape = torch.Size([1, 1, 60, 498, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-06.nii_seg.nii.gz\n",
            "üîç Inference on [7] LUNG3-07.nii | shape = torch.Size([1, 1, 60, 358, 2069])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-07.nii_seg.nii.gz\n",
            "üîç Inference on [8] LUNG3-08.nii | shape = torch.Size([1, 1, 124, 402, 1287])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-08.nii_seg.nii.gz\n",
            "üîç Inference on [9] LUNG3-09.nii | shape = torch.Size([1, 1, 104, 380, 1023])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-09.nii_seg.nii.gz\n",
            "üîç Inference on [10] LUNG3-10.nii | shape = torch.Size([1, 1, 69, 370, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-10.nii_seg.nii.gz\n",
            "üîç Inference on [11] LUNG3-11.nii | shape = torch.Size([1, 1, 212, 430, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-11.nii_seg.nii.gz\n",
            "üîç Inference on [12] LUNG3-12.nii | shape = torch.Size([1, 1, 173, 430, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-12.nii_seg.nii.gz\n",
            "üîç Inference on [13] LUNG3-13.nii | shape = torch.Size([1, 1, 49, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-13.nii_seg.nii.gz\n",
            "üîç Inference on [14] LUNG3-14.nii | shape = torch.Size([1, 1, 444, 700, 1534])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-14.nii_seg.nii.gz\n",
            "üîç Inference on [15] LUNG3-15.nii | shape = torch.Size([1, 1, 274, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-15.nii_seg.nii.gz\n",
            "üîç Inference on [16] LUNG3-16.nii | shape = torch.Size([1, 1, 225, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-16.nii_seg.nii.gz\n",
            "üîç Inference on [17] LUNG3-17.nii | shape = torch.Size([1, 1, 190, 430, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-17.nii_seg.nii.gz\n",
            "üîç Inference on [18] LUNG3-18.nii | shape = torch.Size([1, 1, 174, 498, 2553])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-18.nii_seg.nii.gz\n",
            "üîç Inference on [19] LUNG3-19.nii | shape = torch.Size([1, 1, 174, 498, 2551])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-19.nii_seg.nii.gz\n",
            "üîç Inference on [20] LUNG3-20.nii | shape = torch.Size([1, 1, 206, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-20.nii_seg.nii.gz\n",
            "üîç Inference on [21] LUNG3-21.nii | shape = torch.Size([1, 1, 72, 499, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-21.nii_seg.nii.gz\n",
            "üîç Inference on [22] LUNG3-22.nii | shape = torch.Size([1, 1, 198, 430, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-22.nii_seg.nii.gz\n",
            "üîç Inference on [23] LUNG3-23.nii | shape = torch.Size([1, 1, 47, 465, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-23.nii_seg.nii.gz\n",
            "üîç Inference on [24] LUNG3-24.nii | shape = torch.Size([1, 1, 96, 367, 1023])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-24.nii_seg.nii.gz\n",
            "üîç Inference on [25] LUNG3-25.nii | shape = torch.Size([1, 1, 197, 499, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-25.nii_seg.nii.gz\n",
            "üîç Inference on [26] LUNG3-26.nii | shape = torch.Size([1, 1, 57, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-26.nii_seg.nii.gz\n",
            "üîç Inference on [27] LUNG3-27.nii | shape = torch.Size([1, 1, 109, 375, 1023])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-27.nii_seg.nii.gz\n",
            "üîç Inference on [28] LUNG3-28.nii | shape = torch.Size([1, 1, 53, 311, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-28.nii_seg.nii.gz\n",
            "üîç Inference on [29] LUNG3-29.nii | shape = torch.Size([1, 1, 203, 600, 2571])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-29.nii_seg.nii.gz\n",
            "üîç Inference on [30] LUNG3-30.nii | shape = torch.Size([1, 1, 50, 356, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-30.nii_seg.nii.gz\n",
            "üîç Inference on [31] LUNG3-31.nii | shape = torch.Size([1, 1, 283, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-31.nii_seg.nii.gz\n",
            "üîç Inference on [32] LUNG3-32.nii | shape = torch.Size([1, 1, 57, 499, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-32.nii_seg.nii.gz\n",
            "üîç Inference on [33] LUNG3-33.nii | shape = torch.Size([1, 1, 323, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-33.nii_seg.nii.gz\n",
            "üîç Inference on [34] LUNG3-34.nii | shape = torch.Size([1, 1, 299, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-34.nii_seg.nii.gz\n",
            "üîç Inference on [35] LUNG3-35.nii | shape = torch.Size([1, 1, 213, 429, 766])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-35.nii_seg.nii.gz\n",
            "üîç Inference on [36] LUNG3-36.nii | shape = torch.Size([1, 1, 348, 500, 1278])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-36.nii_seg.nii.gz\n",
            "üîç Inference on [37] LUNG3-37.nii | shape = torch.Size([1, 1, 72, 381, 2088])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-37.nii_seg.nii.gz\n",
            "üîç Inference on [38] LUNG3-38.nii | shape = torch.Size([1, 1, 165, 378, 768])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-38.nii_seg.nii.gz\n",
            "üîç Inference on [39] LUNG3-39.nii | shape = torch.Size([1, 1, 62, 383, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-39.nii_seg.nii.gz\n",
            "üîç Inference on [40] LUNG3-40.nii | shape = torch.Size([1, 1, 201, 430, 774])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-40.nii_seg.nii.gz\n",
            "üîç Inference on [41] LUNG3-41.nii | shape = torch.Size([1, 1, 67, 312, 1023])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-41.nii_seg.nii.gz\n",
            "üîç Inference on [42] LUNG3-42.nii | shape = torch.Size([1, 1, 299, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-42.nii_seg.nii.gz\n",
            "üîç Inference on [43] LUNG3-43.nii | shape = torch.Size([1, 1, 66, 498, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-43.nii_seg.nii.gz\n",
            "üîç Inference on [44] LUNG3-44.nii | shape = torch.Size([1, 1, 191, 429, 766])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-44.nii_seg.nii.gz\n",
            "üîç Inference on [45] LUNG3-45.nii | shape = torch.Size([1, 1, 174, 498, 2552])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-45.nii_seg.nii.gz\n",
            "üîç Inference on [46] LUNG3-46.nii | shape = torch.Size([1, 1, 155, 429, 773])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-46.nii_seg.nii.gz\n",
            "üîç Inference on [47] LUNG3-47.nii | shape = torch.Size([1, 1, 322, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-47.nii_seg.nii.gz\n",
            "üîç Inference on [48] LUNG3-48.nii | shape = torch.Size([1, 1, 184, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-48.nii_seg.nii.gz\n",
            "üîç Inference on [49] LUNG3-49.nii | shape = torch.Size([1, 1, 60, 344, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-49.nii_seg.nii.gz\n",
            "üîç Inference on [50] LUNG3-50.nii | shape = torch.Size([1, 1, 299, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-50.nii_seg.nii.gz\n",
            "üîç Inference on [51] LUNG3-51.nii | shape = torch.Size([1, 1, 56, 375, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-51.nii_seg.nii.gz\n",
            "üîç Inference on [52] LUNG3-52.nii | shape = torch.Size([1, 1, 30, 308, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-52.nii_seg.nii.gz\n",
            "üîç Inference on [53] LUNG3-53.nii | shape = torch.Size([1, 1, 299, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-53.nii_seg.nii.gz\n",
            "üîç Inference on [54] LUNG3-54.nii | shape = torch.Size([1, 1, 205, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-54.nii_seg.nii.gz\n",
            "üîç Inference on [55] LUNG3-55.nii | shape = torch.Size([1, 1, 57, 401, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-55.nii_seg.nii.gz\n",
            "üîç Inference on [56] LUNG3-56.nii | shape = torch.Size([1, 1, 174, 498, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-56.nii_seg.nii.gz\n",
            "üîç Inference on [57] LUNG3-57.nii | shape = torch.Size([1, 1, 174, 498, 2552])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-57.nii_seg.nii.gz\n",
            "üîç Inference on [58] LUNG3-58.nii | shape = torch.Size([1, 1, 50, 398, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-58.nii_seg.nii.gz\n",
            "üîç Inference on [59] LUNG3-59.nii | shape = torch.Size([1, 1, 49, 404, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-59.nii_seg.nii.gz\n",
            "üîç Inference on [60] LUNG3-60.nii | shape = torch.Size([1, 1, 61, 340, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-60.nii_seg.nii.gz\n",
            "üîç Inference on [61] LUNG3-61.nii | shape = torch.Size([1, 1, 171, 430, 771])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-61.nii_seg.nii.gz\n",
            "üîç Inference on [62] LUNG3-62.nii | shape = torch.Size([1, 1, 50, 386, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-62.nii_seg.nii.gz\n",
            "üîç Inference on [63] LUNG3-63.nii | shape = torch.Size([1, 1, 43, 380, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-63.nii_seg.nii.gz\n",
            "üîç Inference on [64] LUNG3-64.nii | shape = torch.Size([1, 1, 201, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-64.nii_seg.nii.gz\n",
            "üîç Inference on [65] LUNG3-65.nii | shape = torch.Size([1, 1, 205, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-65.nii_seg.nii.gz\n",
            "üîç Inference on [66] LUNG3-66.nii | shape = torch.Size([1, 1, 43, 318, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-66.nii_seg.nii.gz\n",
            "üîç Inference on [67] LUNG3-67.nii | shape = torch.Size([1, 1, 51, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-67.nii_seg.nii.gz\n",
            "üîç Inference on [68] LUNG3-68.nii | shape = torch.Size([1, 1, 41, 344, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-68.nii_seg.nii.gz\n",
            "üîç Inference on [69] LUNG3-69.nii | shape = torch.Size([1, 1, 185, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-69.nii_seg.nii.gz\n",
            "üîç Inference on [70] LUNG3-70.nii | shape = torch.Size([1, 1, 302, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-70.nii_seg.nii.gz\n",
            "üîç Inference on [71] LUNG3-71.nii | shape = torch.Size([1, 1, 392, 700, 1534])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-71.nii_seg.nii.gz\n",
            "üîç Inference on [72] LUNG3-72.nii | shape = torch.Size([1, 1, 58, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-72.nii_seg.nii.gz\n",
            "üîç Inference on [73] LUNG3-73.nii | shape = torch.Size([1, 1, 255, 598, 2062])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-73.nii_seg.nii.gz\n",
            "üîç Inference on [74] LUNG3-74.nii | shape = torch.Size([1, 1, 49, 374, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-74.nii_seg.nii.gz\n",
            "üîç Inference on [75] LUNG3-75.nii | shape = torch.Size([1, 1, 56, 324, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-75.nii_seg.nii.gz\n",
            "üîç Inference on [76] LUNG3-76.nii | shape = torch.Size([1, 1, 68, 468, 2625])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-76.nii_seg.nii.gz\n",
            "üîç Inference on [77] LUNG3-77.nii | shape = torch.Size([1, 1, 68, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-77.nii_seg.nii.gz\n",
            "üîç Inference on [78] LUNG3-78.nii | shape = torch.Size([1, 1, 299, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-78.nii_seg.nii.gz\n",
            "üîç Inference on [79] LUNG3-79.nii | shape = torch.Size([1, 1, 281, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-79.nii_seg.nii.gz\n",
            "üîç Inference on [80] LUNG3-80.nii | shape = torch.Size([1, 1, 47, 404, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-80.nii_seg.nii.gz\n",
            "üîç Inference on [81] LUNG3-81.nii | shape = torch.Size([1, 1, 300, 500, 1278])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-81.nii_seg.nii.gz\n",
            "üîç Inference on [82] LUNG3-82.nii | shape = torch.Size([1, 1, 56, 367, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-82.nii_seg.nii.gz\n",
            "üîç Inference on [83] LUNG3-83.nii | shape = torch.Size([1, 1, 174, 498, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-83.nii_seg.nii.gz\n",
            "üîç Inference on [84] LUNG3-84.nii | shape = torch.Size([1, 1, 64, 498, 2554])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-84.nii_seg.nii.gz\n",
            "üîç Inference on [85] LUNG3-85.nii | shape = torch.Size([1, 1, 274, 600, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-85.nii_seg.nii.gz\n",
            "üîç Inference on [86] LUNG3-86.nii | shape = torch.Size([1, 1, 54, 350, 2045])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-86.nii_seg.nii.gz\n",
            "üîç Inference on [87] LUNG3-87.nii | shape = torch.Size([1, 1, 77, 498, 2553])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-87.nii_seg.nii.gz\n",
            "üîç Inference on [88] LUNG3-88.nii | shape = torch.Size([1, 1, 180, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-88.nii_seg.nii.gz\n",
            "üîç Inference on [89] LUNG3-89.nii | shape = torch.Size([1, 1, 185, 600, 2556])\n",
            "‚ö†Ô∏è Invalid affine shape: (1, 4, 4), using identity affine.\n",
            "‚úÖ Saved: /content/drive/MyDrive/PhDwork/Segmentation/datasets/Datasets_OriginalCT_Nifti_Empty_NonEmpty_slices_In_Train/Lung3/segment/LUNG3-89.nii_seg.nii.gz\n",
            "üéâ Inference completed successfully for all patients!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKImglO4-twL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "class LossPlotter:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        if not self.csv_path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.csv_path}\")\n",
        "        df = pd.read_csv(self.csv_path, index_col=0)  # Read row labels as index\n",
        "        return df  # Make rows into columns\n",
        "\n",
        "    def plot(self, title: str = \"Training and Validation Loss\", save_path= None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.data.index, self.data['Train Loss'], label='Train Loss', color='blue')\n",
        "        plt.plot(self.data.index, self.data['Valid Loss'], label='Valid Loss', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(title)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, format='pdf')\n",
        "            print(f\"[INFO] Loss plot saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_dir = \"/content/drive/MyDrive/PhDwork/Segmentation\"\n",
        "    os.chdir(target_dir)\n",
        "    loss_result_file = os.path.join(\".\",\"results\",f\"Results_PreProcessedCT_Fifty_Fifty_DiceLoss_And_Strong_Augmentation\",\"train_and_valid_loss_results.csv\")\n",
        "    plotter = LossPlotter(loss_result_file)\n",
        "    plotter.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeB21BYGQPu"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "os.chdir(\"/content/drive/MyDrive/PhDwork/Segmentation\")\n",
        "print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
        "with h5py.File('./datasets/Datasets_PreprocessedCT_clipping_uniformSpacing_With_Empty_NonEmpty_slices_In_Train/train_dataset.hdf5', 'r') as f:\n",
        "    print(list(f.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud1cFDGmKQBK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyOBDOZbkGzTkyR7asPuHdsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}